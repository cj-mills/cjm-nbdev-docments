{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Fix\n",
    "\n",
    "> Automatically add placeholder documentation to non-compliant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp autofix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import ast\n",
    "from typing import List, Dict, Any, Optional, NamedTuple\n",
    "import re\n",
    "from pathlib import Path\n",
    "from execnb.nbio import read_nb, write_nb\n",
    "from fastcore.foundation import L\n",
    "from fastcore.basics import ifnone, patch, compose\n",
    "from cjm_nbdev_docments.core import DocmentsCheckResult, check_definition\n",
    "from cjm_nbdev_docments.scanner import scan_notebook, get_export_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def needs_fixing(\n",
    "    self: DocmentsCheckResult\n",
    ") -> bool:  # TODO: Add return description\n",
    "    \"Check if this definition needs any fixing\"\n",
    "    return not self.is_compliant or self.missing_params or self.params_missing_type_hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_param_name(\n",
    "    self: DocmentsCheckResult,\n",
    "    param_str: str  # TODO: Add description\n",
    ") -> str:  # TODO: Add return description\n",
    "    \"Extract parameter name from a parameter string\"\n",
    "    return param_str.split(':', 1)[0].split('=', 1)[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch \n",
    "def needs_param_fix(\n",
    "    self: DocmentsCheckResult,\n",
    "    param_name: str  # TODO: Add description\n",
    ") -> bool:  # TODO: Add return description\n",
    "    \"Check if a parameter needs documentation or type hint fixes\"\n",
    "    needs_doc = param_name in self.missing_params and param_name != 'self'\n",
    "    needs_type_hint = param_name in self.params_missing_type_hints and param_name != 'self'\n",
    "    return needs_doc or needs_type_hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def find_signature_boundaries(\n",
    "    lines: List[str]  # Source code lines\n",
    ") -> tuple[int, int]:  # (def_line_idx, sig_end_idx) or (-1, -1) if not found\n",
    "    \"Find the start and end lines of a function signature\"\n",
    "    def_line_idx = None\n",
    "    sig_end_idx = None\n",
    "    paren_count = 0\n",
    "    in_signature = False\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith(('def ', 'async def ')):\n",
    "            def_line_idx = i\n",
    "            in_signature = True\n",
    "            \n",
    "        if in_signature:\n",
    "            # Count parentheses to find where signature ends\n",
    "            paren_count += line.count('(') - line.count(')')\n",
    "            \n",
    "            # If we're back to balanced parens and line contains a colon, signature is done\n",
    "            # (colon might be followed by comments)\n",
    "            if paren_count == 0 and ':' in line:\n",
    "                sig_end_idx = i\n",
    "                break\n",
    "    \n",
    "    # Use ifnone for cleaner null handling\n",
    "    def_line_idx = ifnone(def_line_idx, -1)\n",
    "    sig_end_idx = ifnone(sig_end_idx, -1)\n",
    "    \n",
    "    if def_line_idx == -1 or sig_end_idx == -1:\n",
    "        return -1, -1\n",
    "    \n",
    "    return def_line_idx, sig_end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_parameters(\n",
    "    params_str: str  # Parameter string from function signature\n",
    ") -> List[str]:  # List of individual parameter strings\n",
    "    \"Split a parameter string into individual parameters, handling nested types\"\n",
    "    if not params_str.strip():\n",
    "        return []\n",
    "    \n",
    "    # Use a more robust approach for complex nested types\n",
    "    params = []\n",
    "    current_param = ''\n",
    "    paren_depth = 0\n",
    "    bracket_depth = 0\n",
    "    brace_depth = 0\n",
    "    \n",
    "    for char in params_str:\n",
    "        if char == '(':\n",
    "            paren_depth += 1\n",
    "        elif char == ')':\n",
    "            paren_depth -= 1\n",
    "        elif char == '[':\n",
    "            bracket_depth += 1\n",
    "        elif char == ']':\n",
    "            bracket_depth -= 1\n",
    "        elif char == '{':\n",
    "            brace_depth += 1\n",
    "        elif char == '}':\n",
    "            brace_depth -= 1\n",
    "        elif char == ',' and paren_depth == 0 and bracket_depth == 0 and brace_depth == 0:\n",
    "            params.append(current_param.strip())\n",
    "            current_param = ''\n",
    "            continue\n",
    "        current_param += char\n",
    "    \n",
    "    if current_param.strip():\n",
    "        params.append(current_param.strip())\n",
    "    \n",
    "    # Return as L for easier manipulation\n",
    "    return L(params).filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_single_line_signature(\n",
    "    sig_line: str  # Single-line function signature\n",
    ") -> dict:  # Parsed components of the signature\n",
    "    \"Parse a single-line function signature into its components\"\n",
    "    func_match = re.match(r'^(\\s*)(def|async def)\\s+(\\w+)\\s*\\((.*?)\\)(\\s*(?:->\\s*[^:]+)?)\\s*:\\s*(.*)$', sig_line)\n",
    "    if not func_match:\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        'indent': func_match.group(1),\n",
    "        'def_keyword': func_match.group(2),\n",
    "        'func_name': func_match.group(3),\n",
    "        'params_str': func_match.group(4),\n",
    "        'return_type': func_match.group(5),\n",
    "        'existing_comment': func_match.group(6).strip()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_param_todo_comment(\n",
    "    param_name: str,  # Parameter name\n",
    "    result: DocmentsCheckResult,  # Check result with type hint and doc info\n",
    "    existing_comment: str = \"\"  # Existing comment text (without #)\n",
    ") -> str:  # TODO comment to add\n",
    "    \"Generate appropriate TODO comment for a parameter based on what's missing\"\n",
    "    has_type_hint = result.params_with_type_hints.get(param_name, False)\n",
    "    has_doc = result.params_documented.get(param_name, False)\n",
    "    \n",
    "    if not has_type_hint and not has_doc:\n",
    "        # Missing both type hint and description\n",
    "        return \"TODO: Add type hint and description\"\n",
    "    elif not has_type_hint and has_doc:\n",
    "        # Has description but missing type hint\n",
    "        if existing_comment:\n",
    "            # Check if TODO for type hint already exists\n",
    "            if \"TODO: Add type hint\" in existing_comment or \"TODO:Add type hint\" in existing_comment:\n",
    "                return existing_comment  # Don't add duplicate TODO\n",
    "            else:\n",
    "                return f\"{existing_comment} - TODO: Add type hint\"\n",
    "        else:\n",
    "            return \"TODO: Add type hint\"\n",
    "    elif has_type_hint and not has_doc:\n",
    "        # Has type hint but missing description\n",
    "        return \"TODO: Add description\"\n",
    "    else:\n",
    "        # This shouldn't happen if we're being asked to generate a comment\n",
    "        return existing_comment if existing_comment else \"TODO: Verify documentation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_return_todo_comment(\n",
    "    result: DocmentsCheckResult,  # Check result with type hint and doc info\n",
    "    existing_comment: str = \"\"  # Existing comment text (without #)\n",
    ") -> str:  # TODO comment to add\n",
    "    \"Generate appropriate TODO comment for return value based on what's missing\"\n",
    "    has_type_hint = result.return_has_type_hint\n",
    "    has_doc = result.return_documented\n",
    "    \n",
    "    if not has_type_hint and not has_doc:\n",
    "        # Missing both type hint and description\n",
    "        return \"TODO: Add type hint and return description\"\n",
    "    elif not has_type_hint and has_doc:\n",
    "        # Has description but missing type hint\n",
    "        if existing_comment:\n",
    "            # Check if TODO for type hint already exists\n",
    "            if \"TODO: Add type hint\" in existing_comment or \"TODO:Add type hint\" in existing_comment:\n",
    "                return existing_comment  # Don't add duplicate TODO\n",
    "            else:\n",
    "                return f\"{existing_comment} - TODO: Add type hint\"\n",
    "        else:\n",
    "            return \"TODO: Add type hint\"\n",
    "    elif has_type_hint and not has_doc:\n",
    "        # Has type hint but missing description\n",
    "        return \"TODO: Add return description\"\n",
    "    else:\n",
    "        # This shouldn't happen if we're being asked to generate a comment\n",
    "        return existing_comment if existing_comment else \"TODO: Verify description\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def build_fixed_single_line_function(\n",
    "    parsed: dict,  # Parsed signature components\n",
    "    params: List[str],  # Individual parameter strings\n",
    "    result: DocmentsCheckResult  # Check result with missing params info\n",
    ") -> List[str]:  # Lines of fixed function signature\n",
    "    \"Build a fixed single-line function with documentation comments\"\n",
    "    fixed_lines = []\n",
    "    indent = parsed['indent']\n",
    "    \n",
    "    # Start the function definition\n",
    "    fixed_lines.append(f\"{indent}{parsed['def_keyword']} {parsed['func_name']}(\")\n",
    "    \n",
    "    # Add parameters with comments as needed\n",
    "    for i, param in enumerate(params):\n",
    "        # Use patch method to get parameter name\n",
    "        param_name = result.get_param_name(param)\n",
    "        \n",
    "        # Use patch method to check if needs fixing\n",
    "        if result.needs_param_fix(param_name):\n",
    "            todo_comment = generate_param_todo_comment(param_name, result)\n",
    "            if i < len(params) - 1:\n",
    "                fixed_lines.append(f\"{indent}    {param},  # {todo_comment}\")\n",
    "            else:\n",
    "                fixed_lines.append(f\"{indent}    {param}  # {todo_comment}\")\n",
    "        else:\n",
    "            if i < len(params) - 1:\n",
    "                fixed_lines.append(f\"{indent}    {param},\")\n",
    "            else:\n",
    "                fixed_lines.append(f\"{indent}    {param}\")\n",
    "    \n",
    "    # Handle return type and existing comment\n",
    "    return_type = parsed['return_type']\n",
    "    existing_comment = parsed['existing_comment']\n",
    "    \n",
    "    # For single-line conversions, check if return needs fixing\n",
    "    if return_type:\n",
    "        if 'return' in result.missing_params or 'return' in result.params_missing_type_hints:\n",
    "            if existing_comment:\n",
    "                # Parse existing comment\n",
    "                comment_text = existing_comment[1:].strip() if existing_comment.startswith('#') else existing_comment\n",
    "                todo_comment = generate_return_todo_comment(result, comment_text)\n",
    "                fixed_lines.append(f\"{indent}){return_type}: # {todo_comment}\")\n",
    "            else:\n",
    "                # No existing comment\n",
    "                todo_comment = generate_return_todo_comment(result)\n",
    "                fixed_lines.append(f\"{indent}){return_type}:  # {todo_comment}\")\n",
    "        else:\n",
    "            # Return doesn't need fixing\n",
    "            if existing_comment:\n",
    "                if existing_comment.startswith('#'):\n",
    "                    fixed_lines.append(f\"{indent}){return_type}: {existing_comment}\")\n",
    "                else:\n",
    "                    fixed_lines.append(f\"{indent}){return_type}: # {existing_comment}\")\n",
    "            else:\n",
    "                fixed_lines.append(f\"{indent}){return_type}:\")\n",
    "    else:\n",
    "        # No return type but might need one\n",
    "        if 'return' in result.params_missing_type_hints:\n",
    "            if existing_comment:\n",
    "                comment_text = existing_comment[1:].strip() if existing_comment.startswith('#') else existing_comment\n",
    "                todo_comment = generate_return_todo_comment(result, comment_text)\n",
    "                fixed_lines.append(f\"{indent}): # {todo_comment}\")\n",
    "            else:\n",
    "                todo_comment = generate_return_todo_comment(result)\n",
    "                fixed_lines.append(f\"{indent}): # {todo_comment}\")\n",
    "        else:\n",
    "            # No return type needed\n",
    "            if existing_comment:\n",
    "                if existing_comment.startswith('#'):\n",
    "                    fixed_lines.append(f\"{indent}): {existing_comment}\")\n",
    "                else:\n",
    "                    fixed_lines.append(f\"{indent}): # {existing_comment}\")\n",
    "            else:\n",
    "                fixed_lines.append(f\"{indent}):\")\n",
    "    \n",
    "    return fixed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fix_multi_line_signature(\n",
    "    lines: List[str],  # All source lines\n",
    "    def_line_idx: int,  # Start of function definition\n",
    "    sig_end_idx: int,  # End of function signature\n",
    "    result: DocmentsCheckResult  # Check result with missing params info\n",
    ") -> List[str]:  # Fixed lines for the signature portion\n",
    "    \"Fix a multi-line function signature by adding parameter comments\"\n",
    "    fixed_lines = []\n",
    "    \n",
    "    for i in range(def_line_idx, sig_end_idx + 1):\n",
    "        line = lines[i]\n",
    "        line_stripped = line.strip()\n",
    "        \n",
    "        # More flexible parameter matching for multi-line signatures\n",
    "        # Match: whitespace + word + optional type annotation + optional comma/paren + optional whitespace + optional comment\n",
    "        param_match = re.match(r'^(\\s*)(\\w+)(\\s*(?::\\s*[^,\\)#]+)?)\\s*([,\\)]?)(\\s*)(?:#\\s*(.*))?$', line)\n",
    "        if param_match and i > def_line_idx and i < sig_end_idx:\n",
    "            # This is a parameter line (not the def line, not the return line)\n",
    "            indent = param_match.group(1)\n",
    "            param_name = param_match.group(2)\n",
    "            type_annotation = param_match.group(3) or ''\n",
    "            trailing_punct = param_match.group(4) or ''\n",
    "            trailing_space = param_match.group(5) or ''\n",
    "            existing_comment = param_match.group(6) or ''\n",
    "            \n",
    "            # Check if this parameter needs fixing (either missing docs or missing type hints)\n",
    "            needs_doc_fix = param_name in result.missing_params and param_name != 'self'\n",
    "            needs_type_hint_fix = param_name in result.params_missing_type_hints and param_name != 'self'\n",
    "            \n",
    "            if needs_doc_fix or needs_type_hint_fix:\n",
    "                todo_comment = generate_param_todo_comment(param_name, result, existing_comment)\n",
    "                # Only add the fixed line if the comment actually changed\n",
    "                if todo_comment != existing_comment:\n",
    "                    fixed_lines.append(f\"{indent}{param_name}{type_annotation}{trailing_punct}{trailing_space}  # {todo_comment}\")\n",
    "                else:\n",
    "                    # Comment didn't change, keep original line\n",
    "                    fixed_lines.append(line)\n",
    "            else:\n",
    "                fixed_lines.append(line)\n",
    "        else:\n",
    "            # Check for return type line\n",
    "            return_match = re.match(r'^(\\s*\\)\\s*->\\s*[^:#]+)\\s*:\\s*(.*)$', line)\n",
    "            if return_match and ('return' in result.missing_params or 'return' in result.params_missing_type_hints):\n",
    "                pre_colon = return_match.group(1)\n",
    "                after_colon = return_match.group(2).strip()\n",
    "                \n",
    "                if after_colon:\n",
    "                    # There's already a comment, generate appropriate TODO\n",
    "                    comment_text = after_colon[1:].strip() if after_colon.startswith('#') else after_colon\n",
    "                    todo_comment = generate_return_todo_comment(result, comment_text)\n",
    "                    # Only change if the comment actually changed\n",
    "                    if todo_comment != comment_text:\n",
    "                        fixed_lines.append(f\"{pre_colon}: # {todo_comment}\")\n",
    "                    else:\n",
    "                        fixed_lines.append(line)\n",
    "                else:\n",
    "                    # No comment, add full TODO\n",
    "                    todo_comment = generate_return_todo_comment(result)\n",
    "                    fixed_lines.append(f\"{pre_colon}:  # {todo_comment}\")\n",
    "            else:\n",
    "                fixed_lines.append(line)\n",
    "    \n",
    "    return fixed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fix_class_definition(\n",
    "    result: DocmentsCheckResult  # Check result with non-compliant class\n",
    ") -> str:  # Fixed source code with class docstring\n",
    "    \"Fix a class definition by adding a docstring if missing\"\n",
    "    lines = result.source.split('\\n')\n",
    "    fixed_lines = []\n",
    "    \n",
    "    # Find the class definition line\n",
    "    class_line_idx = -1\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith('class '):\n",
    "            class_line_idx = i\n",
    "            break\n",
    "    \n",
    "    if class_line_idx == -1:\n",
    "        return result.source\n",
    "    \n",
    "    # Add lines up to and including the class definition\n",
    "    for i in range(class_line_idx + 1):\n",
    "        fixed_lines.append(lines[i])\n",
    "    \n",
    "    # If missing docstring, add it after the class definition\n",
    "    if not result.has_docstring:\n",
    "        # Find the indentation of the first line after class definition\n",
    "        indent = '    '  # Default\n",
    "        if class_line_idx + 1 < len(lines):\n",
    "            next_line = lines[class_line_idx + 1]\n",
    "            # Match leading whitespace\n",
    "            indent_match = re.match(r'^(\\s*)', next_line)\n",
    "            indent = ifnone(indent_match.group(1) if indent_match else None, '    ')\n",
    "        \n",
    "        fixed_lines.append(f'{indent}\"TODO: Add class description\"')\n",
    "    \n",
    "    # Add the rest of the class body\n",
    "    for i in range(class_line_idx + 1, len(lines)):\n",
    "        fixed_lines.append(lines[i])\n",
    "    \n",
    "    return '\\n'.join(fixed_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def insert_function_docstring(\n",
    "    lines: List[str],  # Fixed function lines\n",
    "    def_line_idx: int,  # Index of function definition line\n",
    "    indent: str  # Base indentation for the function\n",
    ") -> List[str]:  # Lines with docstring inserted\n",
    "    \"Insert a TODO docstring after the function signature\"\n",
    "    # Find the signature end (last line before function body)\n",
    "    sig_end_idx = def_line_idx\n",
    "    for i in range(def_line_idx, len(lines)):\n",
    "        if lines[i].rstrip().endswith(':'):\n",
    "            sig_end_idx = i\n",
    "            break\n",
    "    \n",
    "    # Insert docstring after signature\n",
    "    result_lines = []\n",
    "    for i in range(sig_end_idx + 1):\n",
    "        result_lines.append(lines[i])\n",
    "    \n",
    "    # Add the docstring\n",
    "    docstring_indent = indent + '    '\n",
    "    result_lines.append(f'{docstring_indent}\"TODO: Add function description\"')\n",
    "    \n",
    "    # Add the rest of the function body\n",
    "    for i in range(sig_end_idx + 1, len(lines)):\n",
    "        result_lines.append(lines[i])\n",
    "    \n",
    "    return result_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fix_single_line_function(\n",
    "    lines: List[str],  # All source lines\n",
    "    def_line_idx: int,  # Index of function definition line\n",
    "    result: DocmentsCheckResult  # Check result with missing params info\n",
    ") -> List[str]:  # Fixed lines for the function\n",
    "    \"Fix a single-line function signature by converting to multi-line with parameter comments\"\n",
    "    # Parse the signature\n",
    "    parsed = parse_single_line_signature(lines[def_line_idx])\n",
    "    if not parsed:\n",
    "        return lines\n",
    "    \n",
    "    # Split parameters\n",
    "    params = split_parameters(parsed['params_str'])\n",
    "    \n",
    "    # Build the fixed function signature\n",
    "    fixed_signature_lines = build_fixed_single_line_function(parsed, params, result)\n",
    "    \n",
    "    # Combine with rest of function\n",
    "    fixed_lines = []\n",
    "    # Add lines before the function\n",
    "    for i in range(def_line_idx):\n",
    "        fixed_lines.append(lines[i])\n",
    "    \n",
    "    # Add the fixed signature\n",
    "    fixed_lines.extend(fixed_signature_lines)\n",
    "    \n",
    "    # Add docstring if missing\n",
    "    if not result.has_docstring:\n",
    "        fixed_lines = insert_function_docstring(fixed_lines, def_line_idx, parsed['indent'])\n",
    "    \n",
    "    # Add lines after the function definition\n",
    "    for i in range(def_line_idx + 1, len(lines)):\n",
    "        fixed_lines.append(lines[i])\n",
    "    \n",
    "    return fixed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fix_multi_line_function(\n",
    "    lines: List[str],  # All source lines\n",
    "    def_line_idx: int,  # Start of function definition\n",
    "    sig_end_idx: int,  # End of function signature\n",
    "    result: DocmentsCheckResult  # Check result with missing params info\n",
    ") -> List[str]:  # Fixed lines for the function\n",
    "    \"Fix a multi-line function signature by adding parameter comments\"\n",
    "    fixed_lines = []\n",
    "    \n",
    "    # Add lines before the function\n",
    "    for i in range(def_line_idx):\n",
    "        fixed_lines.append(lines[i])\n",
    "    \n",
    "    # Fix the signature\n",
    "    signature_lines = fix_multi_line_signature(lines, def_line_idx, sig_end_idx, result)\n",
    "    fixed_lines.extend(signature_lines)\n",
    "    \n",
    "    # Insert docstring if missing\n",
    "    if not result.has_docstring:\n",
    "        # Find the indentation of the function definition\n",
    "        indent_match = re.match(r'^(\\s*)', lines[def_line_idx])\n",
    "        base_indent = indent_match.group(1) if indent_match else ''\n",
    "        docstring_indent = base_indent + '    '\n",
    "        fixed_lines.append(f'{docstring_indent}\"TODO: Add function description\"')\n",
    "    \n",
    "    # Add rest of function body\n",
    "    for i in range(sig_end_idx + 1, len(lines)):\n",
    "        fixed_lines.append(lines[i])\n",
    "    \n",
    "    return fixed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_fixed_source(\n",
    "    result: DocmentsCheckResult  # Check result with non-compliant function\n",
    ") -> str:  # Fixed source code with placeholder documentation\n",
    "    \"Generate fixed source code for a non-compliant function or class\"\n",
    "    # Handle classes (including dataclasses)\n",
    "    if result.type == 'ClassDef':\n",
    "        return fix_class_definition(result)\n",
    "    \n",
    "    # Use the patch method to check if fixing is needed\n",
    "    if not result.needs_fixing():\n",
    "        return result.source\n",
    "    \n",
    "    lines = result.source.split('\\n')\n",
    "    \n",
    "    # Find the function definition line and signature end\n",
    "    def_line_idx, sig_end_idx = find_signature_boundaries(lines)\n",
    "    \n",
    "    if def_line_idx == -1:\n",
    "        return result.source\n",
    "    \n",
    "    # Choose the appropriate fix method based on signature type\n",
    "    if def_line_idx == sig_end_idx and (result.missing_params or result.params_missing_type_hints):\n",
    "        # Single-line signature that needs parameter fixing\n",
    "        fixed_lines = fix_single_line_function(lines, def_line_idx, result)\n",
    "    else:\n",
    "        # Multi-line signature \n",
    "        fixed_lines = fix_multi_line_function(lines, def_line_idx, sig_end_idx, result)\n",
    "    \n",
    "    return '\\n'.join(fixed_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fix_notebook(\n",
    "    nb_path: Path,  # Path to notebook to fix\n",
    "    dry_run: bool = False  # If True, show changes without saving\n",
    ") -> Dict[str, Any]:  # Summary of changes made\n",
    "    \"Fix non-compliant functions in a notebook by adding placeholder documentation\"\n",
    "    nb = read_nb(nb_path)\n",
    "    definitions = scan_notebook(nb_path)\n",
    "    \n",
    "    changes = {\n",
    "        'notebook': nb_path.name,\n",
    "        'definitions_fixed': [],\n",
    "        'cells_modified': []\n",
    "    }\n",
    "    \n",
    "    # Check each definition\n",
    "    for defn in definitions:\n",
    "        result = check_definition(defn)\n",
    "        \n",
    "        # Fix if non-compliant OR has missing type hints\n",
    "        needs_fixing = (not result.is_compliant or \n",
    "                       result.missing_params or \n",
    "                       result.params_missing_type_hints)\n",
    "        \n",
    "        if needs_fixing:\n",
    "            # Generate fixed source\n",
    "            fixed_source = generate_fixed_source(result)\n",
    "            \n",
    "            # Only proceed if the source actually changed\n",
    "            if fixed_source != result.source:\n",
    "                # Find and update the cell\n",
    "                cell_id = defn['cell_id']\n",
    "                for cell in nb.cells:\n",
    "                    if cell.get('id') == cell_id:\n",
    "                        # Replace the definition in the cell source\n",
    "                        old_source = result.source\n",
    "                        cell_source = cell.source\n",
    "                        \n",
    "                        # Find the definition in the cell and replace it\n",
    "                        if old_source in cell_source:\n",
    "                            new_cell_source = cell_source.replace(old_source, fixed_source)\n",
    "                            \n",
    "                            if not dry_run:\n",
    "                                cell.source = new_cell_source\n",
    "                            \n",
    "                            changes['definitions_fixed'].append(result.name)\n",
    "                            if cell_id not in changes['cells_modified']:\n",
    "                                changes['cells_modified'].append(cell_id)\n",
    "                            \n",
    "                            if dry_run:\n",
    "                                print(f\"\\nWould fix {result.name}:\")\n",
    "                                print(\"-\" * 40)\n",
    "                                print(fixed_source)\n",
    "                                print(\"-\" * 40)\n",
    "    \n",
    "    # Save the notebook if not dry run\n",
    "    if not dry_run and changes['definitions_fixed']:\n",
    "        write_nb(nb, nb_path)\n",
    "        # Fix grammar: use singular/plural based on count\n",
    "        count = len(changes['definitions_fixed'])\n",
    "        item_word = \"definition\" if count == 1 else \"definitions\"\n",
    "        print(f\"✅ Fixed {count} {item_word} in {nb_path.name}\")\n",
    "        for defn_name in changes['definitions_fixed']:\n",
    "            print(f\"   - {defn_name}\")\n",
    "    elif dry_run and changes['definitions_fixed']:\n",
    "        count = len(changes['definitions_fixed'])\n",
    "        item_word = \"definition\" if count == 1 else \"definitions\" \n",
    "        print(f\"\\n🔍 Dry run: Would fix {count} {item_word}\")\n",
    "    else:\n",
    "        print(f\"✅ All definitions in {nb_path.name} are already compliant\")\n",
    "    \n",
    "    return changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DocstringInfo(NamedTuple):\n",
    "    \"\"\"Information extracted from a docstring\"\"\"\n",
    "    description: str  # Main function description\n",
    "    params: Dict[str, str]  # Parameter name -> description\n",
    "    returns: Optional[str]  # Return description\n",
    "    docstring_type: str  # Type of docstring (google, numpy, sphinx, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def detect_docstring_style(\n",
    "    docstring: str  # Docstring text to analyze\n",
    ") -> str:  # Detected style: 'google', 'numpy', 'sphinx', 'docments', or 'unknown'\n",
    "    \"Detect the style of a docstring\"\n",
    "    if not docstring:\n",
    "        return 'unknown'\n",
    "    \n",
    "    docstring = docstring.strip()\n",
    "    \n",
    "    # Check for Google style (Args:, Returns:, etc.)\n",
    "    if re.search(r'(Args?|Arguments?|Parameters?|Params?|Returns?|Return|Yields?|Yield|Raises?|Raise|Note|Notes|Example|Examples):\\s*$', docstring, re.MULTILINE):\n",
    "        return 'google'\n",
    "    \n",
    "    # Check for NumPy style (Parameters\\n----------)\n",
    "    if re.search(r'(Parameters?|Returns?|Yields?|Raises?|See Also|Notes?|References?|Examples?)\\s*\\n\\s*-{3,}', docstring, re.MULTILINE):\n",
    "        return 'numpy'\n",
    "    \n",
    "    # Check for Sphinx style (:param, :type, :returns, etc.)\n",
    "    if re.search(r':(param|type|returns?|rtype|raises?|note|example)(\\s+\\w+)?:', docstring, re.MULTILINE):\n",
    "        return 'sphinx'\n",
    "    \n",
    "    # Check if already in docments style (very simple check)\n",
    "    # This would be harder to detect since docments puts docs inline\n",
    "    # For now, assume unknown if none of the above patterns match\n",
    "    return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_google_docstring(\n",
    "    docstring: str  # Google-style docstring text\n",
    ") -> DocstringInfo:  # Parsed docstring information\n",
    "    \"Parse a Google-style docstring\"\n",
    "    params = {}\n",
    "    returns = None\n",
    "    description_lines = []\n",
    "    \n",
    "    # Clean the docstring - remove triple quotes and normalize\n",
    "    cleaned = docstring.strip()\n",
    "    if cleaned.startswith('\"\"\"') or cleaned.startswith(\"'''\"):\n",
    "        cleaned = cleaned[3:]\n",
    "    if cleaned.endswith('\"\"\"') or cleaned.endswith(\"'''\"):\n",
    "        cleaned = cleaned[:-3]\n",
    "    \n",
    "    lines = cleaned.split('\\n')\n",
    "    current_section = None\n",
    "    current_param = None\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Check for section headers\n",
    "        if re.match(r'^(Args?|Arguments?|Parameters?|Params?):\\s*$', line):\n",
    "            current_section = 'params'\n",
    "            continue\n",
    "        elif re.match(r'^(Returns?|Return):\\s*$', line):\n",
    "            current_section = 'returns'\n",
    "            continue\n",
    "        elif re.match(r'^(Yields?|Yield|Raises?|Raise|Note|Notes|Example|Examples):\\s*$', line):\n",
    "            current_section = 'other'\n",
    "            continue\n",
    "        \n",
    "        # Process content based on current section\n",
    "        if current_section == 'params':\n",
    "            # Look for parameter definitions: \"param_name (type): description\"\n",
    "            param_match = re.match(r'^(\\w+)\\s*(?:\\([^)]+\\))?\\s*:\\s*(.+)$', line)\n",
    "            if param_match:\n",
    "                param_name = param_match.group(1)\n",
    "                param_desc = param_match.group(2)\n",
    "                params[param_name] = param_desc\n",
    "                current_param = param_name\n",
    "            elif current_param and line:\n",
    "                # Continuation of previous parameter description\n",
    "                params[current_param] += ' ' + line\n",
    "        elif current_section == 'returns':\n",
    "            if line:\n",
    "                if returns is None:\n",
    "                    returns = line\n",
    "                else:\n",
    "                    returns += ' ' + line\n",
    "        elif current_section is None:\n",
    "            # This is part of the main description\n",
    "            if line:\n",
    "                description_lines.append(line)\n",
    "    \n",
    "    description = ' '.join(description_lines)\n",
    "    return DocstringInfo(description, params, returns, 'google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_numpy_docstring(\n",
    "    docstring: str  # NumPy-style docstring text\n",
    ") -> DocstringInfo:  # Parsed docstring information\n",
    "    \"Parse a NumPy-style docstring\"\n",
    "    params = {}\n",
    "    returns = None\n",
    "    description_lines = []\n",
    "    \n",
    "    # Clean the docstring - remove triple quotes and normalize\n",
    "    cleaned = docstring.strip()\n",
    "    if cleaned.startswith('\"\"\"') or cleaned.startswith(\"'''\"):\n",
    "        cleaned = cleaned[3:]\n",
    "    if cleaned.endswith('\"\"\"') or cleaned.endswith(\"'''\"):\n",
    "        cleaned = cleaned[:-3]\n",
    "    \n",
    "    lines = cleaned.split('\\n')\n",
    "    current_section = None\n",
    "    current_param = None\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        line_stripped = line.strip()\n",
    "        \n",
    "        # Check for section headers (followed by dashes)\n",
    "        if i + 1 < len(lines) and re.match(r'^-{3,}$', lines[i + 1].strip()):\n",
    "            if re.match(r'^(Parameters?|Params?)$', line_stripped):\n",
    "                current_section = 'params'\n",
    "                continue\n",
    "            elif re.match(r'^(Returns?|Return)$', line_stripped):\n",
    "                current_section = 'returns'\n",
    "                continue\n",
    "            elif re.match(r'^(Yields?|Raises?|See Also|Notes?|References?|Examples?)$', line_stripped):\n",
    "                current_section = 'other'\n",
    "                continue\n",
    "        \n",
    "        # Skip the dashes line\n",
    "        if re.match(r'^-{3,}$', line_stripped):\n",
    "            continue\n",
    "        \n",
    "        # Process content based on current section\n",
    "        if current_section == 'params':\n",
    "            # Look for parameter definitions: \"param_name : type\" followed by description\n",
    "            param_match = re.match(r'^(\\w+)\\s*:\\s*(.+)$', line_stripped)\n",
    "            if param_match:\n",
    "                param_name = param_match.group(1)\n",
    "                # The type information is on the same line, description usually follows\n",
    "                current_param = param_name\n",
    "                params[param_name] = ''\n",
    "            elif current_param and line_stripped:\n",
    "                # Description line for the current parameter\n",
    "                if params[current_param]:\n",
    "                    params[current_param] += ' ' + line_stripped\n",
    "                else:\n",
    "                    params[current_param] = line_stripped\n",
    "        elif current_section == 'returns':\n",
    "            if line_stripped:\n",
    "                if returns is None:\n",
    "                    returns = line_stripped\n",
    "                else:\n",
    "                    returns += ' ' + line_stripped\n",
    "        elif current_section is None:\n",
    "            # This is part of the main description\n",
    "            if line_stripped:\n",
    "                description_lines.append(line_stripped)\n",
    "    \n",
    "    description = ' '.join(description_lines)\n",
    "    return DocstringInfo(description, params, returns, 'numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_sphinx_docstring(\n",
    "    docstring: str  # Sphinx-style docstring text\n",
    ") -> DocstringInfo:  # Parsed docstring information\n",
    "    \"Parse a Sphinx-style docstring\"\n",
    "    params = {}\n",
    "    returns = None\n",
    "    description_lines = []\n",
    "    \n",
    "    lines = docstring.split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Check for parameter definitions: \":param param_name: description\"\n",
    "        param_match = re.match(r'^:param\\s+(\\w+)\\s*:\\s*(.+)$', line)\n",
    "        if param_match:\n",
    "            param_name = param_match.group(1)\n",
    "            param_desc = param_match.group(2)\n",
    "            params[param_name] = param_desc\n",
    "            continue\n",
    "        \n",
    "        # Check for return definitions: \":returns: description\" or \":return: description\"\n",
    "        return_match = re.match(r'^:returns?\\s*:\\s*(.+)$', line)\n",
    "        if return_match:\n",
    "            returns = return_match.group(1)\n",
    "            continue\n",
    "        \n",
    "        # Skip other sphinx directives\n",
    "        if re.match(r'^:\\w+(\\s+\\w+)?:', line):\n",
    "            continue\n",
    "        \n",
    "        # This is part of the main description\n",
    "        if line:\n",
    "            description_lines.append(line)\n",
    "    \n",
    "    description = ' '.join(description_lines)\n",
    "    return DocstringInfo(description, params, returns, 'sphinx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extract_docstring_info(\n",
    "    source: str,  # Function source code\n",
    "    name: str  # Function name\n",
    ") -> Optional[DocstringInfo]:  # Extracted docstring information or None\n",
    "    \"Extract docstring information from function source code\"\n",
    "    try:\n",
    "        tree = ast.parse(source)\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "                if node.name == name and node.body:\n",
    "                    # Check if first statement is a docstring\n",
    "                    first_stmt = node.body[0]\n",
    "                    if (isinstance(first_stmt, ast.Expr) and \n",
    "                        isinstance(first_stmt.value, (ast.Str, ast.Constant))):\n",
    "                        \n",
    "                        # Extract docstring text\n",
    "                        if hasattr(first_stmt.value, 's'):\n",
    "                            docstring = first_stmt.value.s\n",
    "                        elif hasattr(first_stmt.value, 'value'):\n",
    "                            docstring = first_stmt.value.value\n",
    "                        else:\n",
    "                            return None\n",
    "                        \n",
    "                        if not isinstance(docstring, str):\n",
    "                            return None\n",
    "                        \n",
    "                        # Detect and parse the docstring style\n",
    "                        style = detect_docstring_style(docstring)\n",
    "                        \n",
    "                        if style == 'google':\n",
    "                            return parse_google_docstring(docstring)\n",
    "                        elif style == 'numpy':\n",
    "                            return parse_numpy_docstring(docstring)\n",
    "                        elif style == 'sphinx':\n",
    "                            return parse_sphinx_docstring(docstring)\n",
    "                        else:\n",
    "                            # Unknown style, return basic info\n",
    "                            return DocstringInfo(docstring.strip(), {}, None, 'unknown')\n",
    "                    break\n",
    "    except Exception:\n",
    "        return None\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_to_docments_format(\n",
    "    source: str,  # Original function source code\n",
    "    docstring_info: DocstringInfo,  # Extracted docstring information\n",
    "    result: DocmentsCheckResult  # Check result with missing params info\n",
    ") -> str:  # Converted source code in docments format\n",
    "    \"Convert function source to docments format using extracted docstring info\"\n",
    "    lines = source.split('\\n')\n",
    "    \n",
    "    # Find the function definition line and signature end\n",
    "    def_line_idx, sig_end_idx = find_signature_boundaries(lines)\n",
    "    \n",
    "    if def_line_idx == -1:\n",
    "        return source\n",
    "    \n",
    "    # Build the new function with docments-style documentation\n",
    "    fixed_lines = []\n",
    "    \n",
    "    # Add lines before the function\n",
    "    for i in range(def_line_idx):\n",
    "        fixed_lines.append(lines[i])\n",
    "    \n",
    "    # Convert single-line to multi-line if needed or fix existing multi-line\n",
    "    if def_line_idx == sig_end_idx:\n",
    "        # Single-line signature - convert to multi-line with docments comments\n",
    "        fixed_lines.extend(convert_single_line_to_docments(lines[def_line_idx], docstring_info, result))\n",
    "    else:\n",
    "        # Multi-line signature - add docments comments to existing structure\n",
    "        fixed_lines.extend(convert_multiline_to_docments(lines[def_line_idx:sig_end_idx+1], docstring_info, result))\n",
    "    \n",
    "    # Replace the original docstring with the description only\n",
    "    body_start_idx = sig_end_idx + 1\n",
    "    if body_start_idx < len(lines):\n",
    "        # Find the docstring in the function body and replace it\n",
    "        body_lines = lines[body_start_idx:]\n",
    "        new_body_lines = replace_docstring_in_body(body_lines, docstring_info.description, lines[def_line_idx])\n",
    "        fixed_lines.extend(new_body_lines)\n",
    "    \n",
    "    return '\\n'.join(fixed_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_single_line_to_docments(\n",
    "    sig_line: str,  # Single-line function signature\n",
    "    docstring_info: DocstringInfo,  # Extracted docstring information\n",
    "    result: DocmentsCheckResult  # Check result with missing params info\n",
    ") -> List[str]:  # Multi-line signature with docments comments\n",
    "    \"Convert single-line function signature to multi-line docments format\"\n",
    "    \n",
    "    # Parse the signature\n",
    "    parsed = parse_single_line_signature(sig_line)\n",
    "    if not parsed:\n",
    "        return [sig_line]\n",
    "    \n",
    "    # Split parameters\n",
    "    params = split_parameters(parsed['params_str'])\n",
    "    \n",
    "    # Build the new signature\n",
    "    fixed_lines = []\n",
    "    indent = parsed['indent']\n",
    "    \n",
    "    # Start the function definition\n",
    "    fixed_lines.append(f\"{indent}{parsed['def_keyword']} {parsed['func_name']}(\")\n",
    "    \n",
    "    # Add parameters with docments comments\n",
    "    for i, param in enumerate(params):\n",
    "        param_name = result.get_param_name(param)\n",
    "        \n",
    "        # Get documentation from the extracted docstring info\n",
    "        param_doc = docstring_info.params.get(param_name, '')\n",
    "        \n",
    "        if param_doc:\n",
    "            # Use the extracted documentation\n",
    "            if i < len(params) - 1:\n",
    "                fixed_lines.append(f\"{indent}    {param},  # {param_doc}\")\n",
    "            else:\n",
    "                fixed_lines.append(f\"{indent}    {param}  # {param_doc}\")\n",
    "        else:\n",
    "            # No documentation found, add TODO\n",
    "            if param_name in result.missing_params:\n",
    "                todo_comment = generate_param_todo_comment(param_name, result)\n",
    "                if i < len(params) - 1:\n",
    "                    fixed_lines.append(f\"{indent}    {param},  # {todo_comment}\")\n",
    "                else:\n",
    "                    fixed_lines.append(f\"{indent}    {param}  # {todo_comment}\")\n",
    "            else:\n",
    "                # Keep as is\n",
    "                if i < len(params) - 1:\n",
    "                    fixed_lines.append(f\"{indent}    {param},\")\n",
    "                else:\n",
    "                    fixed_lines.append(f\"{indent}    {param}\")\n",
    "    \n",
    "    # Handle return type\n",
    "    return_type = parsed['return_type']\n",
    "    if return_type and docstring_info.returns:\n",
    "        fixed_lines.append(f\"{indent}){return_type}:  # {docstring_info.returns}\")\n",
    "    elif return_type and 'return' in result.missing_params:\n",
    "        todo_comment = generate_return_todo_comment(result)\n",
    "        fixed_lines.append(f\"{indent}){return_type}:  # {todo_comment}\")\n",
    "    elif return_type:\n",
    "        fixed_lines.append(f\"{indent}){return_type}:\")\n",
    "    else:\n",
    "        fixed_lines.append(f\"{indent}):\")\n",
    "    \n",
    "    return fixed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_multiline_to_docments(\n",
    "    sig_lines: List[str],  # Multi-line function signature\n",
    "    docstring_info: DocstringInfo,  # Extracted docstring information\n",
    "    result: DocmentsCheckResult  # Check result with missing params info\n",
    ") -> List[str]:  # Multi-line signature with docments comments\n",
    "    \"Convert multi-line function signature to docments format\"\n",
    "    \n",
    "    fixed_lines = []\n",
    "    \n",
    "    for i, line in enumerate(sig_lines):\n",
    "        line_stripped = line.strip()\n",
    "        \n",
    "        # Check if this line contains a parameter\n",
    "        param_match = re.match(r'^(\\s*)(\\w+)(\\s*(?::\\s*[^,\\)#]+)?)\\s*([,\\)]?)(\\s*)(?:#\\s*(.*))?$', line)\n",
    "        if param_match and i > 0 and i < len(sig_lines) - 1:\n",
    "            # This is a parameter line\n",
    "            indent = param_match.group(1)\n",
    "            param_name = param_match.group(2)\n",
    "            type_annotation = param_match.group(3) or ''\n",
    "            trailing_punct = param_match.group(4) or ''\n",
    "            trailing_space = param_match.group(5) or ''\n",
    "            existing_comment = param_match.group(6) or ''\n",
    "            \n",
    "            # Get documentation from the extracted docstring info\n",
    "            param_doc = docstring_info.params.get(param_name, '')\n",
    "            \n",
    "            if param_doc:\n",
    "                # Use the extracted documentation\n",
    "                fixed_lines.append(f\"{indent}{param_name}{type_annotation}{trailing_punct}{trailing_space}  # {param_doc}\")\n",
    "            elif param_name in result.missing_params:\n",
    "                # No documentation found, add TODO\n",
    "                todo_comment = generate_param_todo_comment(param_name, result, existing_comment)\n",
    "                fixed_lines.append(f\"{indent}{param_name}{type_annotation}{trailing_punct}{trailing_space}  # {todo_comment}\")\n",
    "            else:\n",
    "                # Keep original\n",
    "                fixed_lines.append(line)\n",
    "        else:\n",
    "            # Check for return type line\n",
    "            return_match = re.match(r'^(\\s*\\)\\s*->\\s*[^:#]+)\\s*:\\s*(.*)$', line)\n",
    "            if return_match and docstring_info.returns:\n",
    "                pre_colon = return_match.group(1)\n",
    "                fixed_lines.append(f\"{pre_colon}:  # {docstring_info.returns}\")\n",
    "            elif return_match and 'return' in result.missing_params:\n",
    "                pre_colon = return_match.group(1)\n",
    "                existing_comment = return_match.group(2).strip()\n",
    "                comment_text = existing_comment[1:].strip() if existing_comment.startswith('#') else existing_comment\n",
    "                todo_comment = generate_return_todo_comment(result, comment_text)\n",
    "                fixed_lines.append(f\"{pre_colon}:  # {todo_comment}\")\n",
    "            else:\n",
    "                fixed_lines.append(line)\n",
    "    \n",
    "    return fixed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def replace_docstring_in_body(\n",
    "    body_lines: List[str],  # Function body lines\n",
    "    description: str,  # New description to use\n",
    "    def_line: str  # Function definition line for indentation\n",
    ") -> List[str]:  # Modified body lines\n",
    "    \"Replace the docstring in function body with a simple description\"\n",
    "    \n",
    "    # Find the indentation of the function definition\n",
    "    indent_match = re.match(r'^(\\s*)', def_line)\n",
    "    base_indent = indent_match.group(1) if indent_match else ''\n",
    "    docstring_indent = base_indent + '    '\n",
    "    \n",
    "    # Look for the docstring (first string literal after function definition)\n",
    "    docstring_found = False\n",
    "    result_lines = []\n",
    "    in_multiline_docstring = False\n",
    "    \n",
    "    for i, line in enumerate(body_lines):\n",
    "        line_stripped = line.strip()\n",
    "        \n",
    "        # If we haven't found the docstring yet and this line is not empty\n",
    "        if not docstring_found and line_stripped:\n",
    "            # Check if it starts a docstring\n",
    "            if line_stripped.startswith(('\"\"\"', \"'''\", '\"', \"'\")):\n",
    "                docstring_found = True\n",
    "                \n",
    "                # Check if it's a single-line docstring\n",
    "                if ((line_stripped.startswith('\"\"\"') and line_stripped.endswith('\"\"\"') and len(line_stripped) > 6) or\n",
    "                    (line_stripped.startswith(\"'''\") and line_stripped.endswith(\"'''\") and len(line_stripped) > 6) or\n",
    "                    (line_stripped.startswith('\"') and line_stripped.endswith('\"') and len(line_stripped) > 2 and not line_stripped.startswith('\"\"\"')) or\n",
    "                    (line_stripped.startswith(\"'\") and line_stripped.endswith(\"'\") and len(line_stripped) > 2 and not line_stripped.startswith(\"'''\"))):\n",
    "                    # Single-line docstring\n",
    "                    result_lines.append(f'{docstring_indent}\"{description}\"')\n",
    "                else:\n",
    "                    # Start of multi-line docstring\n",
    "                    in_multiline_docstring = True\n",
    "                    result_lines.append(f'{docstring_indent}\"{description}\"')\n",
    "            else:\n",
    "                # Not a docstring, keep the line\n",
    "                result_lines.append(line)\n",
    "        elif in_multiline_docstring:\n",
    "            # We're inside a multi-line docstring, check if this ends it\n",
    "            if line_stripped.endswith(('\"\"\"', \"'''\")):\n",
    "                in_multiline_docstring = False\n",
    "                # Skip this line (end of docstring)\n",
    "            # Skip all lines inside the multi-line docstring\n",
    "        else:\n",
    "            # Either we already processed the docstring or this is a regular line\n",
    "            result_lines.append(line)\n",
    "    \n",
    "    # If no docstring was found, add the description at the beginning\n",
    "    if not docstring_found:\n",
    "        result_lines.insert(0, f'{docstring_indent}\"{description}\"')\n",
    "    \n",
    "    return result_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_fixed_source_with_conversion(\n",
    "    result: DocmentsCheckResult  # Check result with non-compliant function\n",
    ") -> str:  # Fixed source code with converted documentation\n",
    "    \"Generate fixed source code, converting existing docstrings to docments format if possible\"\n",
    "    \n",
    "    # First, try to extract docstring information for conversion\n",
    "    docstring_info = extract_docstring_info(result.source, result.name)\n",
    "    \n",
    "    # If we found structured docstring info (not unknown), convert it\n",
    "    if (docstring_info and \n",
    "        docstring_info.docstring_type in ['google', 'numpy', 'sphinx'] and\n",
    "        (docstring_info.params or docstring_info.returns)):\n",
    "        try:\n",
    "            converted_source = convert_to_docments_format(result.source, docstring_info, result)\n",
    "            return converted_source\n",
    "        except Exception:\n",
    "            # Fallback to original fix if conversion fails\n",
    "            pass\n",
    "    \n",
    "    # Fallback to the original generate_fixed_source function\n",
    "    return generate_fixed_source(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fix_notebook_with_conversion(\n",
    "    nb_path: Path,  # Path to notebook to fix\n",
    "    dry_run: bool = False,  # If True, show changes without saving\n",
    "    convert_docstrings: bool = True  # If True, convert existing docstrings to docments format\n",
    ") -> Dict[str, Any]:  # Summary of changes made\n",
    "    \"Fix non-compliant functions in a notebook, optionally converting docstrings to docments format\"\n",
    "    nb = read_nb(nb_path)\n",
    "    definitions = scan_notebook(nb_path)\n",
    "    \n",
    "    changes = {\n",
    "        'notebook': nb_path.name,\n",
    "        'definitions_fixed': [],\n",
    "        'definitions_converted': [],\n",
    "        'cells_modified': []\n",
    "    }\n",
    "    \n",
    "    # Check each definition\n",
    "    for defn in definitions:\n",
    "        result = check_definition(defn)\n",
    "        \n",
    "        # Fix if non-compliant OR has missing type hints\n",
    "        needs_fixing = (not result.is_compliant or \n",
    "                       result.missing_params or \n",
    "                       result.params_missing_type_hints)\n",
    "        \n",
    "        if needs_fixing:\n",
    "            # Choose the appropriate fix method\n",
    "            if convert_docstrings:\n",
    "                fixed_source = generate_fixed_source_with_conversion(result)\n",
    "                \n",
    "                # Check if this was a conversion (has structured docstring info)\n",
    "                docstring_info = extract_docstring_info(result.source, result.name)\n",
    "                is_conversion = (docstring_info and \n",
    "                               docstring_info.docstring_type in ['google', 'numpy', 'sphinx'])\n",
    "            else:\n",
    "                fixed_source = generate_fixed_source(result)\n",
    "                is_conversion = False\n",
    "            \n",
    "            # Only proceed if the source actually changed\n",
    "            if fixed_source != result.source:\n",
    "                # Find and update the cell\n",
    "                cell_id = defn['cell_id']\n",
    "                for cell in nb.cells:\n",
    "                    if cell.get('id') == cell_id:\n",
    "                        # Replace the definition in the cell source\n",
    "                        old_source = result.source\n",
    "                        cell_source = cell.source\n",
    "                        \n",
    "                        # Find the definition in the cell and replace it\n",
    "                        if old_source in cell_source:\n",
    "                            new_cell_source = cell_source.replace(old_source, fixed_source)\n",
    "                            \n",
    "                            if not dry_run:\n",
    "                                cell.source = new_cell_source\n",
    "                            \n",
    "                            changes['definitions_fixed'].append(result.name)\n",
    "                            if is_conversion:\n",
    "                                changes['definitions_converted'].append(result.name)\n",
    "                            \n",
    "                            if cell_id not in changes['cells_modified']:\n",
    "                                changes['cells_modified'].append(cell_id)\n",
    "                            \n",
    "                            if dry_run:\n",
    "                                action = \"convert and fix\" if is_conversion else \"fix\"\n",
    "                                print(f\"\\nWould {action} {result.name}:\")\n",
    "                                print(\"-\" * 40)\n",
    "                                print(fixed_source)\n",
    "                                print(\"-\" * 40)\n",
    "    \n",
    "    # Save the notebook if not dry run\n",
    "    if not dry_run and changes['definitions_fixed']:\n",
    "        write_nb(nb, nb_path)\n",
    "        \n",
    "        # Report results\n",
    "        fixed_count = len(changes['definitions_fixed'])\n",
    "        converted_count = len(changes['definitions_converted'])\n",
    "        \n",
    "        if converted_count > 0:\n",
    "            print(f\"✅ Fixed {fixed_count} definitions in {nb_path.name} ({converted_count} converted from other docstring styles)\")\n",
    "        else:\n",
    "            print(f\"✅ Fixed {fixed_count} definitions in {nb_path.name}\")\n",
    "        \n",
    "        for defn_name in changes['definitions_fixed']:\n",
    "            action = \"converted & fixed\" if defn_name in changes['definitions_converted'] else \"fixed\"\n",
    "            print(f\"   - {defn_name} ({action})\")\n",
    "    elif dry_run and changes['definitions_fixed']:\n",
    "        fixed_count = len(changes['definitions_fixed'])\n",
    "        converted_count = len(changes['definitions_converted'])\n",
    "        \n",
    "        if converted_count > 0:\n",
    "            print(f\"\\n🔍 Dry run: Would fix {fixed_count} definitions ({converted_count} converted from other docstring styles)\")\n",
    "        else:\n",
    "            print(f\"\\n🔍 Dry run: Would fix {fixed_count} definitions\")\n",
    "    else:\n",
    "        print(f\"✅ All definitions in {nb_path.name} are already compliant\")\n",
    "    \n",
    "    return changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docstring 1: google\n",
      "Docstring 2: numpy\n",
      "Docstring 3: sphinx\n",
      "Docstring 4: unknown\n",
      "\n",
      "==================================================\n",
      "Google style parsing:\n",
      "Description: Calculate the sum of two numbers.\n",
      "Parameters: {'x': 'The first number to add', 'y': 'The second number to add'}\n",
      "Returns: int: The sum of x and y\n",
      "\n",
      "==================================================\n",
      "NumPy style parsing:\n",
      "Description: Calculate the sum of two numbers.\n",
      "Parameters: {'x': 'The first number to add', 'y': 'The second number to add'}\n",
      "Returns: int The sum of x and y\n"
     ]
    }
   ],
   "source": [
    "# Test docstring style detection\n",
    "test_docstrings = [\n",
    "    # Google style\n",
    "    '''\"\"\"Calculate the sum of two numbers.\n",
    "    \n",
    "    Args:\n",
    "        x (int): The first number to add\n",
    "        y (int): The second number to add\n",
    "        \n",
    "    Returns:\n",
    "        int: The sum of x and y\n",
    "    \"\"\"''',\n",
    "    \n",
    "    # NumPy style  \n",
    "    '''\"\"\"Calculate the sum of two numbers.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : int\n",
    "        The first number to add\n",
    "    y : int  \n",
    "        The second number to add\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The sum of x and y\n",
    "    \"\"\"''',\n",
    "    \n",
    "    # Sphinx style\n",
    "    '''\"\"\"Calculate the sum of two numbers.\n",
    "    \n",
    "    :param x: The first number to add\n",
    "    :param y: The second number to add\n",
    "    :returns: The sum of x and y\n",
    "    \"\"\"''',\n",
    "    \n",
    "    # Unknown style\n",
    "    '''\"\"\"Just a simple description without structured parameters.\"\"\"'''\n",
    "]\n",
    "\n",
    "for i, docstring in enumerate(test_docstrings):\n",
    "    style = detect_docstring_style(docstring)\n",
    "    print(f\"Docstring {i+1}: {style}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Test parsing Google style\n",
    "google_docstring = test_docstrings[0]\n",
    "google_info = parse_google_docstring(google_docstring)\n",
    "print(\"Google style parsing:\")\n",
    "print(f\"Description: {google_info.description}\")\n",
    "print(f\"Parameters: {google_info.params}\")\n",
    "print(f\"Returns: {google_info.returns}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Test parsing NumPy style\n",
    "numpy_docstring = test_docstrings[1]\n",
    "numpy_info = parse_numpy_docstring(numpy_docstring)\n",
    "print(\"NumPy style parsing:\")\n",
    "print(f\"Description: {numpy_info.description}\")\n",
    "print(f\"Parameters: {numpy_info.params}\")\n",
    "print(f\"Returns: {numpy_info.returns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Google-style function:\n",
      "def calculate_sum(x: int, y: int) -> int:\n",
      "    \"\"\"Calculate the sum of two numbers.\n",
      "\n",
      "    Args:\n",
      "        x (int): The first number to add\n",
      "        y (int): The second number to add\n",
      "\n",
      "    Returns:\n",
      "        int: The sum of x and y\n",
      "    \"\"\"\n",
      "    return x + y\n",
      "\n",
      "Compliant: False\n",
      "Missing: ['x', 'y', 'return']\n",
      "\n",
      "Converted to docments style:\n",
      "def calculate_sum(\n",
      "    x: int,  # The first number to add\n",
      "    y: int  # The second number to add\n",
      ") -> int:  # int: The sum of x and y\n",
      "    \"Calculate the sum of two numbers.\"\n",
      "    return x + y\n",
      "\n",
      "After conversion - Compliant: True\n",
      "After conversion - Missing: []\n"
     ]
    }
   ],
   "source": [
    "# Test full conversion on a Google-style function\n",
    "google_function_source = '''def calculate_sum(x: int, y: int) -> int:\n",
    "    \"\"\"Calculate the sum of two numbers.\n",
    "    \n",
    "    Args:\n",
    "        x (int): The first number to add\n",
    "        y (int): The second number to add\n",
    "        \n",
    "    Returns:\n",
    "        int: The sum of x and y\n",
    "    \"\"\"\n",
    "    return x + y'''\n",
    "\n",
    "# Create a test definition\n",
    "test_def_google = {\n",
    "    'name': 'calculate_sum',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': google_function_source,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [\n",
    "        {'name': 'x', 'annotation': 'int'},\n",
    "        {'name': 'y', 'annotation': 'int'}\n",
    "    ],\n",
    "    'returns': 'int'\n",
    "}\n",
    "\n",
    "# Check it\n",
    "result_google = check_definition(test_def_google)\n",
    "print(\"Original Google-style function:\")\n",
    "print(google_function_source)\n",
    "print(f\"\\nCompliant: {result_google.is_compliant}\")\n",
    "print(f\"Missing: {result_google.missing_params}\")\n",
    "\n",
    "# Convert it\n",
    "if not result_google.is_compliant:\n",
    "    converted = generate_fixed_source_with_conversion(result_google)\n",
    "    print(\"\\nConverted to docments style:\")\n",
    "    print(converted)\n",
    "    \n",
    "    # Verify the converted version is compliant\n",
    "    test_def_converted = {\n",
    "        'name': 'calculate_sum',\n",
    "        'type': 'FunctionDef',\n",
    "        'source': converted,\n",
    "        'notebook': 'test.ipynb',\n",
    "        'args': [\n",
    "            {'name': 'x', 'annotation': 'int'},\n",
    "            {'name': 'y', 'annotation': 'int'}\n",
    "        ],\n",
    "        'returns': 'int'\n",
    "    }\n",
    "    \n",
    "    result_converted = check_definition(test_def_converted)\n",
    "    print(f\"\\nAfter conversion - Compliant: {result_converted.is_compliant}\")\n",
    "    print(f\"After conversion - Missing: {result_converted.missing_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing conversion with debug output:\n",
      "Extracted docstring_info: DocstringInfo(description='Calculate the sum of two numbers.', params={'x': 'The first number to add', 'y': 'The second number to add'}, returns='int: The sum of x and y', docstring_type='google')\n",
      "Docstring type: google\n",
      "Params: {'x': 'The first number to add', 'y': 'The second number to add'}\n",
      "\\nConverted result:\n",
      "def calculate_sum(\n",
      "    x: int,  # The first number to add\n",
      "    y: int  # The second number to add\n",
      ") -> int:  # int: The sum of x and y\n",
      "    \"Calculate the sum of two numbers.\"\n",
      "    return x + y\n"
     ]
    }
   ],
   "source": [
    "# Test with debug output to see what's happening\n",
    "google_function_source = '''def calculate_sum(x: int, y: int) -> int:\n",
    "    \"\"\"Calculate the sum of two numbers.\n",
    "    \n",
    "    Args:\n",
    "        x (int): The first number to add\n",
    "        y (int): The second number to add\n",
    "        \n",
    "    Returns:\n",
    "        int: The sum of x and y\n",
    "    \"\"\"\n",
    "    return x + y'''\n",
    "\n",
    "test_def_google = {\n",
    "    'name': 'calculate_sum',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': google_function_source,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [\n",
    "        {'name': 'x', 'annotation': 'int'},\n",
    "        {'name': 'y', 'annotation': 'int'}\n",
    "    ],\n",
    "    'returns': 'int'\n",
    "}\n",
    "\n",
    "result_google = check_definition(test_def_google)\n",
    "print(\"Testing conversion with debug output:\")\n",
    "\n",
    "# First test the docstring extraction\n",
    "docstring_info = extract_docstring_info(result_google.source, result_google.name)\n",
    "print(f\"Extracted docstring_info: {docstring_info}\")\n",
    "print(f\"Docstring type: {docstring_info.docstring_type if docstring_info else 'None'}\")\n",
    "print(f\"Params: {docstring_info.params if docstring_info else 'None'}\")\n",
    "\n",
    "# Now test the conversion\n",
    "converted = generate_fixed_source_with_conversion(result_google)\n",
    "print(\"\\\\nConverted result:\")\n",
    "print(converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug AST parsing:\n",
      "AST parsing successful\n",
      "Found node: Module\n",
      "Found node: FunctionDef\n",
      "  Function name: calculate_sum\n",
      "  Function body has 2 statements\n",
      "  First statement type: Expr\n",
      "  Expression value type: Constant\n",
      "  Found docstring (s): 'Calculate the sum of two numbers.\n",
      "\n",
      "    Args:\n",
      "     ...'\n",
      "\n",
      "==================================================\n",
      "Testing docstring style detection:\n",
      "Detected style: google\n",
      "\n",
      "Testing parsing:\n",
      "Parsed info: DocstringInfo(description='Calculate the sum of two numbers.', params={'x': 'The first number to add', 'y': 'The second number to add'}, returns='int: The sum of x and y', docstring_type='google')\n"
     ]
    }
   ],
   "source": [
    "# Debug the docstring extraction step by step\n",
    "print(\"Debug AST parsing:\")\n",
    "\n",
    "try:\n",
    "    tree = ast.parse(google_function_source)\n",
    "    print(\"AST parsing successful\")\n",
    "    \n",
    "    for node in ast.walk(tree):\n",
    "        print(f\"Found node: {type(node).__name__}\")\n",
    "        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "            print(f\"  Function name: {node.name}\")\n",
    "            if node.name == 'calculate_sum' and node.body:\n",
    "                print(f\"  Function body has {len(node.body)} statements\")\n",
    "                first_stmt = node.body[0]\n",
    "                print(f\"  First statement type: {type(first_stmt).__name__}\")\n",
    "                \n",
    "                if isinstance(first_stmt, ast.Expr):\n",
    "                    print(f\"  Expression value type: {type(first_stmt.value).__name__}\")\n",
    "                    if isinstance(first_stmt.value, (ast.Str, ast.Constant)):\n",
    "                        # Extract docstring text\n",
    "                        if hasattr(first_stmt.value, 's'):\n",
    "                            docstring = first_stmt.value.s\n",
    "                            print(f\"  Found docstring (s): '{docstring[:50]}...'\")\n",
    "                        elif hasattr(first_stmt.value, 'value'):\n",
    "                            docstring = first_stmt.value.value\n",
    "                            print(f\"  Found docstring (value): '{docstring[:50]}...'\")\n",
    "                        else:\n",
    "                            print(\"  No docstring text found\")\n",
    "                    else:\n",
    "                        print(f\"  Expression value is not a string: {first_stmt.value}\")\n",
    "                else:\n",
    "                    print(f\"  First statement is not an expression\")\n",
    "            break\n",
    "except Exception as e:\n",
    "    print(f\"Error in AST parsing: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Test the detect_docstring_style function directly\n",
    "docstring_text = '''\"\"\"Calculate the sum of two numbers.\n",
    "\n",
    "Args:\n",
    "    x (int): The first number to add\n",
    "    y (int): The second number to add\n",
    "    \n",
    "Returns:\n",
    "    int: The sum of x and y\n",
    "\"\"\"'''\n",
    "\n",
    "print(\"Testing docstring style detection:\")\n",
    "style = detect_docstring_style(docstring_text)\n",
    "print(f\"Detected style: {style}\")\n",
    "\n",
    "print(\"\\nTesting parsing:\")\n",
    "if style == 'google':\n",
    "    parsed = parse_google_docstring(docstring_text)\n",
    "    print(f\"Parsed info: {parsed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing extract_docstring_info with debug:\n",
      "Result: DocstringInfo(description='Calculate the sum of two numbers.', params={'x': 'The first number to add', 'y': 'The second number to add'}, returns='int: The sum of x and y', docstring_type='google')\n",
      "\\nTesting step by step:\n",
      "Source: 'def calculate_sum(x: int, y: int) -> int:\\n    \"\"\"Calculate the sum of two numbers.\\n\\n    Args:\\n      '\n",
      "Name: calculate_sum\n",
      "DocstringInfo works: DocstringInfo(description='test', params={}, returns=None, docstring_type='test')\n"
     ]
    }
   ],
   "source": [
    "# Test the extraction with debug output\n",
    "print(\"Testing extract_docstring_info with debug:\")\n",
    "docstring_info = extract_docstring_info(result_google.source, result_google.name)\n",
    "print(f\"Result: {docstring_info}\")\n",
    "\n",
    "# Also test it step by step to see where it fails\n",
    "print(\"\\\\nTesting step by step:\")\n",
    "print(f\"Source: {repr(result_google.source[:100])}\")\n",
    "print(f\"Name: {result_google.name}\")\n",
    "\n",
    "# Test if DocstringInfo is available\n",
    "try:\n",
    "    test_info = DocstringInfo(\"test\", {}, None, \"test\")\n",
    "    print(f\"DocstringInfo works: {test_info}\")\n",
    "except Exception as e:\n",
    "    print(f\"DocstringInfo error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 COMPREHENSIVE DOCSTRING CONVERSION TEST\n",
      "============================================================\n",
      "\n",
      "📝 Test 1: Google Example\n",
      "----------------------------------------\n",
      "Original compliance: ❌ Non-compliant\n",
      "Missing: ['name', 'age', 'active', 'return']\n",
      "Docstring type: google\n",
      "Parameters found: ['name', 'age', 'active']\n",
      "Return info: Yes\n",
      "After conversion: ✅ Compliant\n",
      "\n",
      "🔄 Converted function:\n",
      "def google_example(\n",
      "    name: str,  # The user's full name\n",
      "    age: int,  # The user's age in years\n",
      "    active: bool = True  # Whether the user is currently active\n",
      ") -> str:  # str: A formatted profile string\n",
      "    \"Generate a user profile string.\"\n",
      "    return f\"{name} ({age}) - {'Active' if active else 'Inactive'}\"\n",
      "\n",
      "📝 Test 2: Numpy Example\n",
      "----------------------------------------\n",
      "Original compliance: ❌ Non-compliant\n",
      "Missing: ['data', 'threshold', 'return']\n",
      "Docstring type: numpy\n",
      "Parameters found: ['data', 'threshold']\n",
      "Return info: Yes\n",
      "After conversion: ✅ Compliant\n",
      "\n",
      "🔄 Converted function:\n",
      "def numpy_example(\n",
      "    data: list,  # Input data to process\n",
      "    threshold: float = 0.5  # Minimum threshold value\n",
      ") -> dict:  # dict Processing results with statistics\n",
      "    \"Process data based on threshold.\"\n",
      "    return {'processed': len(data), 'threshold': threshold}\n",
      "\n",
      "📝 Test 3: Sphinx Example\n",
      "----------------------------------------\n",
      "Original compliance: ❌ Non-compliant\n",
      "Missing: ['filename', 'encoding', 'return']\n",
      "Docstring type: sphinx\n",
      "Parameters found: ['filename', 'encoding']\n",
      "Return info: Yes\n",
      "After conversion: ✅ Compliant\n",
      "\n",
      "🔄 Converted function:\n",
      "def sphinx_example(\n",
      "    filename: str,  # Path to the file to read\n",
      "    encoding: str = 'utf-8'  # Text encoding to use\n",
      ") -> bool:  # True if file is valid, False otherwise\n",
      "    \"Read and validate a file.\"\n",
      "    return True\n",
      "\n",
      "🎉 All tests completed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive test of all docstring formats and conversion\n",
    "print(\"🧪 COMPREHENSIVE DOCSTRING CONVERSION TEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test functions with different docstring formats\n",
    "test_functions = [\n",
    "    # Google style\n",
    "    {\n",
    "        'name': 'google_example',\n",
    "        'source': '''def google_example(name: str, age: int, active: bool = True) -> str:\n",
    "    \"\"\"Generate a user profile string.\n",
    "    \n",
    "    Args:\n",
    "        name (str): The user's full name\n",
    "        age (int): The user's age in years\n",
    "        active (bool): Whether the user is currently active\n",
    "        \n",
    "    Returns:\n",
    "        str: A formatted profile string\n",
    "    \"\"\"\n",
    "    return f\"{name} ({age}) - {'Active' if active else 'Inactive'}\"''',\n",
    "        'args': [\n",
    "            {'name': 'name', 'annotation': 'str'},\n",
    "            {'name': 'age', 'annotation': 'int'},\n",
    "            {'name': 'active', 'annotation': 'bool'}\n",
    "        ],\n",
    "        'returns': 'str'\n",
    "    },\n",
    "    \n",
    "    # NumPy style\n",
    "    {\n",
    "        'name': 'numpy_example',\n",
    "        'source': '''def numpy_example(data: list, threshold: float = 0.5) -> dict:\n",
    "    \"\"\"Process data based on threshold.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : list\n",
    "        Input data to process\n",
    "    threshold : float\n",
    "        Minimum threshold value\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Processing results with statistics\n",
    "    \"\"\"\n",
    "    return {'processed': len(data), 'threshold': threshold}''',\n",
    "        'args': [\n",
    "            {'name': 'data', 'annotation': 'list'},\n",
    "            {'name': 'threshold', 'annotation': 'float'}\n",
    "        ],\n",
    "        'returns': 'dict'\n",
    "    },\n",
    "    \n",
    "    # Sphinx style\n",
    "    {\n",
    "        'name': 'sphinx_example',\n",
    "        'source': '''def sphinx_example(filename: str, encoding: str = 'utf-8') -> bool:\n",
    "    \"\"\"Read and validate a file.\n",
    "    \n",
    "    :param filename: Path to the file to read\n",
    "    :param encoding: Text encoding to use\n",
    "    :returns: True if file is valid, False otherwise\n",
    "    \"\"\"\n",
    "    return True''',\n",
    "        'args': [\n",
    "            {'name': 'filename', 'annotation': 'str'},\n",
    "            {'name': 'encoding', 'annotation': 'str'}\n",
    "        ],\n",
    "        'returns': 'bool'\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, func_info in enumerate(test_functions, 1):\n",
    "    print(f\"\\n📝 Test {i}: {func_info['name'].replace('_', ' ').title()}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Create test definition\n",
    "    test_def = {\n",
    "        'name': func_info['name'],\n",
    "        'type': 'FunctionDef',\n",
    "        'source': func_info['source'],\n",
    "        'notebook': 'test.ipynb',\n",
    "        'args': func_info['args'],\n",
    "        'returns': func_info['returns']\n",
    "    }\n",
    "    \n",
    "    # Check compliance\n",
    "    result = check_definition(test_def)\n",
    "    print(f\"Original compliance: {'✅ Compliant' if result.is_compliant else '❌ Non-compliant'}\")\n",
    "    if not result.is_compliant:\n",
    "        print(f\"Missing: {result.missing_params}\")\n",
    "    \n",
    "    # Extract docstring info\n",
    "    docstring_info = extract_docstring_info(result.source, result.name)\n",
    "    if docstring_info:\n",
    "        print(f\"Docstring type: {docstring_info.docstring_type}\")\n",
    "        print(f\"Parameters found: {list(docstring_info.params.keys())}\")\n",
    "        print(f\"Return info: {'Yes' if docstring_info.returns else 'No'}\")\n",
    "    \n",
    "    # Convert\n",
    "    converted = generate_fixed_source_with_conversion(result)\n",
    "    \n",
    "    # Verify converted version\n",
    "    test_def_converted = test_def.copy()\n",
    "    test_def_converted['source'] = converted\n",
    "    result_converted = check_definition(test_def_converted)\n",
    "    \n",
    "    print(f\"After conversion: {'✅ Compliant' if result_converted.is_compliant else '❌ Non-compliant'}\")\n",
    "    \n",
    "    print(\"\\n🔄 Converted function:\")\n",
    "    print(converted)\n",
    "\n",
    "print(f\"\\n🎉 All tests completed!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original function:\n",
      "def bad_function(x, y, z=10):\n",
      "    result = x + y + z\n",
      "    return result\n",
      "\n",
      "Compliant: False\n",
      "Missing: ['x', 'y', 'z']\n",
      "\n",
      "Fixed function:\n",
      "def bad_function(\n",
      "    \"TODO: Add function description\"\n",
      "    x,  # TODO: Add type hint and description\n",
      "    y,  # TODO: Add type hint and description\n",
      "    z=10  # TODO: Add type hint and description\n",
      "): # TODO: Add type hint\n",
      "    result = x + y + z\n",
      "    return result\n"
     ]
    }
   ],
   "source": [
    "# Test fixing a non-compliant function\n",
    "from cjm_nbdev_docments.core import check_definition\n",
    "\n",
    "# Create a test function\n",
    "test_source = '''def bad_function(x, y, z=10):\n",
    "    result = x + y + z\n",
    "    return result'''\n",
    "\n",
    "# Create a mock definition\n",
    "test_def = {\n",
    "    'name': 'bad_function',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': test_source,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [\n",
    "        {'name': 'x', 'annotation': None},\n",
    "        {'name': 'y', 'annotation': None},\n",
    "        {'name': 'z', 'annotation': None}\n",
    "    ],\n",
    "    'returns': None\n",
    "}\n",
    "\n",
    "# Check it\n",
    "result = check_definition(test_def)\n",
    "print(\"Original function:\")\n",
    "print(result.source)\n",
    "print(f\"\\nCompliant: {result.is_compliant}\")\n",
    "print(f\"Missing: {result.missing_params}\")\n",
    "\n",
    "# Fix it\n",
    "fixed = generate_fixed_source(result)\n",
    "print(\"\\nFixed function:\")\n",
    "print(fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original function:\n",
      "def typed_function(name: str, age: int) -> str:\n",
      "    return f\"{name} is {age} years old\"\n",
      "\n",
      "Compliant: False\n",
      "Missing: ['name', 'age', 'return']\n",
      "\n",
      "Fixed function:\n",
      "def typed_function(\n",
      "    \"TODO: Add function description\"\n",
      "    name: str,  # TODO: Add description\n",
      "    age: int  # TODO: Add description\n",
      ") -> str:  # TODO: Add return description\n",
      "    return f\"{name} is {age} years old\"\n"
     ]
    }
   ],
   "source": [
    "# Test with a function that has return type\n",
    "test_source2 = '''def typed_function(name: str, age: int) -> str:\n",
    "    return f\"{name} is {age} years old\"'''\n",
    "\n",
    "test_def2 = {\n",
    "    'name': 'typed_function',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': test_source2,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [\n",
    "        {'name': 'name', 'annotation': 'str'},\n",
    "        {'name': 'age', 'annotation': 'int'}\n",
    "    ],\n",
    "    'returns': 'str'\n",
    "}\n",
    "\n",
    "result2 = check_definition(test_def2)\n",
    "print(\"Original function:\")\n",
    "print(result2.source)\n",
    "print(f\"\\nCompliant: {result2.is_compliant}\")\n",
    "print(f\"Missing: {result2.missing_params}\")\n",
    "\n",
    "fixed2 = generate_fixed_source(result2)\n",
    "print(\"\\nFixed function:\")\n",
    "print(fixed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 0: 'def bad_function(x, y, z=10):'\n",
      "Line 1: '    result = x + y + z'\n",
      "Line 2: '    return result'\n"
     ]
    }
   ],
   "source": [
    "# Debug the line matching\n",
    "test_source = '''def bad_function(x, y, z=10):\n",
    "    result = x + y + z\n",
    "    return result'''\n",
    "\n",
    "lines = test_source.split('\\n')\n",
    "for i, line in enumerate(lines):\n",
    "    print(f\"Line {i}: {repr(line)}\")\n",
    "    param_match = re.match(r'^(\\s*)(\\w+)(\\s*(?::\\s*[^,\\)#]+)?(?:\\s*=\\s*[^,\\)#]+)?)\\s*([,\\)])\\s*$', line)\n",
    "    if param_match:\n",
    "        print(f\"  -> Matched param: {param_match.groups()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original function:\n",
      "def get_export_cells(\n",
      "    nb_path: Path  # Path to the notebook file\n",
      ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
      "    nb = read_nb(nb_path)\n",
      "    export_cells = []\n",
      "\n",
      "    for cell in nb.cells:\n",
      "        if cell.cell_type == 'code' and cell.source:\n",
      "            lines = cell.source.split('\\n')\n",
      "            for line in lines:\n",
      "                if line.strip().startswith('#| export'):\n",
      "                    export_cells.append({\n",
      "                        'cell_id': cell.get('id', None),\n",
      "                        'source': cell.source,\n",
      "                        'idx': cell.idx_ if hasattr(cell, 'idx_') else None\n",
      "                    })\n",
      "                    break\n",
      "\n",
      "    return export_cells\n",
      "\\nCompliant: False\n",
      "Missing: []\n",
      "\\nFixed function:\n",
      "def get_export_cells(\n",
      "    nb_path: Path  # Path to the notebook file\n",
      ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
      "    \"TODO: Add function description\"\n",
      "    nb = read_nb(nb_path)\n",
      "    export_cells = []\n",
      "\n",
      "    for cell in nb.cells:\n",
      "        if cell.cell_type == 'code' and cell.source:\n",
      "            lines = cell.source.split('\\n')\n",
      "            for line in lines:\n",
      "                if line.strip().startswith('#| export'):\n",
      "                    export_cells.append({\n",
      "                        'cell_id': cell.get('id', None),\n",
      "                        'source': cell.source,\n",
      "                        'idx': cell.idx_ if hasattr(cell, 'idx_') else None\n",
      "                    })\n",
      "                    break\n",
      "\n",
      "    return export_cells\n"
     ]
    }
   ],
   "source": [
    "# Test the problematic case you described\n",
    "problematic_source = '''def get_export_cells(\n",
    "    nb_path: Path  # Path to the notebook file\n",
    ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
    "    nb = read_nb(nb_path)\n",
    "    export_cells = []\n",
    "    \n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == 'code' and cell.source:\n",
    "            lines = cell.source.split('\\\\n')\n",
    "            for line in lines:\n",
    "                if line.strip().startswith('#| export'):\n",
    "                    export_cells.append({\n",
    "                        'cell_id': cell.get('id', None),\n",
    "                        'source': cell.source,\n",
    "                        'idx': cell.idx_ if hasattr(cell, 'idx_') else None\n",
    "                    })\n",
    "                    break\n",
    "    \n",
    "    return export_cells'''\n",
    "\n",
    "# Create test definition (missing docstring only)\n",
    "test_def = {\n",
    "    'name': 'get_export_cells',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': problematic_source,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [{'name': 'nb_path', 'annotation': 'Path'}],\n",
    "    'returns': 'List[Dict[str, Any]]'\n",
    "}\n",
    "\n",
    "result = check_definition(test_def)\n",
    "print(\"Original function:\")\n",
    "print(result.source)\n",
    "print(f\"\\\\nCompliant: {result.is_compliant}\")\n",
    "print(f\"Missing: {result.missing_params}\")\n",
    "\n",
    "if not result.is_compliant:\n",
    "    fixed = generate_fixed_source(result)\n",
    "    print(\"\\\\nFixed function:\")\n",
    "    print(fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines with indices:\n",
      "0: 'def get_export_cells('\n",
      "1: '    nb_path: Path  # Path to the notebook file'\n",
      "2: ') -> List[Dict[str, Any]]:  # List of cells with export directives'\n",
      "3: '    nb = read_nb(nb_path)'\n",
      "4: '    export_cells = []'\n",
      "5: ''\n",
      "6: '    for cell in nb.cells:'\n",
      "    ^ Line 6 ends with ':'\n",
      "7: \"        if cell.cell_type == 'code' and cell.source:\"\n",
      "    ^ Line 7 ends with ':'\n",
      "8: \"            lines = cell.source.split('\\\\n')\"\n",
      "9: '            for line in lines:'\n",
      "    ^ Line 9 ends with ':'\n",
      "10: \"                if line.strip().startswith('#| export'):\"\n",
      "    ^ Line 10 ends with ':'\n",
      "11: '                    export_cells.append({'\n",
      "12: \"                        'cell_id': cell.get('id', None),\"\n",
      "13: \"                        'source': cell.source,\"\n",
      "14: \"                        'idx': cell.idx_ if hasattr(cell, 'idx_') else None\"\n",
      "15: '                    })'\n",
      "16: '                    break'\n",
      "17: ''\n",
      "18: '    return export_cells'\n",
      "Function starts at line 0\n",
      "Signature ends at line 6\n",
      "\\nFunction definition: line 0\n",
      "Signature end: line 6\n",
      "Multi-line signature: True\n"
     ]
    }
   ],
   "source": [
    "# Debug the signature detection\n",
    "problematic_source = '''def get_export_cells(\n",
    "    nb_path: Path  # Path to the notebook file\n",
    ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
    "    nb = read_nb(nb_path)\n",
    "    export_cells = []\n",
    "\n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == 'code' and cell.source:\n",
    "            lines = cell.source.split('\\\\n')\n",
    "            for line in lines:\n",
    "                if line.strip().startswith('#| export'):\n",
    "                    export_cells.append({\n",
    "                        'cell_id': cell.get('id', None),\n",
    "                        'source': cell.source,\n",
    "                        'idx': cell.idx_ if hasattr(cell, 'idx_') else None\n",
    "                    })\n",
    "                    break\n",
    "\n",
    "    return export_cells'''\n",
    "\n",
    "lines = problematic_source.split('\\n')\n",
    "print(\"Lines with indices:\")\n",
    "for i, line in enumerate(lines):\n",
    "    print(f\"{i}: {repr(line)}\")\n",
    "    if line.rstrip().endswith(':'):\n",
    "        print(f\"    ^ Line {i} ends with ':'\")\n",
    "\n",
    "# Find signature end\n",
    "def_line_idx = None\n",
    "sig_end_idx = None\n",
    "for i, line in enumerate(lines):\n",
    "    if line.strip().startswith(('def ', 'async def ')):\n",
    "        def_line_idx = i\n",
    "        print(f\"Function starts at line {i}\")\n",
    "    if def_line_idx is not None and line.rstrip().endswith(':'):\n",
    "        sig_end_idx = i\n",
    "        print(f\"Signature ends at line {i}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\\\nFunction definition: line {def_line_idx}\")\n",
    "print(f\"Signature end: line {sig_end_idx}\")\n",
    "print(f\"Multi-line signature: {def_line_idx != sig_end_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function starts at line 0\n",
      "Line 0: paren_count 0 -> 1, ends with ':': False\n",
      "Line 1: paren_count 1 -> 1, ends with ':': False\n",
      "Line 2: paren_count 1 -> 0, ends with ':': False\n",
      "Line 3: paren_count 0 -> 0, ends with ':': False\n",
      "Line 4: paren_count 0 -> 0, ends with ':': False\n",
      "Line 5: paren_count 0 -> 0, ends with ':': False\n",
      "Line 6: paren_count 0 -> 0, ends with ':': True\n",
      "Signature ends at line 6\n",
      "\n",
      "Corrected detection:\n",
      "Function definition: line 0\n",
      "Signature end: line 6\n",
      "\n",
      "Fixed function:\n",
      "def get_export_cells(\n",
      "    nb_path: Path  # Path to the notebook file\n",
      ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
      "    \"TODO: Add function description\"\n",
      "    nb = read_nb(nb_path)\n",
      "    export_cells = []\n",
      "\n",
      "    for cell in nb.cells:\n",
      "        if cell.cell_type == 'code' and cell.source:\n",
      "            lines = cell.source.split('\\n')\n",
      "            for line in lines:\n",
      "                if line.strip().startswith('#| export'):\n",
      "                    export_cells.append({\n",
      "                        'cell_id': cell.get('id', None),\n",
      "                        'source': cell.source,\n",
      "                        'idx': cell.idx_ if hasattr(cell, 'idx_') else None\n",
      "                    })\n",
      "                    break\n",
      "\n",
      "    return export_cells\n"
     ]
    }
   ],
   "source": [
    "# Test the corrected signature detection\n",
    "lines = problematic_source.split('\\n')\n",
    "\n",
    "def_line_idx = None\n",
    "sig_end_idx = None\n",
    "paren_count = 0\n",
    "in_signature = False\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    if line.strip().startswith(('def ', 'async def ')):\n",
    "        def_line_idx = i\n",
    "        in_signature = True\n",
    "        print(f\"Function starts at line {i}\")\n",
    "        \n",
    "    if in_signature:\n",
    "        # Count parentheses to find where signature ends\n",
    "        old_count = paren_count\n",
    "        paren_count += line.count('(') - line.count(')')\n",
    "        print(f\"Line {i}: paren_count {old_count} -> {paren_count}, ends with ':': {line.rstrip().endswith(':')}\")\n",
    "        \n",
    "        # If we're back to balanced parens and line ends with colon, signature is done\n",
    "        if paren_count == 0 and line.rstrip().endswith(':'):\n",
    "            sig_end_idx = i\n",
    "            print(f\"Signature ends at line {i}\")\n",
    "            break\n",
    "\n",
    "print(f\"\\nCorrected detection:\")\n",
    "print(f\"Function definition: line {def_line_idx}\")\n",
    "print(f\"Signature end: line {sig_end_idx}\")\n",
    "\n",
    "# Test the fix\n",
    "result = check_definition(test_def)\n",
    "if not result.is_compliant:\n",
    "    fixed = generate_fixed_source(result)\n",
    "    print(\"\\nFixed function:\")\n",
    "    print(fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1 Debug:\n",
      "Compliant: False\n",
      "Missing params: ['nb_path']\n",
      "Params documented: {'nb_path': False}\n",
      "Original == Fixed: False\n",
      "\n",
      "Original:\n",
      "'def get_export_cells(\\n    nb_path: Path  \\n) -> List[Dict[str, Any]]:  # List of cells with export directives\\n    \"Extract all code cells from a notebook that have export directives\"\\n    nb = read_nb(nb_path)\\n    return []'\n",
      "\n",
      "Fixed:\n",
      "'def get_export_cells(\\n    nb_path: Path    # TODO: Add description\\n) -> List[Dict[str, Any]]:  # List of cells with export directives\\n    \"Extract all code cells from a notebook that have export directives\"\\n    nb = read_nb(nb_path)\\n    return []'\n"
     ]
    }
   ],
   "source": [
    "# Debug scenario 1 - should need fixing but claims to be compliant\n",
    "scenario1_source = '''def get_export_cells(\n",
    "    nb_path: Path  \n",
    ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
    "    \"Extract all code cells from a notebook that have export directives\"\n",
    "    nb = read_nb(nb_path)\n",
    "    return []'''\n",
    "\n",
    "test_def1 = {\n",
    "    'name': 'get_export_cells',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': scenario1_source,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [{'name': 'nb_path', 'annotation': 'Path'}],\n",
    "    'returns': 'List[Dict[str, Any]]'\n",
    "}\n",
    "\n",
    "result1 = check_definition(test_def1)\n",
    "print(\"Scenario 1 Debug:\")\n",
    "print(f\"Compliant: {result1.is_compliant}\")\n",
    "print(f\"Missing params: {result1.missing_params}\")\n",
    "print(f\"Params documented: {result1.params_documented}\")\n",
    "\n",
    "# Test what the autofix generates\n",
    "if not result1.is_compliant:\n",
    "    fixed1 = generate_fixed_source(result1)\n",
    "    print(f\"Original == Fixed: {scenario1_source == fixed1}\")\n",
    "    print(\"\\nOriginal:\")\n",
    "    print(repr(scenario1_source))\n",
    "    print(\"\\nFixed:\")\n",
    "    print(repr(fixed1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 4 Debug:\n",
      "Compliant: False\n",
      "Missing params: ['nb_path', 'fake_test_path']\n",
      "Params documented: {'nb_path': False, 'fake_test_path': False}\n",
      "\n",
      "Fixed version:\n",
      "def get_export_cells(\n",
      "    nb_path: Path,    # TODO: Add description\n",
      "    fake_test_path: Path  # TODO: Add description\n",
      ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
      "    \"Extract all code cells from a notebook that have export directives\"\n",
      "    nb = read_nb(nb_path)\n",
      "    return []\n",
      "\n",
      "After fix - Compliant: True\n",
      "After fix - Missing: []\n"
     ]
    }
   ],
   "source": [
    "# Debug scenario 4 - only partially fixes\n",
    "scenario4_source = '''def get_export_cells(\n",
    "    nb_path: Path,  \n",
    "    fake_test_path: Path\n",
    ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
    "    \"Extract all code cells from a notebook that have export directives\"\n",
    "    nb = read_nb(nb_path)\n",
    "    return []'''\n",
    "\n",
    "test_def4 = {\n",
    "    'name': 'get_export_cells',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': scenario4_source,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [\n",
    "        {'name': 'nb_path', 'annotation': 'Path'},\n",
    "        {'name': 'fake_test_path', 'annotation': 'Path'}\n",
    "    ],\n",
    "    'returns': 'List[Dict[str, Any]]'\n",
    "}\n",
    "\n",
    "result4 = check_definition(test_def4)\n",
    "print(\"Scenario 4 Debug:\")\n",
    "print(f\"Compliant: {result4.is_compliant}\")\n",
    "print(f\"Missing params: {result4.missing_params}\")\n",
    "print(f\"Params documented: {result4.params_documented}\")\n",
    "\n",
    "if not result4.is_compliant:\n",
    "    fixed4 = generate_fixed_source(result4)\n",
    "    print(\"\\nFixed version:\")\n",
    "    print(fixed4)\n",
    "    \n",
    "    # Check if all missing params were actually fixed\n",
    "    test_def4_fixed = {\n",
    "        'name': 'get_export_cells',\n",
    "        'type': 'FunctionDef',\n",
    "        'source': fixed4,\n",
    "        'notebook': 'test.ipynb',\n",
    "        'args': [\n",
    "            {'name': 'nb_path', 'annotation': 'Path'},\n",
    "            {'name': 'fake_test_path', 'annotation': 'Path'}\n",
    "        ],\n",
    "        'returns': 'List[Dict[str, Any]]'\n",
    "    }\n",
    "    \n",
    "    result4_after_fix = check_definition(test_def4_fixed)\n",
    "    print(f\"\\nAfter fix - Compliant: {result4_after_fix.is_compliant}\")\n",
    "    print(f\"After fix - Missing: {result4_after_fix.missing_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines in scenario 4:\n",
      "0: 'def get_export_cells('\n",
      "   -> NO MATCH\n",
      "1: '    nb_path: Path,  '\n",
      "   -> MATCHED: param=nb_path\n",
      "2: '    fake_test_path: Path'\n",
      "   -> NO MATCH\n",
      "3: ') -> List[Dict[str, Any]]:  # List of cells with export directives'\n",
      "   -> NO MATCH\n",
      "4: '    \"Extract all code cells from a notebook that have export directives\"'\n",
      "   -> NO MATCH\n",
      "5: '    nb = read_nb(nb_path)'\n",
      "   -> MATCHED: param=nb\n",
      "6: '    return []'\n",
      "   -> NO MATCH\n",
      "\n",
      "==================================================\n",
      "Testing simpler parameter detection:\n",
      "Line 1 contains 'nb_path': '    nb_path: Path,  '\n",
      "Line 2 contains 'fake_test_path': '    fake_test_path: Path'\n",
      "Line 5 contains 'nb_path': '    nb = read_nb(nb_path)'\n"
     ]
    }
   ],
   "source": [
    "# Debug the parameter matching regex\n",
    "scenario4_lines = scenario4_source.split('\\n')\n",
    "print(\"Lines in scenario 4:\")\n",
    "for i, line in enumerate(scenario4_lines):\n",
    "    print(f\"{i}: {repr(line)}\")\n",
    "    # Test the regex that should match parameter lines\n",
    "    param_match = re.match(r'^(\\s*)(\\w+)(\\s*(?::\\s*[^,\\)#]+)?(?:\\s*=\\s*[^,\\)#]+)?)\\s*([,\\)])\\s*$', line)\n",
    "    if param_match:\n",
    "        print(f\"   -> MATCHED: param={param_match.group(2)}\")\n",
    "    else:\n",
    "        print(f\"   -> NO MATCH\")\n",
    "        \n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Let's also test a simpler pattern\n",
    "print(\"Testing simpler parameter detection:\")\n",
    "for i, line in enumerate(scenario4_lines):\n",
    "    # Look for lines that contain parameter names we know about\n",
    "    if 'nb_path' in line:\n",
    "        print(f\"Line {i} contains 'nb_path': {repr(line)}\")\n",
    "    if 'fake_test_path' in line:\n",
    "        print(f\"Line {i} contains 'fake_test_path': {repr(line)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1 results:\n",
      "(Run this after the previous debug cell)\n",
      "\n",
      "Testing what causes false positive 'fixed' reports...\n"
     ]
    }
   ],
   "source": [
    "# Check the scenario 1 output\n",
    "print(\"Scenario 1 results:\")\n",
    "print(\"(Run this after the previous debug cell)\")\n",
    "\n",
    "# Also let's see what the fix_notebook function does\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a mock scenario to test fix_notebook behavior\n",
    "print(\"\\nTesting what causes false positive 'fixed' reports...\")\n",
    "\n",
    "# Let's see if the issue is in the fix_notebook function's change detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 4 with improved fix:\n",
      "Missing params: ['nb_path', 'fake_test_path']\n",
      "\n",
      "Improved fixed version:\n",
      "def get_export_cells(\n",
      "    nb_path: Path,    # TODO: Add description\n",
      "    fake_test_path: Path  # TODO: Add description\n",
      ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
      "    \"Extract all code cells from a notebook that have export directives\"\n",
      "    nb = read_nb(nb_path)\n",
      "    return []\n",
      "\n",
      "After improved fix - Compliant: True\n",
      "After improved fix - Missing: []\n"
     ]
    }
   ],
   "source": [
    "# Test the improved version on scenario 4\n",
    "result4 = check_definition(test_def4)\n",
    "print(\"Scenario 4 with improved fix:\")\n",
    "print(f\"Missing params: {result4.missing_params}\")\n",
    "\n",
    "fixed4_new = generate_fixed_source(result4)\n",
    "print(\"\\nImproved fixed version:\")\n",
    "print(fixed4_new)\n",
    "\n",
    "# Check if it's now fully compliant\n",
    "test_def4_new_fixed = {\n",
    "    'name': 'get_export_cells',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': fixed4_new,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [\n",
    "        {'name': 'nb_path', 'annotation': 'Path'},\n",
    "        {'name': 'fake_test_path', 'annotation': 'Path'}\n",
    "    ],\n",
    "    'returns': 'List[Dict[str, Any]]'\n",
    "}\n",
    "\n",
    "result4_new_after_fix = check_definition(test_def4_new_fixed)\n",
    "print(f\"\\nAfter improved fix - Compliant: {result4_new_after_fix.is_compliant}\")\n",
    "print(f\"After improved fix - Missing: {result4_new_after_fix.missing_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1 Debug:\n",
      "Compliant: False\n",
      "Missing params: ['nb_path']\n",
      "Params documented: {'nb_path': False}\n",
      "\n",
      "Fixed version:\n",
      "def get_export_cells(\n",
      "    nb_path: Path    # TODO: Add description\n",
      ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
      "    \"Extract all code cells from a notebook that have export directives\"\n",
      "    nb = read_nb(nb_path)\n",
      "    return []\n",
      "\n",
      "Original == Fixed: False\n",
      "Changes detected correctly\n"
     ]
    }
   ],
   "source": [
    "# Test scenario 1 - single param, no comma\n",
    "scenario1_source = '''def get_export_cells(\n",
    "    nb_path: Path  \n",
    ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
    "    \"Extract all code cells from a notebook that have export directives\"\n",
    "    nb = read_nb(nb_path)\n",
    "    return []'''\n",
    "\n",
    "test_def1 = {\n",
    "    'name': 'get_export_cells',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': scenario1_source,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [{'name': 'nb_path', 'annotation': 'Path'}],\n",
    "    'returns': 'List[Dict[str, Any]]'\n",
    "}\n",
    "\n",
    "result1 = check_definition(test_def1)\n",
    "print(\"Scenario 1 Debug:\")\n",
    "print(f\"Compliant: {result1.is_compliant}\")\n",
    "print(f\"Missing params: {result1.missing_params}\")\n",
    "print(f\"Params documented: {result1.params_documented}\")\n",
    "\n",
    "if not result1.is_compliant:\n",
    "    fixed1 = generate_fixed_source(result1)\n",
    "    print(\"\\nFixed version:\")\n",
    "    print(fixed1)\n",
    "    \n",
    "    # Check the change detection\n",
    "    print(f\"\\nOriginal == Fixed: {scenario1_source == fixed1}\")\n",
    "    if scenario1_source != fixed1:\n",
    "        print(\"Changes detected correctly\")\n",
    "    else:\n",
    "        print(\"ERROR: No changes made but function was not compliant!\")\n",
    "else:\n",
    "    print(\"Function is already compliant - should not be 'fixed'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing change detection logic:\n",
      "Function: get_export_cells\n",
      "Old source in new source: False\n",
      "Sources equal: False\n",
      "Would report as fixed: False\n"
     ]
    }
   ],
   "source": [
    "# Check if the issue is in fix_notebook's change detection\n",
    "# Let me examine the fix_notebook logic by looking at what it considers a \"change\"\n",
    "\n",
    "def debug_fix_notebook_logic(definition, old_source, new_source):\n",
    "    \"\"\"Debug what fix_notebook considers a change\"\"\"\n",
    "    print(f\"Function: {definition['name']}\")\n",
    "    print(f\"Old source in new source: {old_source in new_source}\")\n",
    "    print(f\"Sources equal: {old_source == new_source}\")\n",
    "    print(f\"Would report as fixed: {old_source in new_source and old_source != new_source}\")\n",
    "    \n",
    "# Test with our scenarios\n",
    "print(\"Testing change detection logic:\")\n",
    "\n",
    "# Scenario 1 - might be wrongly detected as changed\n",
    "result1 = check_definition(test_def1)\n",
    "if not result1.is_compliant:\n",
    "    fixed1 = generate_fixed_source(result1)\n",
    "    debug_fix_notebook_logic(test_def1, result1.source, fixed1)\n",
    "else:\n",
    "    print(\"Scenario 1: Already compliant, no fix needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOUR Scenario 1 (should be compliant):\n",
      "Compliant: True\n",
      "Missing: []\n",
      "✅ Correctly identified as compliant\n",
      "\n",
      "============================================================\n",
      "YOUR Scenario 2 (should need fixing):\n",
      "Compliant: False\n",
      "Missing: ['fake_test_path']\n",
      "✅ Correctly identified as non-compliant\n",
      "Fixed to:\n",
      "def get_export_cells(\n",
      "    nb_path: Path,  # Path to the notebook file\n",
      "    fake_test_path: Path   # TODO: Add description\n",
      ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
      "    \"Extract all code cells from a notebook that have export directives\"\n",
      "    nb = read_nb(nb_path)\n",
      "    return []\n"
     ]
    }
   ],
   "source": [
    "# Test the EXACT scenarios from your original issue\n",
    "\n",
    "# Your scenario 1 - this should be compliant, no fix needed\n",
    "your_scenario1 = '''def get_export_cells(\n",
    "    nb_path: Path  # Path to the notebook file\n",
    ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
    "    \"Extract all code cells from a notebook that have export directives\"\n",
    "    nb = read_nb(nb_path)\n",
    "    export_cells = []\n",
    "    return export_cells'''\n",
    "\n",
    "test_your_s1 = {\n",
    "    'name': 'get_export_cells',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': your_scenario1,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [{'name': 'nb_path', 'annotation': 'Path'}],\n",
    "    'returns': 'List[Dict[str, Any]]'\n",
    "}\n",
    "\n",
    "result_s1 = check_definition(test_your_s1)\n",
    "print(\"YOUR Scenario 1 (should be compliant):\")\n",
    "print(f\"Compliant: {result_s1.is_compliant}\")\n",
    "print(f\"Missing: {result_s1.missing_params}\")\n",
    "\n",
    "if not result_s1.is_compliant:\n",
    "    print(\"❌ ERROR: This should be compliant but isn't!\")\n",
    "    fixed_s1 = generate_fixed_source(result_s1)\n",
    "    print(\"Would be 'fixed' to:\")\n",
    "    print(fixed_s1)\n",
    "else:\n",
    "    print(\"✅ Correctly identified as compliant\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Your scenario 2 - missing one param doc, should be fixed\n",
    "your_scenario2 = '''def get_export_cells(\n",
    "    nb_path: Path,  # Path to the notebook file\n",
    "    fake_test_path: Path \n",
    ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
    "    \"Extract all code cells from a notebook that have export directives\"\n",
    "    nb = read_nb(nb_path)\n",
    "    return []'''\n",
    "\n",
    "test_your_s2 = {\n",
    "    'name': 'get_export_cells',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': your_scenario2,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [\n",
    "        {'name': 'nb_path', 'annotation': 'Path'},\n",
    "        {'name': 'fake_test_path', 'annotation': 'Path'}\n",
    "    ],\n",
    "    'returns': 'List[Dict[str, Any]]'\n",
    "}\n",
    "\n",
    "result_s2 = check_definition(test_your_s2)\n",
    "print(\"YOUR Scenario 2 (should need fixing):\")\n",
    "print(f\"Compliant: {result_s2.is_compliant}\")\n",
    "print(f\"Missing: {result_s2.missing_params}\")\n",
    "\n",
    "if not result_s2.is_compliant:\n",
    "    print(\"✅ Correctly identified as non-compliant\")\n",
    "    fixed_s2 = generate_fixed_source(result_s2)\n",
    "    print(\"Fixed to:\")\n",
    "    print(fixed_s2)\n",
    "else:\n",
    "    print(\"❌ ERROR: This should need fixing but was marked compliant!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge case - single line with existing return comment:\n",
      "Compliant: False\n",
      "Missing: ['nb_path']\n",
      "\n",
      "Fixed version (should preserve existing comment with TODO):\n",
      "def get_export_cells(\n",
      "    nb_path: Path  # TODO: Add description\n",
      ") -> List[Dict[str, Any]]: # List of cells with export directives\n",
      "    \"Extract all code cells from a notebook that have export directives\"\n",
      "    nb = read_nb(nb_path)\n",
      "    return []\n",
      "\n",
      "After fix - Compliant: True\n",
      "After fix - Missing: []\n"
     ]
    }
   ],
   "source": [
    "# Test the edge case with existing return comment\n",
    "edge_case_source = '''def get_export_cells(nb_path: Path) -> List[Dict[str, Any]]:  # List of cells with export directives\n",
    "    \"Extract all code cells from a notebook that have export directives\"\n",
    "    nb = read_nb(nb_path)\n",
    "    return []'''\n",
    "\n",
    "test_edge_case = {\n",
    "    'name': 'get_export_cells',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': edge_case_source,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [{'name': 'nb_path', 'annotation': 'Path'}],\n",
    "    'returns': 'List[Dict[str, Any]]'\n",
    "}\n",
    "\n",
    "result_edge = check_definition(test_edge_case)\n",
    "print(\"Edge case - single line with existing return comment:\")\n",
    "print(f\"Compliant: {result_edge.is_compliant}\")\n",
    "print(f\"Missing: {result_edge.missing_params}\")\n",
    "\n",
    "if not result_edge.is_compliant:\n",
    "    fixed_edge = generate_fixed_source(result_edge)\n",
    "    print(\"\\nFixed version (should preserve existing comment with TODO):\")\n",
    "    print(fixed_edge)\n",
    "    \n",
    "    # Verify the fix worked\n",
    "    test_edge_fixed = {\n",
    "        'name': 'get_export_cells',\n",
    "        'type': 'FunctionDef',\n",
    "        'source': fixed_edge,\n",
    "        'notebook': 'test.ipynb',\n",
    "        'args': [{'name': 'nb_path', 'annotation': 'Path'}],\n",
    "        'returns': 'List[Dict[str, Any]]'\n",
    "    }\n",
    "    \n",
    "    result_edge_after = check_definition(test_edge_fixed)\n",
    "    print(f\"\\nAfter fix - Compliant: {result_edge_after.is_compliant}\")\n",
    "    print(f\"After fix - Missing: {result_edge_after.missing_params}\")\n",
    "else:\n",
    "    print(\"Already compliant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataclass:\n",
      "@dataclass\n",
      "class DocmentsCheckResult:\n",
      "    name: str  # Name of the function/class\n",
      "    type: str  # Type (FunctionDef, ClassDef, etc.)\n",
      "    notebook: str  # Source notebook\n",
      "    has_docstring: bool  # Whether it has a docstring\n",
      "    params_documented: Dict[str, bool]  # Which params have documentation\n",
      "    return_documented: bool  # Whether return is documented\n",
      "    missing_params: List[str]  # Parameters missing documentation\n",
      "    is_compliant: bool  # Overall compliance status\n",
      "    source: str  # Source code of the definition\n",
      "    has_todos: bool = False  # Whether it contains TODO placeholders\n",
      "    todo_count: int = 0  # Number of TODO placeholders found\n",
      "\n",
      "Compliant: False\n",
      "Has docstring: False\n",
      "Missing: []\n",
      "\n",
      "Fixed dataclass:\n",
      "@dataclass\n",
      "class DocmentsCheckResult:\n",
      "    \"TODO: Add class description\"\n",
      "    name: str  # Name of the function/class\n",
      "    type: str  # Type (FunctionDef, ClassDef, etc.)\n",
      "    notebook: str  # Source notebook\n",
      "    has_docstring: bool  # Whether it has a docstring\n",
      "    params_documented: Dict[str, bool]  # Which params have documentation\n",
      "    return_documented: bool  # Whether return is documented\n",
      "    missing_params: List[str]  # Parameters missing documentation\n",
      "    is_compliant: bool  # Overall compliance status\n",
      "    source: str  # Source code of the definition\n",
      "    has_todos: bool = False  # Whether it contains TODO placeholders\n",
      "    todo_count: int = 0  # Number of TODO placeholders found\n",
      "\n",
      "Source changed: True\n"
     ]
    }
   ],
   "source": [
    "# Test with a dataclass without docstring\n",
    "dataclass_source = '''@dataclass\n",
    "class DocmentsCheckResult:\n",
    "    name: str  # Name of the function/class\n",
    "    type: str  # Type (FunctionDef, ClassDef, etc.)\n",
    "    notebook: str  # Source notebook\n",
    "    has_docstring: bool  # Whether it has a docstring\n",
    "    params_documented: Dict[str, bool]  # Which params have documentation\n",
    "    return_documented: bool  # Whether return is documented\n",
    "    missing_params: List[str]  # Parameters missing documentation\n",
    "    is_compliant: bool  # Overall compliance status\n",
    "    source: str  # Source code of the definition\n",
    "    has_todos: bool = False  # Whether it contains TODO placeholders\n",
    "    todo_count: int = 0  # Number of TODO placeholders found'''\n",
    "\n",
    "# Create test definition for dataclass\n",
    "test_dataclass = {\n",
    "    'name': 'DocmentsCheckResult',\n",
    "    'type': 'ClassDef',\n",
    "    'source': dataclass_source,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [],  # Classes don't have args in our scanner\n",
    "    'returns': None\n",
    "}\n",
    "\n",
    "# Check it\n",
    "result = check_definition(test_dataclass)\n",
    "print(\"Original dataclass:\")\n",
    "print(result.source)\n",
    "print(f\"\\nCompliant: {result.is_compliant}\")\n",
    "print(f\"Has docstring: {result.has_docstring}\")\n",
    "print(f\"Missing: {result.missing_params}\")\n",
    "\n",
    "# Try to fix it\n",
    "if not result.is_compliant:\n",
    "    fixed = generate_fixed_source(result)\n",
    "    print(\"\\nFixed dataclass:\")\n",
    "    print(fixed)\n",
    "    print(f\"\\nSource changed: {result.source != fixed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
