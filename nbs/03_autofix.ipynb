{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Fix\n",
    "\n",
    "> Automatically add placeholder documentation to non-compliant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp autofix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import List, Dict, Any, Optional\n",
    "import re\n",
    "from pathlib import Path\n",
    "from execnb.nbio import read_nb, write_nb\n",
    "from cjm_nbdev_docments.core import DocmentsCheckResult, check_definition\n",
    "from cjm_nbdev_docments.scanner import scan_notebook, get_export_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def find_signature_boundaries(\n",
    "    lines: List[str]  # Source code lines\n",
    ") -> tuple[int, int]:  # (def_line_idx, sig_end_idx) or (-1, -1) if not found\n",
    "    \"Find the start and end lines of a function signature\"\n",
    "    def_line_idx = None\n",
    "    sig_end_idx = None\n",
    "    paren_count = 0\n",
    "    in_signature = False\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith(('def ', 'async def ')):\n",
    "            def_line_idx = i\n",
    "            in_signature = True\n",
    "            \n",
    "        if in_signature:\n",
    "            # Count parentheses to find where signature ends\n",
    "            paren_count += line.count('(') - line.count(')')\n",
    "            \n",
    "            # If we're back to balanced parens and line contains a colon, signature is done\n",
    "            # (colon might be followed by comments)\n",
    "            if paren_count == 0 and ':' in line:\n",
    "                sig_end_idx = i\n",
    "                break\n",
    "    \n",
    "    if def_line_idx is None or sig_end_idx is None:\n",
    "        return -1, -1\n",
    "    \n",
    "    return def_line_idx, sig_end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_parameters(\n",
    "    params_str: str  # Parameter string from function signature\n",
    ") -> List[str]:  # List of individual parameter strings\n",
    "    \"Split a parameter string into individual parameters, handling nested types\"\n",
    "    params = []\n",
    "    current_param = ''\n",
    "    paren_depth = 0\n",
    "    \n",
    "    for char in params_str:\n",
    "        if char in '([{':\n",
    "            paren_depth += 1\n",
    "        elif char in ')]}':\n",
    "            paren_depth -= 1\n",
    "        elif char == ',' and paren_depth == 0:\n",
    "            params.append(current_param.strip())\n",
    "            current_param = ''\n",
    "            continue\n",
    "        current_param += char\n",
    "    \n",
    "    if current_param.strip():\n",
    "        params.append(current_param.strip())\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_single_line_signature(\n",
    "    sig_line: str  # Single-line function signature\n",
    ") -> dict:  # Parsed components of the signature\n",
    "    \"Parse a single-line function signature into its components\"\n",
    "    func_match = re.match(r'^(\\s*)(def|async def)\\s+(\\w+)\\s*\\((.*?)\\)(\\s*(?:->\\s*[^:]+)?)\\s*:\\s*(.*)$', sig_line)\n",
    "    if not func_match:\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        'indent': func_match.group(1),\n",
    "        'def_keyword': func_match.group(2),\n",
    "        'func_name': func_match.group(3),\n",
    "        'params_str': func_match.group(4),\n",
    "        'return_type': func_match.group(5),\n",
    "        'existing_comment': func_match.group(6).strip()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_param_todo_comment(\n",
    "    param_name: str,  # Parameter name\n",
    "    result: DocmentsCheckResult,  # Check result with type hint and doc info\n",
    "    existing_comment: str = \"\"  # Existing comment text (without #)\n",
    ") -> str:  # TODO comment to add\n",
    "    \"Generate appropriate TODO comment for a parameter based on what's missing\"\n",
    "    has_type_hint = result.params_with_type_hints.get(param_name, False)\n",
    "    has_doc = result.params_documented.get(param_name, False)\n",
    "    \n",
    "    if not has_type_hint and not has_doc:\n",
    "        # Missing both type hint and description\n",
    "        return \"TODO: Add type hint and description\"\n",
    "    elif not has_type_hint and has_doc:\n",
    "        # Has description but missing type hint\n",
    "        if existing_comment:\n",
    "            # Check if TODO for type hint already exists\n",
    "            if \"TODO: Add type hint\" in existing_comment or \"TODO:Add type hint\" in existing_comment:\n",
    "                return existing_comment  # Don't add duplicate TODO\n",
    "            else:\n",
    "                return f\"{existing_comment} - TODO: Add type hint\"\n",
    "        else:\n",
    "            return \"TODO: Add type hint\"\n",
    "    elif has_type_hint and not has_doc:\n",
    "        # Has type hint but missing description\n",
    "        return \"TODO: Add description\"\n",
    "    else:\n",
    "        # This shouldn't happen if we're being asked to generate a comment\n",
    "        return existing_comment if existing_comment else \"TODO: Verify documentation\"\n",
    "\n",
    "\n",
    "#| export\n",
    "def generate_return_todo_comment(\n",
    "    result: DocmentsCheckResult,  # Check result with type hint and doc info\n",
    "    existing_comment: str = \"\"  # Existing comment text (without #)\n",
    ") -> str:  # TODO comment to add\n",
    "    \"Generate appropriate TODO comment for return value based on what's missing\"\n",
    "    has_type_hint = result.return_has_type_hint\n",
    "    has_doc = result.return_documented\n",
    "    \n",
    "    if not has_type_hint and not has_doc:\n",
    "        # Missing both type hint and description\n",
    "        return \"TODO: Add type hint and return description\"\n",
    "    elif not has_type_hint and has_doc:\n",
    "        # Has description but missing type hint\n",
    "        if existing_comment:\n",
    "            # Check if TODO for type hint already exists\n",
    "            if \"TODO: Add type hint\" in existing_comment or \"TODO:Add type hint\" in existing_comment:\n",
    "                return existing_comment  # Don't add duplicate TODO\n",
    "            else:\n",
    "                return f\"{existing_comment} - TODO: Add type hint\"\n",
    "        else:\n",
    "            return \"TODO: Add type hint\"\n",
    "    elif has_type_hint and not has_doc:\n",
    "        # Has type hint but missing description\n",
    "        return \"TODO: Add return description\"\n",
    "    else:\n",
    "        # This shouldn't happen if we're being asked to generate a comment\n",
    "        return existing_comment if existing_comment else \"TODO: Verify description\"\n",
    "\n",
    "\n",
    "#| export\n",
    "def build_fixed_single_line_function(\n",
    "    parsed: dict,  # Parsed signature components\n",
    "    params: List[str],  # Individual parameter strings\n",
    "    result: DocmentsCheckResult  # Check result with missing params info\n",
    ") -> List[str]:  # Lines of fixed function signature\n",
    "    \"Build a fixed single-line function with documentation comments\"\n",
    "    fixed_lines = []\n",
    "    indent = parsed['indent']\n",
    "    \n",
    "    # Start the function definition\n",
    "    fixed_lines.append(f\"{indent}{parsed['def_keyword']} {parsed['func_name']}(\")\n",
    "    \n",
    "    # Add parameters with comments as needed\n",
    "    for i, param in enumerate(params):\n",
    "        # Check if this parameter needs documentation or type hints\n",
    "        param_name = param.split(':', 1)[0].split('=', 1)[0].strip()\n",
    "        \n",
    "        needs_doc_fix = param_name in result.missing_params and param_name != 'self'\n",
    "        needs_type_hint_fix = param_name in result.params_missing_type_hints and param_name != 'self'\n",
    "        \n",
    "        if needs_doc_fix or needs_type_hint_fix:\n",
    "            todo_comment = generate_param_todo_comment(param_name, result)\n",
    "            if i < len(params) - 1:\n",
    "                fixed_lines.append(f\"{indent}    {param},  # {todo_comment}\")\n",
    "            else:\n",
    "                fixed_lines.append(f\"{indent}    {param}  # {todo_comment}\")\n",
    "        else:\n",
    "            if i < len(params) - 1:\n",
    "                fixed_lines.append(f\"{indent}    {param},\")\n",
    "            else:\n",
    "                fixed_lines.append(f\"{indent}    {param}\")\n",
    "    \n",
    "    # Handle return type and existing comment\n",
    "    return_type = parsed['return_type']\n",
    "    existing_comment = parsed['existing_comment']\n",
    "    \n",
    "    # For single-line conversions, check if return needs fixing\n",
    "    if return_type:\n",
    "        if 'return' in result.missing_params or 'return' in result.params_missing_type_hints:\n",
    "            if existing_comment:\n",
    "                # Parse existing comment\n",
    "                comment_text = existing_comment[1:].strip() if existing_comment.startswith('#') else existing_comment\n",
    "                todo_comment = generate_return_todo_comment(result, comment_text)\n",
    "                fixed_lines.append(f\"{indent}){return_type}: # {todo_comment}\")\n",
    "            else:\n",
    "                # No existing comment\n",
    "                todo_comment = generate_return_todo_comment(result)\n",
    "                fixed_lines.append(f\"{indent}){return_type}:  # {todo_comment}\")\n",
    "        else:\n",
    "            # Return doesn't need fixing\n",
    "            if existing_comment:\n",
    "                if existing_comment.startswith('#'):\n",
    "                    fixed_lines.append(f\"{indent}){return_type}: {existing_comment}\")\n",
    "                else:\n",
    "                    fixed_lines.append(f\"{indent}){return_type}: # {existing_comment}\")\n",
    "            else:\n",
    "                fixed_lines.append(f\"{indent}){return_type}:\")\n",
    "    else:\n",
    "        # No return type but might need one\n",
    "        if 'return' in result.params_missing_type_hints:\n",
    "            if existing_comment:\n",
    "                comment_text = existing_comment[1:].strip() if existing_comment.startswith('#') else existing_comment\n",
    "                todo_comment = generate_return_todo_comment(result, comment_text)\n",
    "                fixed_lines.append(f\"{indent}): # {todo_comment}\")\n",
    "            else:\n",
    "                todo_comment = generate_return_todo_comment(result)\n",
    "                fixed_lines.append(f\"{indent}): # {todo_comment}\")\n",
    "        else:\n",
    "            # No return type needed\n",
    "            if existing_comment:\n",
    "                if existing_comment.startswith('#'):\n",
    "                    fixed_lines.append(f\"{indent}): {existing_comment}\")\n",
    "                else:\n",
    "                    fixed_lines.append(f\"{indent}): # {existing_comment}\")\n",
    "            else:\n",
    "                fixed_lines.append(f\"{indent}):\")\n",
    "    \n",
    "    return fixed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fix_multi_line_signature(\n",
    "    lines: List[str],  # All source lines\n",
    "    def_line_idx: int,  # Start of function definition\n",
    "    sig_end_idx: int,  # End of function signature\n",
    "    result: DocmentsCheckResult  # Check result with missing params info\n",
    ") -> List[str]:  # Fixed lines for the signature portion\n",
    "    \"Fix a multi-line function signature by adding parameter comments\"\n",
    "    fixed_lines = []\n",
    "    \n",
    "    for i in range(def_line_idx, sig_end_idx + 1):\n",
    "        line = lines[i]\n",
    "        line_stripped = line.strip()\n",
    "        \n",
    "        # More flexible parameter matching for multi-line signatures\n",
    "        # Match: whitespace + word + optional type annotation + optional comma/paren + optional whitespace + optional comment\n",
    "        param_match = re.match(r'^(\\s*)(\\w+)(\\s*(?::\\s*[^,\\)#]+)?)\\s*([,\\)]?)(\\s*)(?:#\\s*(.*))?$', line)\n",
    "        if param_match and i > def_line_idx and i < sig_end_idx:\n",
    "            # This is a parameter line (not the def line, not the return line)\n",
    "            indent = param_match.group(1)\n",
    "            param_name = param_match.group(2)\n",
    "            type_annotation = param_match.group(3) or ''\n",
    "            trailing_punct = param_match.group(4) or ''\n",
    "            trailing_space = param_match.group(5) or ''\n",
    "            existing_comment = param_match.group(6) or ''\n",
    "            \n",
    "            # Check if this parameter needs fixing (either missing docs or missing type hints)\n",
    "            needs_doc_fix = param_name in result.missing_params and param_name != 'self'\n",
    "            needs_type_hint_fix = param_name in result.params_missing_type_hints and param_name != 'self'\n",
    "            \n",
    "            if needs_doc_fix or needs_type_hint_fix:\n",
    "                todo_comment = generate_param_todo_comment(param_name, result, existing_comment)\n",
    "                # Only add the fixed line if the comment actually changed\n",
    "                if todo_comment != existing_comment:\n",
    "                    fixed_lines.append(f\"{indent}{param_name}{type_annotation}{trailing_punct}{trailing_space}  # {todo_comment}\")\n",
    "                else:\n",
    "                    # Comment didn't change, keep original line\n",
    "                    fixed_lines.append(line)\n",
    "            else:\n",
    "                fixed_lines.append(line)\n",
    "        else:\n",
    "            # Check for return type line\n",
    "            return_match = re.match(r'^(\\s*\\)\\s*->\\s*[^:#]+)\\s*:\\s*(.*)$', line)\n",
    "            if return_match and ('return' in result.missing_params or 'return' in result.params_missing_type_hints):\n",
    "                pre_colon = return_match.group(1)\n",
    "                after_colon = return_match.group(2).strip()\n",
    "                \n",
    "                if after_colon:\n",
    "                    # There's already a comment, generate appropriate TODO\n",
    "                    comment_text = after_colon[1:].strip() if after_colon.startswith('#') else after_colon\n",
    "                    todo_comment = generate_return_todo_comment(result, comment_text)\n",
    "                    # Only change if the comment actually changed\n",
    "                    if todo_comment != comment_text:\n",
    "                        fixed_lines.append(f\"{pre_colon}: # {todo_comment}\")\n",
    "                    else:\n",
    "                        fixed_lines.append(line)\n",
    "                else:\n",
    "                    # No comment, add full TODO\n",
    "                    todo_comment = generate_return_todo_comment(result)\n",
    "                    fixed_lines.append(f\"{pre_colon}:  # {todo_comment}\")\n",
    "            else:\n",
    "                fixed_lines.append(line)\n",
    "    \n",
    "    return fixed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_fixed_source(\n",
    "    result: DocmentsCheckResult  # Check result with non-compliant function\n",
    ") -> str:  # Fixed source code with placeholder documentation\n",
    "    \"Generate fixed source code for a non-compliant function or class\"\n",
    "    lines = result.source.split('\\n')\n",
    "    fixed_lines = []\n",
    "    \n",
    "    # Handle classes (including dataclasses)\n",
    "    if result.type == 'ClassDef':\n",
    "        # Find the class definition line\n",
    "        class_line_idx = -1\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.strip().startswith('class '):\n",
    "                class_line_idx = i\n",
    "                break\n",
    "        \n",
    "        if class_line_idx == -1:\n",
    "            return result.source\n",
    "        \n",
    "        # Add lines up to and including the class definition\n",
    "        for i in range(class_line_idx + 1):\n",
    "            fixed_lines.append(lines[i])\n",
    "        \n",
    "        # If missing docstring, add it after the class definition\n",
    "        if not result.has_docstring:\n",
    "            # Find the indentation of the first line after class definition\n",
    "            indent = ''\n",
    "            if class_line_idx + 1 < len(lines):\n",
    "                next_line = lines[class_line_idx + 1]\n",
    "                # Match leading whitespace\n",
    "                indent_match = re.match(r'^(\\s*)', next_line)\n",
    "                if indent_match:\n",
    "                    indent = indent_match.group(1)\n",
    "                else:\n",
    "                    # Default to 4 spaces if can't determine\n",
    "                    indent = '    '\n",
    "            else:\n",
    "                indent = '    '\n",
    "            \n",
    "            fixed_lines.append(f'{indent}\"TODO: Add class description\"')\n",
    "        \n",
    "        # Add the rest of the class body\n",
    "        for i in range(class_line_idx + 1, len(lines)):\n",
    "            fixed_lines.append(lines[i])\n",
    "        \n",
    "        return '\\n'.join(fixed_lines)\n",
    "    \n",
    "    # Function handling - check if we need to fix anything\n",
    "    needs_fixing = (not result.is_compliant or \n",
    "                   result.missing_params or \n",
    "                   result.params_missing_type_hints)\n",
    "    \n",
    "    if not needs_fixing:\n",
    "        return result.source\n",
    "    \n",
    "    # Find the function definition line and signature end\n",
    "    def_line_idx, sig_end_idx = find_signature_boundaries(lines)\n",
    "    \n",
    "    if def_line_idx == -1:\n",
    "        return result.source\n",
    "    \n",
    "    # For single-line signatures, we need to split and reformat\n",
    "    if def_line_idx == sig_end_idx and (result.missing_params or result.params_missing_type_hints):\n",
    "        # Parse the signature\n",
    "        parsed = parse_single_line_signature(lines[def_line_idx])\n",
    "        if not parsed:\n",
    "            return result.source\n",
    "        \n",
    "        # Split parameters\n",
    "        params = split_parameters(parsed['params_str'])\n",
    "        \n",
    "        # Build the fixed function\n",
    "        fixed_lines = build_fixed_single_line_function(parsed, params, result)\n",
    "        \n",
    "        # Add docstring if missing\n",
    "        if not result.has_docstring:\n",
    "            fixed_lines.append(f'{parsed[\"indent\"]}    \"TODO: Add function description\"')\n",
    "        \n",
    "        # Add rest of function body\n",
    "        for i in range(sig_end_idx + 1, len(lines)):\n",
    "            fixed_lines.append(lines[i])\n",
    "    else:\n",
    "        # Multi-line signature - process line by line\n",
    "        # Add lines before the function\n",
    "        for i in range(def_line_idx):\n",
    "            fixed_lines.append(lines[i])\n",
    "        \n",
    "        # Fix the signature\n",
    "        signature_lines = fix_multi_line_signature(lines, def_line_idx, sig_end_idx, result)\n",
    "        fixed_lines.extend(signature_lines)\n",
    "        \n",
    "        # Insert docstring immediately after signature ends if missing\n",
    "        if not result.has_docstring:\n",
    "            # Find the indentation of the function definition\n",
    "            indent_match = re.match(r'^(\\s*)', lines[def_line_idx])\n",
    "            base_indent = indent_match.group(1) if indent_match else ''\n",
    "            docstring_indent = base_indent + '    '\n",
    "            fixed_lines.append(f'{docstring_indent}\"TODO: Add function description\"')\n",
    "        \n",
    "        # Add rest of function body\n",
    "        for i in range(sig_end_idx + 1, len(lines)):\n",
    "            fixed_lines.append(lines[i])\n",
    "    \n",
    "    return '\\n'.join(fixed_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fix_notebook(\n",
    "    nb_path: Path,  # Path to notebook to fix\n",
    "    dry_run: bool = False  # If True, show changes without saving\n",
    ") -> Dict[str, Any]:  # Summary of changes made\n",
    "    \"Fix non-compliant functions in a notebook by adding placeholder documentation\"\n",
    "    nb = read_nb(nb_path)\n",
    "    definitions = scan_notebook(nb_path)\n",
    "    \n",
    "    changes = {\n",
    "        'notebook': nb_path.name,\n",
    "        'definitions_fixed': [],\n",
    "        'cells_modified': []\n",
    "    }\n",
    "    \n",
    "    # Check each definition\n",
    "    for defn in definitions:\n",
    "        result = check_definition(defn)\n",
    "        \n",
    "        # Fix if non-compliant OR has missing type hints\n",
    "        needs_fixing = (not result.is_compliant or \n",
    "                       result.missing_params or \n",
    "                       result.params_missing_type_hints)\n",
    "        \n",
    "        if needs_fixing:\n",
    "            # Generate fixed source\n",
    "            fixed_source = generate_fixed_source(result)\n",
    "            \n",
    "            # Only proceed if the source actually changed\n",
    "            if fixed_source != result.source:\n",
    "                # Find and update the cell\n",
    "                cell_id = defn['cell_id']\n",
    "                for cell in nb.cells:\n",
    "                    if cell.get('id') == cell_id:\n",
    "                        # Replace the definition in the cell source\n",
    "                        old_source = result.source\n",
    "                        cell_source = cell.source\n",
    "                        \n",
    "                        # Find the definition in the cell and replace it\n",
    "                        if old_source in cell_source:\n",
    "                            new_cell_source = cell_source.replace(old_source, fixed_source)\n",
    "                            \n",
    "                            if not dry_run:\n",
    "                                cell.source = new_cell_source\n",
    "                            \n",
    "                            changes['definitions_fixed'].append(result.name)\n",
    "                            if cell_id not in changes['cells_modified']:\n",
    "                                changes['cells_modified'].append(cell_id)\n",
    "                            \n",
    "                            if dry_run:\n",
    "                                print(f\"\\nWould fix {result.name}:\")\n",
    "                                print(\"-\" * 40)\n",
    "                                print(fixed_source)\n",
    "                                print(\"-\" * 40)\n",
    "    \n",
    "    # Save the notebook if not dry run\n",
    "    if not dry_run and changes['definitions_fixed']:\n",
    "        write_nb(nb, nb_path)\n",
    "        # Fix grammar: use singular/plural based on count\n",
    "        count = len(changes['definitions_fixed'])\n",
    "        item_word = \"definition\" if count == 1 else \"definitions\"\n",
    "        print(f\"âœ… Fixed {count} {item_word} in {nb_path.name}\")\n",
    "        for defn_name in changes['definitions_fixed']:\n",
    "            print(f\"   - {defn_name}\")\n",
    "    elif dry_run and changes['definitions_fixed']:\n",
    "        count = len(changes['definitions_fixed'])\n",
    "        item_word = \"definition\" if count == 1 else \"definitions\" \n",
    "        print(f\"\\nðŸ” Dry run: Would fix {count} {item_word}\")\n",
    "    else:\n",
    "        print(f\"âœ… All definitions in {nb_path.name} are already compliant\")\n",
    "    \n",
    "    return changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original function:\n",
      "def bad_function(x, y, z=10):\n",
      "    result = x + y + z\n",
      "    return result\n",
      "\n",
      "Compliant: False\n",
      "Missing: ['x', 'y', 'z']\n",
      "\n",
      "Fixed function:\n",
      "def bad_function(\n",
      "    x,  # TODO: Add type hint and description\n",
      "    y,  # TODO: Add type hint and description\n",
      "    z=10  # TODO: Add type hint and description\n",
      "): # TODO: Add type hint\n",
      "    \"TODO: Add function description\"\n",
      "    result = x + y + z\n",
      "    return result\n"
     ]
    }
   ],
   "source": [
    "# Test fixing a non-compliant function\n",
    "from cjm_nbdev_docments.core import check_definition\n",
    "\n",
    "# Create a test function\n",
    "test_source = '''def bad_function(x, y, z=10):\n",
    "    result = x + y + z\n",
    "    return result'''\n",
    "\n",
    "# Create a mock definition\n",
    "test_def = {\n",
    "    'name': 'bad_function',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': test_source,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [\n",
    "        {'name': 'x', 'annotation': None},\n",
    "        {'name': 'y', 'annotation': None},\n",
    "        {'name': 'z', 'annotation': None}\n",
    "    ],\n",
    "    'returns': None\n",
    "}\n",
    "\n",
    "# Check it\n",
    "result = check_definition(test_def)\n",
    "print(\"Original function:\")\n",
    "print(result.source)\n",
    "print(f\"\\nCompliant: {result.is_compliant}\")\n",
    "print(f\"Missing: {result.missing_params}\")\n",
    "\n",
    "# Fix it\n",
    "fixed = generate_fixed_source(result)\n",
    "print(\"\\nFixed function:\")\n",
    "print(fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original function:\n",
      "def typed_function(name: str, age: int) -> str:\n",
      "    return f\"{name} is {age} years old\"\n",
      "\n",
      "Compliant: False\n",
      "Missing: ['name', 'age', 'return']\n",
      "\n",
      "Fixed function:\n",
      "def typed_function(\n",
      "    name: str,  # TODO: Add description\n",
      "    age: int  # TODO: Add description\n",
      ") -> str:  # TODO: Add return description\n",
      "    \"TODO: Add function description\"\n",
      "    return f\"{name} is {age} years old\"\n"
     ]
    }
   ],
   "source": [
    "# Test with a function that has return type\n",
    "test_source2 = '''def typed_function(name: str, age: int) -> str:\n",
    "    return f\"{name} is {age} years old\"'''\n",
    "\n",
    "test_def2 = {\n",
    "    'name': 'typed_function',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': test_source2,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [\n",
    "        {'name': 'name', 'annotation': 'str'},\n",
    "        {'name': 'age', 'annotation': 'int'}\n",
    "    ],\n",
    "    'returns': 'str'\n",
    "}\n",
    "\n",
    "result2 = check_definition(test_def2)\n",
    "print(\"Original function:\")\n",
    "print(result2.source)\n",
    "print(f\"\\nCompliant: {result2.is_compliant}\")\n",
    "print(f\"Missing: {result2.missing_params}\")\n",
    "\n",
    "fixed2 = generate_fixed_source(result2)\n",
    "print(\"\\nFixed function:\")\n",
    "print(fixed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 0: 'def bad_function(x, y, z=10):'\n",
      "Line 1: '    result = x + y + z'\n",
      "Line 2: '    return result'\n"
     ]
    }
   ],
   "source": [
    "# Debug the line matching\n",
    "test_source = '''def bad_function(x, y, z=10):\n",
    "    result = x + y + z\n",
    "    return result'''\n",
    "\n",
    "lines = test_source.split('\\n')\n",
    "for i, line in enumerate(lines):\n",
    "    print(f\"Line {i}: {repr(line)}\")\n",
    "    param_match = re.match(r'^(\\s*)(\\w+)(\\s*(?::\\s*[^,\\)#]+)?(?:\\s*=\\s*[^,\\)#]+)?)\\s*([,\\)])\\s*$', line)\n",
    "    if param_match:\n",
    "        print(f\"  -> Matched param: {param_match.groups()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original function:\n",
      "def get_export_cells(\n",
      "    nb_path: Path  # Path to the notebook file\n",
      ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
      "    nb = read_nb(nb_path)\n",
      "    export_cells = []\n",
      "\n",
      "    for cell in nb.cells:\n",
      "        if cell.cell_type == 'code' and cell.source:\n",
      "            lines = cell.source.split('\\n')\n",
      "            for line in lines:\n",
      "                if line.strip().startswith('#| export'):\n",
      "                    export_cells.append({\n",
      "                        'cell_id': cell.get('id', None),\n",
      "                        'source': cell.source,\n",
      "                        'idx': cell.idx_ if hasattr(cell, 'idx_') else None\n",
      "                    })\n",
      "                    break\n",
      "\n",
      "    return export_cells\n",
      "\\nCompliant: False\n",
      "Missing: []\n",
      "\\nFixed function:\n",
      "def get_export_cells(\n",
      "    nb_path: Path  # Path to the notebook file\n",
      ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
      "    \"TODO: Add function description\"\n",
      "    nb = read_nb(nb_path)\n",
      "    export_cells = []\n",
      "\n",
      "    for cell in nb.cells:\n",
      "        if cell.cell_type == 'code' and cell.source:\n",
      "            lines = cell.source.split('\\n')\n",
      "            for line in lines:\n",
      "                if line.strip().startswith('#| export'):\n",
      "                    export_cells.append({\n",
      "                        'cell_id': cell.get('id', None),\n",
      "                        'source': cell.source,\n",
      "                        'idx': cell.idx_ if hasattr(cell, 'idx_') else None\n",
      "                    })\n",
      "                    break\n",
      "\n",
      "    return export_cells\n"
     ]
    }
   ],
   "source": [
    "# Test the problematic case you described\n",
    "problematic_source = '''def get_export_cells(\n",
    "    nb_path: Path  # Path to the notebook file\n",
    ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
    "    nb = read_nb(nb_path)\n",
    "    export_cells = []\n",
    "    \n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == 'code' and cell.source:\n",
    "            lines = cell.source.split('\\\\n')\n",
    "            for line in lines:\n",
    "                if line.strip().startswith('#| export'):\n",
    "                    export_cells.append({\n",
    "                        'cell_id': cell.get('id', None),\n",
    "                        'source': cell.source,\n",
    "                        'idx': cell.idx_ if hasattr(cell, 'idx_') else None\n",
    "                    })\n",
    "                    break\n",
    "    \n",
    "    return export_cells'''\n",
    "\n",
    "# Create test definition (missing docstring only)\n",
    "test_def = {\n",
    "    'name': 'get_export_cells',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': problematic_source,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [{'name': 'nb_path', 'annotation': 'Path'}],\n",
    "    'returns': 'List[Dict[str, Any]]'\n",
    "}\n",
    "\n",
    "result = check_definition(test_def)\n",
    "print(\"Original function:\")\n",
    "print(result.source)\n",
    "print(f\"\\\\nCompliant: {result.is_compliant}\")\n",
    "print(f\"Missing: {result.missing_params}\")\n",
    "\n",
    "if not result.is_compliant:\n",
    "    fixed = generate_fixed_source(result)\n",
    "    print(\"\\\\nFixed function:\")\n",
    "    print(fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines with indices:\n",
      "0: 'def get_export_cells('\n",
      "1: '    nb_path: Path  # Path to the notebook file'\n",
      "2: ') -> List[Dict[str, Any]]:  # List of cells with export directives'\n",
      "3: '    nb = read_nb(nb_path)'\n",
      "4: '    export_cells = []'\n",
      "5: ''\n",
      "6: '    for cell in nb.cells:'\n",
      "    ^ Line 6 ends with ':'\n",
      "7: \"        if cell.cell_type == 'code' and cell.source:\"\n",
      "    ^ Line 7 ends with ':'\n",
      "8: \"            lines = cell.source.split('\\\\n')\"\n",
      "9: '            for line in lines:'\n",
      "    ^ Line 9 ends with ':'\n",
      "10: \"                if line.strip().startswith('#| export'):\"\n",
      "    ^ Line 10 ends with ':'\n",
      "11: '                    export_cells.append({'\n",
      "12: \"                        'cell_id': cell.get('id', None),\"\n",
      "13: \"                        'source': cell.source,\"\n",
      "14: \"                        'idx': cell.idx_ if hasattr(cell, 'idx_') else None\"\n",
      "15: '                    })'\n",
      "16: '                    break'\n",
      "17: ''\n",
      "18: '    return export_cells'\n",
      "Function starts at line 0\n",
      "Signature ends at line 6\n",
      "\\nFunction definition: line 0\n",
      "Signature end: line 6\n",
      "Multi-line signature: True\n"
     ]
    }
   ],
   "source": [
    "# Debug the signature detection\n",
    "problematic_source = '''def get_export_cells(\n",
    "    nb_path: Path  # Path to the notebook file\n",
    ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
    "    nb = read_nb(nb_path)\n",
    "    export_cells = []\n",
    "\n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == 'code' and cell.source:\n",
    "            lines = cell.source.split('\\\\n')\n",
    "            for line in lines:\n",
    "                if line.strip().startswith('#| export'):\n",
    "                    export_cells.append({\n",
    "                        'cell_id': cell.get('id', None),\n",
    "                        'source': cell.source,\n",
    "                        'idx': cell.idx_ if hasattr(cell, 'idx_') else None\n",
    "                    })\n",
    "                    break\n",
    "\n",
    "    return export_cells'''\n",
    "\n",
    "lines = problematic_source.split('\\n')\n",
    "print(\"Lines with indices:\")\n",
    "for i, line in enumerate(lines):\n",
    "    print(f\"{i}: {repr(line)}\")\n",
    "    if line.rstrip().endswith(':'):\n",
    "        print(f\"    ^ Line {i} ends with ':'\")\n",
    "\n",
    "# Find signature end\n",
    "def_line_idx = None\n",
    "sig_end_idx = None\n",
    "for i, line in enumerate(lines):\n",
    "    if line.strip().startswith(('def ', 'async def ')):\n",
    "        def_line_idx = i\n",
    "        print(f\"Function starts at line {i}\")\n",
    "    if def_line_idx is not None and line.rstrip().endswith(':'):\n",
    "        sig_end_idx = i\n",
    "        print(f\"Signature ends at line {i}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\\\nFunction definition: line {def_line_idx}\")\n",
    "print(f\"Signature end: line {sig_end_idx}\")\n",
    "print(f\"Multi-line signature: {def_line_idx != sig_end_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function starts at line 0\n",
      "Line 0: paren_count 0 -> 1, ends with ':': False\n",
      "Line 1: paren_count 1 -> 1, ends with ':': False\n",
      "Line 2: paren_count 1 -> 0, ends with ':': False\n",
      "Line 3: paren_count 0 -> 0, ends with ':': False\n",
      "Line 4: paren_count 0 -> 0, ends with ':': False\n",
      "Line 5: paren_count 0 -> 0, ends with ':': False\n",
      "Line 6: paren_count 0 -> 0, ends with ':': True\n",
      "Signature ends at line 6\n",
      "\n",
      "Corrected detection:\n",
      "Function definition: line 0\n",
      "Signature end: line 6\n",
      "\n",
      "Fixed function:\n",
      "def get_export_cells(\n",
      "    nb_path: Path  # Path to the notebook file\n",
      ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
      "    \"TODO: Add function description\"\n",
      "    nb = read_nb(nb_path)\n",
      "    export_cells = []\n",
      "\n",
      "    for cell in nb.cells:\n",
      "        if cell.cell_type == 'code' and cell.source:\n",
      "            lines = cell.source.split('\\n')\n",
      "            for line in lines:\n",
      "                if line.strip().startswith('#| export'):\n",
      "                    export_cells.append({\n",
      "                        'cell_id': cell.get('id', None),\n",
      "                        'source': cell.source,\n",
      "                        'idx': cell.idx_ if hasattr(cell, 'idx_') else None\n",
      "                    })\n",
      "                    break\n",
      "\n",
      "    return export_cells\n"
     ]
    }
   ],
   "source": [
    "# Test the corrected signature detection\n",
    "lines = problematic_source.split('\\n')\n",
    "\n",
    "def_line_idx = None\n",
    "sig_end_idx = None\n",
    "paren_count = 0\n",
    "in_signature = False\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    if line.strip().startswith(('def ', 'async def ')):\n",
    "        def_line_idx = i\n",
    "        in_signature = True\n",
    "        print(f\"Function starts at line {i}\")\n",
    "        \n",
    "    if in_signature:\n",
    "        # Count parentheses to find where signature ends\n",
    "        old_count = paren_count\n",
    "        paren_count += line.count('(') - line.count(')')\n",
    "        print(f\"Line {i}: paren_count {old_count} -> {paren_count}, ends with ':': {line.rstrip().endswith(':')}\")\n",
    "        \n",
    "        # If we're back to balanced parens and line ends with colon, signature is done\n",
    "        if paren_count == 0 and line.rstrip().endswith(':'):\n",
    "            sig_end_idx = i\n",
    "            print(f\"Signature ends at line {i}\")\n",
    "            break\n",
    "\n",
    "print(f\"\\nCorrected detection:\")\n",
    "print(f\"Function definition: line {def_line_idx}\")\n",
    "print(f\"Signature end: line {sig_end_idx}\")\n",
    "\n",
    "# Test the fix\n",
    "result = check_definition(test_def)\n",
    "if not result.is_compliant:\n",
    "    fixed = generate_fixed_source(result)\n",
    "    print(\"\\nFixed function:\")\n",
    "    print(fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1 Debug:\n",
      "Compliant: False\n",
      "Missing params: ['nb_path']\n",
      "Params documented: {'nb_path': False}\n",
      "Original == Fixed: False\n",
      "\n",
      "Original:\n",
      "'def get_export_cells(\\n    nb_path: Path  \\n) -> List[Dict[str, Any]]:  # List of cells with export directives\\n    \"Extract all code cells from a notebook that have export directives\"\\n    nb = read_nb(nb_path)\\n    return []'\n",
      "\n",
      "Fixed:\n",
      "'def get_export_cells(\\n    nb_path: Path    # TODO: Add description\\n) -> List[Dict[str, Any]]:  # List of cells with export directives\\n    \"Extract all code cells from a notebook that have export directives\"\\n    nb = read_nb(nb_path)\\n    return []'\n"
     ]
    }
   ],
   "source": [
    "# Debug scenario 1 - should need fixing but claims to be compliant\n",
    "scenario1_source = '''def get_export_cells(\n",
    "    nb_path: Path  \n",
    ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
    "    \"Extract all code cells from a notebook that have export directives\"\n",
    "    nb = read_nb(nb_path)\n",
    "    return []'''\n",
    "\n",
    "test_def1 = {\n",
    "    'name': 'get_export_cells',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': scenario1_source,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [{'name': 'nb_path', 'annotation': 'Path'}],\n",
    "    'returns': 'List[Dict[str, Any]]'\n",
    "}\n",
    "\n",
    "result1 = check_definition(test_def1)\n",
    "print(\"Scenario 1 Debug:\")\n",
    "print(f\"Compliant: {result1.is_compliant}\")\n",
    "print(f\"Missing params: {result1.missing_params}\")\n",
    "print(f\"Params documented: {result1.params_documented}\")\n",
    "\n",
    "# Test what the autofix generates\n",
    "if not result1.is_compliant:\n",
    "    fixed1 = generate_fixed_source(result1)\n",
    "    print(f\"Original == Fixed: {scenario1_source == fixed1}\")\n",
    "    print(\"\\nOriginal:\")\n",
    "    print(repr(scenario1_source))\n",
    "    print(\"\\nFixed:\")\n",
    "    print(repr(fixed1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 4 Debug:\n",
      "Compliant: False\n",
      "Missing params: ['nb_path', 'fake_test_path']\n",
      "Params documented: {'nb_path': False, 'fake_test_path': False}\n",
      "\n",
      "Fixed version:\n",
      "def get_export_cells(\n",
      "    nb_path: Path,    # TODO: Add description\n",
      "    fake_test_path: Path  # TODO: Add description\n",
      ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
      "    \"Extract all code cells from a notebook that have export directives\"\n",
      "    nb = read_nb(nb_path)\n",
      "    return []\n",
      "\n",
      "After fix - Compliant: True\n",
      "After fix - Missing: []\n"
     ]
    }
   ],
   "source": [
    "# Debug scenario 4 - only partially fixes\n",
    "scenario4_source = '''def get_export_cells(\n",
    "    nb_path: Path,  \n",
    "    fake_test_path: Path\n",
    ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
    "    \"Extract all code cells from a notebook that have export directives\"\n",
    "    nb = read_nb(nb_path)\n",
    "    return []'''\n",
    "\n",
    "test_def4 = {\n",
    "    'name': 'get_export_cells',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': scenario4_source,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [\n",
    "        {'name': 'nb_path', 'annotation': 'Path'},\n",
    "        {'name': 'fake_test_path', 'annotation': 'Path'}\n",
    "    ],\n",
    "    'returns': 'List[Dict[str, Any]]'\n",
    "}\n",
    "\n",
    "result4 = check_definition(test_def4)\n",
    "print(\"Scenario 4 Debug:\")\n",
    "print(f\"Compliant: {result4.is_compliant}\")\n",
    "print(f\"Missing params: {result4.missing_params}\")\n",
    "print(f\"Params documented: {result4.params_documented}\")\n",
    "\n",
    "if not result4.is_compliant:\n",
    "    fixed4 = generate_fixed_source(result4)\n",
    "    print(\"\\nFixed version:\")\n",
    "    print(fixed4)\n",
    "    \n",
    "    # Check if all missing params were actually fixed\n",
    "    test_def4_fixed = {\n",
    "        'name': 'get_export_cells',\n",
    "        'type': 'FunctionDef',\n",
    "        'source': fixed4,\n",
    "        'notebook': 'test.ipynb',\n",
    "        'args': [\n",
    "            {'name': 'nb_path', 'annotation': 'Path'},\n",
    "            {'name': 'fake_test_path', 'annotation': 'Path'}\n",
    "        ],\n",
    "        'returns': 'List[Dict[str, Any]]'\n",
    "    }\n",
    "    \n",
    "    result4_after_fix = check_definition(test_def4_fixed)\n",
    "    print(f\"\\nAfter fix - Compliant: {result4_after_fix.is_compliant}\")\n",
    "    print(f\"After fix - Missing: {result4_after_fix.missing_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines in scenario 4:\n",
      "0: 'def get_export_cells('\n",
      "   -> NO MATCH\n",
      "1: '    nb_path: Path,  '\n",
      "   -> MATCHED: param=nb_path\n",
      "2: '    fake_test_path: Path'\n",
      "   -> NO MATCH\n",
      "3: ') -> List[Dict[str, Any]]:  # List of cells with export directives'\n",
      "   -> NO MATCH\n",
      "4: '    \"Extract all code cells from a notebook that have export directives\"'\n",
      "   -> NO MATCH\n",
      "5: '    nb = read_nb(nb_path)'\n",
      "   -> MATCHED: param=nb\n",
      "6: '    return []'\n",
      "   -> NO MATCH\n",
      "\n",
      "==================================================\n",
      "Testing simpler parameter detection:\n",
      "Line 1 contains 'nb_path': '    nb_path: Path,  '\n",
      "Line 2 contains 'fake_test_path': '    fake_test_path: Path'\n",
      "Line 5 contains 'nb_path': '    nb = read_nb(nb_path)'\n"
     ]
    }
   ],
   "source": [
    "# Debug the parameter matching regex\n",
    "scenario4_lines = scenario4_source.split('\\n')\n",
    "print(\"Lines in scenario 4:\")\n",
    "for i, line in enumerate(scenario4_lines):\n",
    "    print(f\"{i}: {repr(line)}\")\n",
    "    # Test the regex that should match parameter lines\n",
    "    param_match = re.match(r'^(\\s*)(\\w+)(\\s*(?::\\s*[^,\\)#]+)?(?:\\s*=\\s*[^,\\)#]+)?)\\s*([,\\)])\\s*$', line)\n",
    "    if param_match:\n",
    "        print(f\"   -> MATCHED: param={param_match.group(2)}\")\n",
    "    else:\n",
    "        print(f\"   -> NO MATCH\")\n",
    "        \n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Let's also test a simpler pattern\n",
    "print(\"Testing simpler parameter detection:\")\n",
    "for i, line in enumerate(scenario4_lines):\n",
    "    # Look for lines that contain parameter names we know about\n",
    "    if 'nb_path' in line:\n",
    "        print(f\"Line {i} contains 'nb_path': {repr(line)}\")\n",
    "    if 'fake_test_path' in line:\n",
    "        print(f\"Line {i} contains 'fake_test_path': {repr(line)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1 results:\n",
      "(Run this after the previous debug cell)\n",
      "\n",
      "Testing what causes false positive 'fixed' reports...\n"
     ]
    }
   ],
   "source": [
    "# Check the scenario 1 output\n",
    "print(\"Scenario 1 results:\")\n",
    "print(\"(Run this after the previous debug cell)\")\n",
    "\n",
    "# Also let's see what the fix_notebook function does\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a mock scenario to test fix_notebook behavior\n",
    "print(\"\\nTesting what causes false positive 'fixed' reports...\")\n",
    "\n",
    "# Let's see if the issue is in the fix_notebook function's change detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 4 with improved fix:\n",
      "Missing params: ['nb_path', 'fake_test_path']\n",
      "\n",
      "Improved fixed version:\n",
      "def get_export_cells(\n",
      "    nb_path: Path,    # TODO: Add description\n",
      "    fake_test_path: Path  # TODO: Add description\n",
      ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
      "    \"Extract all code cells from a notebook that have export directives\"\n",
      "    nb = read_nb(nb_path)\n",
      "    return []\n",
      "\n",
      "After improved fix - Compliant: True\n",
      "After improved fix - Missing: []\n"
     ]
    }
   ],
   "source": [
    "# Test the improved version on scenario 4\n",
    "result4 = check_definition(test_def4)\n",
    "print(\"Scenario 4 with improved fix:\")\n",
    "print(f\"Missing params: {result4.missing_params}\")\n",
    "\n",
    "fixed4_new = generate_fixed_source(result4)\n",
    "print(\"\\nImproved fixed version:\")\n",
    "print(fixed4_new)\n",
    "\n",
    "# Check if it's now fully compliant\n",
    "test_def4_new_fixed = {\n",
    "    'name': 'get_export_cells',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': fixed4_new,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [\n",
    "        {'name': 'nb_path', 'annotation': 'Path'},\n",
    "        {'name': 'fake_test_path', 'annotation': 'Path'}\n",
    "    ],\n",
    "    'returns': 'List[Dict[str, Any]]'\n",
    "}\n",
    "\n",
    "result4_new_after_fix = check_definition(test_def4_new_fixed)\n",
    "print(f\"\\nAfter improved fix - Compliant: {result4_new_after_fix.is_compliant}\")\n",
    "print(f\"After improved fix - Missing: {result4_new_after_fix.missing_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1 Debug:\n",
      "Compliant: False\n",
      "Missing params: ['nb_path']\n",
      "Params documented: {'nb_path': False}\n",
      "\n",
      "Fixed version:\n",
      "def get_export_cells(\n",
      "    nb_path: Path    # TODO: Add description\n",
      ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
      "    \"Extract all code cells from a notebook that have export directives\"\n",
      "    nb = read_nb(nb_path)\n",
      "    return []\n",
      "\n",
      "Original == Fixed: False\n",
      "Changes detected correctly\n"
     ]
    }
   ],
   "source": [
    "# Test scenario 1 - single param, no comma\n",
    "scenario1_source = '''def get_export_cells(\n",
    "    nb_path: Path  \n",
    ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
    "    \"Extract all code cells from a notebook that have export directives\"\n",
    "    nb = read_nb(nb_path)\n",
    "    return []'''\n",
    "\n",
    "test_def1 = {\n",
    "    'name': 'get_export_cells',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': scenario1_source,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [{'name': 'nb_path', 'annotation': 'Path'}],\n",
    "    'returns': 'List[Dict[str, Any]]'\n",
    "}\n",
    "\n",
    "result1 = check_definition(test_def1)\n",
    "print(\"Scenario 1 Debug:\")\n",
    "print(f\"Compliant: {result1.is_compliant}\")\n",
    "print(f\"Missing params: {result1.missing_params}\")\n",
    "print(f\"Params documented: {result1.params_documented}\")\n",
    "\n",
    "if not result1.is_compliant:\n",
    "    fixed1 = generate_fixed_source(result1)\n",
    "    print(\"\\nFixed version:\")\n",
    "    print(fixed1)\n",
    "    \n",
    "    # Check the change detection\n",
    "    print(f\"\\nOriginal == Fixed: {scenario1_source == fixed1}\")\n",
    "    if scenario1_source != fixed1:\n",
    "        print(\"Changes detected correctly\")\n",
    "    else:\n",
    "        print(\"ERROR: No changes made but function was not compliant!\")\n",
    "else:\n",
    "    print(\"Function is already compliant - should not be 'fixed'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing change detection logic:\n",
      "Function: get_export_cells\n",
      "Old source in new source: False\n",
      "Sources equal: False\n",
      "Would report as fixed: False\n"
     ]
    }
   ],
   "source": [
    "# Check if the issue is in fix_notebook's change detection\n",
    "# Let me examine the fix_notebook logic by looking at what it considers a \"change\"\n",
    "\n",
    "def debug_fix_notebook_logic(definition, old_source, new_source):\n",
    "    \"\"\"Debug what fix_notebook considers a change\"\"\"\n",
    "    print(f\"Function: {definition['name']}\")\n",
    "    print(f\"Old source in new source: {old_source in new_source}\")\n",
    "    print(f\"Sources equal: {old_source == new_source}\")\n",
    "    print(f\"Would report as fixed: {old_source in new_source and old_source != new_source}\")\n",
    "    \n",
    "# Test with our scenarios\n",
    "print(\"Testing change detection logic:\")\n",
    "\n",
    "# Scenario 1 - might be wrongly detected as changed\n",
    "result1 = check_definition(test_def1)\n",
    "if not result1.is_compliant:\n",
    "    fixed1 = generate_fixed_source(result1)\n",
    "    debug_fix_notebook_logic(test_def1, result1.source, fixed1)\n",
    "else:\n",
    "    print(\"Scenario 1: Already compliant, no fix needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOUR Scenario 1 (should be compliant):\n",
      "Compliant: True\n",
      "Missing: []\n",
      "âœ… Correctly identified as compliant\n",
      "\n",
      "============================================================\n",
      "YOUR Scenario 2 (should need fixing):\n",
      "Compliant: False\n",
      "Missing: ['fake_test_path']\n",
      "âœ… Correctly identified as non-compliant\n",
      "Fixed to:\n",
      "def get_export_cells(\n",
      "    nb_path: Path,  # Path to the notebook file\n",
      "    fake_test_path: Path   # TODO: Add description\n",
      ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
      "    \"Extract all code cells from a notebook that have export directives\"\n",
      "    nb = read_nb(nb_path)\n",
      "    return []\n"
     ]
    }
   ],
   "source": [
    "# Test the EXACT scenarios from your original issue\n",
    "\n",
    "# Your scenario 1 - this should be compliant, no fix needed\n",
    "your_scenario1 = '''def get_export_cells(\n",
    "    nb_path: Path  # Path to the notebook file\n",
    ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
    "    \"Extract all code cells from a notebook that have export directives\"\n",
    "    nb = read_nb(nb_path)\n",
    "    export_cells = []\n",
    "    return export_cells'''\n",
    "\n",
    "test_your_s1 = {\n",
    "    'name': 'get_export_cells',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': your_scenario1,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [{'name': 'nb_path', 'annotation': 'Path'}],\n",
    "    'returns': 'List[Dict[str, Any]]'\n",
    "}\n",
    "\n",
    "result_s1 = check_definition(test_your_s1)\n",
    "print(\"YOUR Scenario 1 (should be compliant):\")\n",
    "print(f\"Compliant: {result_s1.is_compliant}\")\n",
    "print(f\"Missing: {result_s1.missing_params}\")\n",
    "\n",
    "if not result_s1.is_compliant:\n",
    "    print(\"âŒ ERROR: This should be compliant but isn't!\")\n",
    "    fixed_s1 = generate_fixed_source(result_s1)\n",
    "    print(\"Would be 'fixed' to:\")\n",
    "    print(fixed_s1)\n",
    "else:\n",
    "    print(\"âœ… Correctly identified as compliant\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Your scenario 2 - missing one param doc, should be fixed\n",
    "your_scenario2 = '''def get_export_cells(\n",
    "    nb_path: Path,  # Path to the notebook file\n",
    "    fake_test_path: Path \n",
    ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
    "    \"Extract all code cells from a notebook that have export directives\"\n",
    "    nb = read_nb(nb_path)\n",
    "    return []'''\n",
    "\n",
    "test_your_s2 = {\n",
    "    'name': 'get_export_cells',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': your_scenario2,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [\n",
    "        {'name': 'nb_path', 'annotation': 'Path'},\n",
    "        {'name': 'fake_test_path', 'annotation': 'Path'}\n",
    "    ],\n",
    "    'returns': 'List[Dict[str, Any]]'\n",
    "}\n",
    "\n",
    "result_s2 = check_definition(test_your_s2)\n",
    "print(\"YOUR Scenario 2 (should need fixing):\")\n",
    "print(f\"Compliant: {result_s2.is_compliant}\")\n",
    "print(f\"Missing: {result_s2.missing_params}\")\n",
    "\n",
    "if not result_s2.is_compliant:\n",
    "    print(\"âœ… Correctly identified as non-compliant\")\n",
    "    fixed_s2 = generate_fixed_source(result_s2)\n",
    "    print(\"Fixed to:\")\n",
    "    print(fixed_s2)\n",
    "else:\n",
    "    print(\"âŒ ERROR: This should need fixing but was marked compliant!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge case - single line with existing return comment:\n",
      "Compliant: False\n",
      "Missing: ['nb_path']\n",
      "\n",
      "Fixed version (should preserve existing comment with TODO):\n",
      "def get_export_cells(\n",
      "    nb_path: Path  # TODO: Add description\n",
      ") -> List[Dict[str, Any]]: # List of cells with export directives\n",
      "    \"Extract all code cells from a notebook that have export directives\"\n",
      "    nb = read_nb(nb_path)\n",
      "    return []\n",
      "\n",
      "After fix - Compliant: True\n",
      "After fix - Missing: []\n"
     ]
    }
   ],
   "source": [
    "# Test the edge case with existing return comment\n",
    "edge_case_source = '''def get_export_cells(nb_path: Path) -> List[Dict[str, Any]]:  # List of cells with export directives\n",
    "    \"Extract all code cells from a notebook that have export directives\"\n",
    "    nb = read_nb(nb_path)\n",
    "    return []'''\n",
    "\n",
    "test_edge_case = {\n",
    "    'name': 'get_export_cells',\n",
    "    'type': 'FunctionDef',\n",
    "    'source': edge_case_source,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [{'name': 'nb_path', 'annotation': 'Path'}],\n",
    "    'returns': 'List[Dict[str, Any]]'\n",
    "}\n",
    "\n",
    "result_edge = check_definition(test_edge_case)\n",
    "print(\"Edge case - single line with existing return comment:\")\n",
    "print(f\"Compliant: {result_edge.is_compliant}\")\n",
    "print(f\"Missing: {result_edge.missing_params}\")\n",
    "\n",
    "if not result_edge.is_compliant:\n",
    "    fixed_edge = generate_fixed_source(result_edge)\n",
    "    print(\"\\nFixed version (should preserve existing comment with TODO):\")\n",
    "    print(fixed_edge)\n",
    "    \n",
    "    # Verify the fix worked\n",
    "    test_edge_fixed = {\n",
    "        'name': 'get_export_cells',\n",
    "        'type': 'FunctionDef',\n",
    "        'source': fixed_edge,\n",
    "        'notebook': 'test.ipynb',\n",
    "        'args': [{'name': 'nb_path', 'annotation': 'Path'}],\n",
    "        'returns': 'List[Dict[str, Any]]'\n",
    "    }\n",
    "    \n",
    "    result_edge_after = check_definition(test_edge_fixed)\n",
    "    print(f\"\\nAfter fix - Compliant: {result_edge_after.is_compliant}\")\n",
    "    print(f\"After fix - Missing: {result_edge_after.missing_params}\")\n",
    "else:\n",
    "    print(\"Already compliant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataclass:\n",
      "@dataclass\n",
      "class DocmentsCheckResult:\n",
      "    name: str  # Name of the function/class\n",
      "    type: str  # Type (FunctionDef, ClassDef, etc.)\n",
      "    notebook: str  # Source notebook\n",
      "    has_docstring: bool  # Whether it has a docstring\n",
      "    params_documented: Dict[str, bool]  # Which params have documentation\n",
      "    return_documented: bool  # Whether return is documented\n",
      "    missing_params: List[str]  # Parameters missing documentation\n",
      "    is_compliant: bool  # Overall compliance status\n",
      "    source: str  # Source code of the definition\n",
      "    has_todos: bool = False  # Whether it contains TODO placeholders\n",
      "    todo_count: int = 0  # Number of TODO placeholders found\n",
      "\n",
      "Compliant: False\n",
      "Has docstring: False\n",
      "Missing: []\n",
      "\n",
      "Fixed dataclass:\n",
      "@dataclass\n",
      "class DocmentsCheckResult:\n",
      "    \"TODO: Add class description\"\n",
      "    name: str  # Name of the function/class\n",
      "    type: str  # Type (FunctionDef, ClassDef, etc.)\n",
      "    notebook: str  # Source notebook\n",
      "    has_docstring: bool  # Whether it has a docstring\n",
      "    params_documented: Dict[str, bool]  # Which params have documentation\n",
      "    return_documented: bool  # Whether return is documented\n",
      "    missing_params: List[str]  # Parameters missing documentation\n",
      "    is_compliant: bool  # Overall compliance status\n",
      "    source: str  # Source code of the definition\n",
      "    has_todos: bool = False  # Whether it contains TODO placeholders\n",
      "    todo_count: int = 0  # Number of TODO placeholders found\n",
      "\n",
      "Source changed: True\n"
     ]
    }
   ],
   "source": [
    "# Test with a dataclass without docstring\n",
    "dataclass_source = '''@dataclass\n",
    "class DocmentsCheckResult:\n",
    "    name: str  # Name of the function/class\n",
    "    type: str  # Type (FunctionDef, ClassDef, etc.)\n",
    "    notebook: str  # Source notebook\n",
    "    has_docstring: bool  # Whether it has a docstring\n",
    "    params_documented: Dict[str, bool]  # Which params have documentation\n",
    "    return_documented: bool  # Whether return is documented\n",
    "    missing_params: List[str]  # Parameters missing documentation\n",
    "    is_compliant: bool  # Overall compliance status\n",
    "    source: str  # Source code of the definition\n",
    "    has_todos: bool = False  # Whether it contains TODO placeholders\n",
    "    todo_count: int = 0  # Number of TODO placeholders found'''\n",
    "\n",
    "# Create test definition for dataclass\n",
    "test_dataclass = {\n",
    "    'name': 'DocmentsCheckResult',\n",
    "    'type': 'ClassDef',\n",
    "    'source': dataclass_source,\n",
    "    'notebook': 'test.ipynb',\n",
    "    'args': [],  # Classes don't have args in our scanner\n",
    "    'returns': None\n",
    "}\n",
    "\n",
    "# Check it\n",
    "result = check_definition(test_dataclass)\n",
    "print(\"Original dataclass:\")\n",
    "print(result.source)\n",
    "print(f\"\\nCompliant: {result.is_compliant}\")\n",
    "print(f\"Has docstring: {result.has_docstring}\")\n",
    "print(f\"Missing: {result.missing_params}\")\n",
    "\n",
    "# Try to fix it\n",
    "if not result.is_compliant:\n",
    "    fixed = generate_fixed_source(result)\n",
    "    print(\"\\nFixed dataclass:\")\n",
    "    print(fixed)\n",
    "    print(f\"\\nSource changed: {result.source != fixed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
