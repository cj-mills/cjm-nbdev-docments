{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scanner\n",
    "\n",
    "> Scan nbdev notebooks for exported functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp scanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import ast\n",
    "from execnb.nbio import read_nb\n",
    "from fastcore.basics import AttrDict\n",
    "from nbdev.config import get_config\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_export_cells(\n",
    "    nb_path: Path  # Path to the notebook file\n",
    ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
    "    \"Extract all code cells from a notebook that have export directives\"\n",
    "    nb = read_nb(nb_path)\n",
    "    export_cells = []\n",
    "    \n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == 'code' and cell.source:\n",
    "            lines = cell.source.split('\\n')\n",
    "            for line in lines:\n",
    "                if line.strip().startswith('#| export'):\n",
    "                    export_cells.append({\n",
    "                        'cell_id': cell.get('id', None),\n",
    "                        'source': cell.source,\n",
    "                        'idx': cell.idx_ if hasattr(cell, 'idx_') else None\n",
    "                    })\n",
    "                    break\n",
    "    \n",
    "    return export_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extract_definitions(\n",
    "    source: str  # Python source code\n",
    ") -> List[Dict[str, Any]]:  # List of function/class definitions with metadata\n",
    "    \"Extract function and class definitions from source code\"\n",
    "    definitions = []\n",
    "    \n",
    "    # Remove export directive lines\n",
    "    lines = source.split('\\n')\n",
    "    clean_lines = [line for line in lines if not line.strip().startswith('#| ')]\n",
    "    clean_source = '\\n'.join(clean_lines)\n",
    "    \n",
    "    try:\n",
    "        tree = ast.parse(clean_source)\n",
    "        \n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n",
    "                # Get the source lines for this definition\n",
    "                start_line = node.lineno - 1\n",
    "                end_line = node.end_lineno if hasattr(node, 'end_lineno') else start_line + 1\n",
    "                \n",
    "                def_lines = clean_lines[start_line:end_line]\n",
    "                def_source = '\\n'.join(def_lines)\n",
    "                \n",
    "                definition = {\n",
    "                    'name': node.name,\n",
    "                    'type': type(node).__name__,\n",
    "                    'source': def_source,\n",
    "                    'lineno': node.lineno,\n",
    "                    'is_async': isinstance(node, ast.AsyncFunctionDef)\n",
    "                }\n",
    "                \n",
    "                # For functions, extract parameters\n",
    "                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "                    definition['args'] = []\n",
    "                    for arg in node.args.args:\n",
    "                        definition['args'].append({\n",
    "                            'name': arg.arg,\n",
    "                            'annotation': ast.unparse(arg.annotation) if arg.annotation else None\n",
    "                        })\n",
    "                    \n",
    "                    # Add return annotation\n",
    "                    definition['returns'] = ast.unparse(node.returns) if node.returns else None\n",
    "                \n",
    "                definitions.append(definition)\n",
    "                \n",
    "    except SyntaxError as e:\n",
    "        print(f\"Syntax error parsing source: {e}\")\n",
    "        \n",
    "    return definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def scan_notebook(\n",
    "    nb_path: Path  # Path to the notebook to scan\n",
    ") -> List[Dict[str, Any]]:  # List of exported definitions with metadata\n",
    "    \"Scan a notebook and extract all exported function/class definitions\"\n",
    "    export_cells = get_export_cells(nb_path)\n",
    "    all_definitions = []\n",
    "    \n",
    "    for cell in export_cells:\n",
    "        definitions = extract_definitions(cell['source'])\n",
    "        for defn in definitions:\n",
    "            defn['notebook'] = nb_path.name\n",
    "            defn['cell_id'] = cell['cell_id']\n",
    "            all_definitions.append(defn)\n",
    "    \n",
    "    return all_definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def scan_project(\n",
    "    nbs_path: Optional[Path] = None,  # Path to notebooks directory (defaults to config.nbs_path)\n",
    "    pattern: str = \"*.ipynb\"  # Pattern for notebook files to scan\n",
    ") -> List[Dict[str, Any]]:  # All exported definitions found in the project\n",
    "    \"Scan all notebooks in a project for exported definitions\"\n",
    "    if nbs_path is None:\n",
    "        cfg = get_config()\n",
    "        nbs_path = Path(cfg.config_path) / cfg.nbs_path\n",
    "    \n",
    "    nbs_path = Path(nbs_path)\n",
    "    all_definitions = []\n",
    "    \n",
    "    for nb_path in nbs_path.glob(pattern):\n",
    "        if not nb_path.name.startswith('_'):  # Skip private notebooks\n",
    "            try:\n",
    "                definitions = scan_notebook(nb_path)\n",
    "                all_definitions.extend(definitions)\n",
    "            except Exception as e:\n",
    "                print(f\"Error scanning {nb_path}: {e}\")\n",
    "    \n",
    "    return all_definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 exported definitions\n",
      "- ClassDef: DocmentsCheckResult in 00_core.ipynb\n",
      "- FunctionDef: extract_param_docs in 00_core.ipynb\n",
      "- FunctionDef: check_return_doc in 00_core.ipynb\n",
      "- FunctionDef: check_definition in 00_core.ipynb\n",
      "- FunctionDef: check_notebook in 00_core.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Test scanning this project\n",
    "definitions = scan_project()\n",
    "print(f\"Found {len(definitions)} exported definitions\")\n",
    "for defn in definitions[:5]:  # Show first 5\n",
    "    print(f\"- {defn['type']}: {defn['name']} in {defn['notebook']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in: /mnt/SN850X_8TB_EXT4/Projects/GitHub/cj-mills/cjm-nbdev-docments/nbs\n",
      "Found 6 notebooks:\n",
      "  - 00_core.ipynb\n",
      "    Export cells: 7\n",
      "  - 03_autofix.ipynb\n",
      "    Export cells: 3\n",
      "  - 01_scanner.ipynb\n",
      "    Export cells: 5\n",
      "  - index.ipynb\n",
      "    Export cells: 0\n",
      "  - 04_cli.ipynb\n",
      "    Export cells: 2\n",
      "  - 02_report.ipynb\n",
      "    Export cells: 4\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check what notebooks we're finding\n",
    "from nbdev.config import get_config\n",
    "cfg = get_config()\n",
    "nbs_path = Path(cfg.config_path) / cfg.nbs_path\n",
    "notebooks = list(nbs_path.glob(\"*.ipynb\"))\n",
    "print(f\"Looking in: {nbs_path}\")\n",
    "print(f\"Found {len(notebooks)} notebooks:\")\n",
    "for nb in notebooks:\n",
    "    if not nb.name.startswith('_'):\n",
    "        print(f\"  - {nb.name}\")\n",
    "        cells = get_export_cells(nb)\n",
    "        print(f\"    Export cells: {len(cells)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
