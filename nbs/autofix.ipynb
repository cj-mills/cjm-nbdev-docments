{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Fix\n",
    "\n",
    "> Automatically add placeholder documentation to non-compliant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp autofix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import ast\n",
    "from typing import List, Dict, Any, Optional, NamedTuple\n",
    "import re\n",
    "from pathlib import Path\n",
    "from execnb.nbio import read_nb, write_nb\n",
    "from fastcore.foundation import L\n",
    "from fastcore.basics import ifnone, patch, compose\n",
    "from cjm_nbdev_docments.core import DocmentsCheckResult, check_definition\n",
    "from cjm_nbdev_docments.scanner import scan_notebook, get_export_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def needs_fixing(\n",
    "    self: DocmentsCheckResult\n",
    ") -> bool:  # TODO: Add return description\n",
    "    \"Check if this definition needs any fixing\"\n",
    "    return not self.is_compliant or self.missing_params or self.params_missing_type_hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_param_name(\n",
    "    self: DocmentsCheckResult,\n",
    "    param_str: str  # TODO: Add description\n",
    ") -> str:  # TODO: Add return description\n",
    "    \"Extract parameter name from a parameter string\"\n",
    "    return param_str.split(':', 1)[0].split('=', 1)[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch \n",
    "def needs_param_fix(\n",
    "    self: DocmentsCheckResult,\n",
    "    param_name: str  # TODO: Add description\n",
    ") -> bool:  # TODO: Add return description\n",
    "    \"Check if a parameter needs documentation or type hint fixes\"\n",
    "    needs_doc = param_name in self.missing_params and param_name != 'self'\n",
    "    needs_type_hint = param_name in self.params_missing_type_hints and param_name != 'self'\n",
    "    return needs_doc or needs_type_hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def find_signature_boundaries(\n",
    "    lines: List[str]  # Source code lines\n",
    ") -> tuple[int, int]:  # (def_line_idx, sig_end_idx) or (-1, -1) if not found\n",
    "    \"Find the start and end lines of a function signature\"\n",
    "    def_line_idx = None\n",
    "    sig_end_idx = None\n",
    "    paren_count = 0\n",
    "    in_signature = False\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith(('def ', 'async def ')):\n",
    "            def_line_idx = i\n",
    "            in_signature = True\n",
    "            \n",
    "        if in_signature:\n",
    "            # Count parentheses to find where signature ends\n",
    "            paren_count += line.count('(') - line.count(')')\n",
    "            \n",
    "            # If we're back to balanced parens and line contains a colon, signature is done\n",
    "            # (colon might be followed by comments)\n",
    "            if paren_count == 0 and ':' in line:\n",
    "                sig_end_idx = i\n",
    "                break\n",
    "    \n",
    "    # Use ifnone for cleaner null handling\n",
    "    def_line_idx = ifnone(def_line_idx, -1)\n",
    "    sig_end_idx = ifnone(sig_end_idx, -1)\n",
    "    \n",
    "    if def_line_idx == -1 or sig_end_idx == -1:\n",
    "        return -1, -1\n",
    "    \n",
    "    return def_line_idx, sig_end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_parameters(\n",
    "    params_str: str  # Parameter string from function signature\n",
    ") -> List[str]:  # List of individual parameter strings\n",
    "    \"Split a parameter string into individual parameters, handling nested types\"\n",
    "    if not params_str.strip():\n",
    "        return []\n",
    "    \n",
    "    # Use a more robust approach for complex nested types\n",
    "    params = []\n",
    "    current_param = ''\n",
    "    paren_depth = 0\n",
    "    bracket_depth = 0\n",
    "    brace_depth = 0\n",
    "    \n",
    "    for char in params_str:\n",
    "        if char == '(':\n",
    "            paren_depth += 1\n",
    "        elif char == ')':\n",
    "            paren_depth -= 1\n",
    "        elif char == '[':\n",
    "            bracket_depth += 1\n",
    "        elif char == ']':\n",
    "            bracket_depth -= 1\n",
    "        elif char == '{':\n",
    "            brace_depth += 1\n",
    "        elif char == '}':\n",
    "            brace_depth -= 1\n",
    "        elif char == ',' and paren_depth == 0 and bracket_depth == 0 and brace_depth == 0:\n",
    "            params.append(current_param.strip())\n",
    "            current_param = ''\n",
    "            continue\n",
    "        current_param += char\n",
    "    \n",
    "    if current_param.strip():\n",
    "        params.append(current_param.strip())\n",
    "    \n",
    "    # Return as L for easier manipulation\n",
    "    return L(params).filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_single_line_signature(\n",
    "    sig_line: str  # Single-line function signature\n",
    ") -> dict:  # Parsed components of the signature\n",
    "    \"Parse a single-line function signature into its components\"\n",
    "    func_match = re.match(r'^(\\s*)(def|async def)\\s+(\\w+)\\s*\\((.*?)\\)(\\s*(?:->\\s*[^:]+)?)\\s*:\\s*(.*)$', sig_line)\n",
    "    if not func_match:\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        'indent': func_match.group(1),\n",
    "        'def_keyword': func_match.group(2),\n",
    "        'func_name': func_match.group(3),\n",
    "        'params_str': func_match.group(4),\n",
    "        'return_type': func_match.group(5),\n",
    "        'existing_comment': func_match.group(6).strip()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_param_todo_comment(\n",
    "    param_name: str,  # Parameter name\n",
    "    result: DocmentsCheckResult,  # Check result with type hint and doc info\n",
    "    existing_comment: str = \"\"  # Existing comment text (without #)\n",
    ") -> str:  # TODO comment to add\n",
    "    \"Generate appropriate TODO comment for a parameter based on what's missing\"\n",
    "    has_type_hint = result.params_with_type_hints.get(param_name, False)\n",
    "    has_doc = result.params_documented.get(param_name, False)\n",
    "    \n",
    "    if not has_type_hint and not has_doc:\n",
    "        # Missing both type hint and description\n",
    "        return \"TODO: Add type hint and description\"\n",
    "    elif not has_type_hint and has_doc:\n",
    "        # Has description but missing type hint\n",
    "        if existing_comment:\n",
    "            # Check if TODO for type hint already exists\n",
    "            if \"TODO: Add type hint\" in existing_comment or \"TODO:Add type hint\" in existing_comment:\n",
    "                return existing_comment  # Don't add duplicate TODO\n",
    "            else:\n",
    "                return f\"{existing_comment} - TODO: Add type hint\"\n",
    "        else:\n",
    "            return \"TODO: Add type hint\"\n",
    "    elif has_type_hint and not has_doc:\n",
    "        # Has type hint but missing description\n",
    "        return \"TODO: Add description\"\n",
    "    else:\n",
    "        # This shouldn't happen if we're being asked to generate a comment\n",
    "        return existing_comment if existing_comment else \"TODO: Verify documentation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_return_todo_comment(\n",
    "    result: DocmentsCheckResult,  # Check result with type hint and doc info\n",
    "    existing_comment: str = \"\"  # Existing comment text (without #)\n",
    ") -> str:  # TODO comment to add\n",
    "    \"Generate appropriate TODO comment for return value based on what's missing\"\n",
    "    has_type_hint = result.return_has_type_hint\n",
    "    has_doc = result.return_documented\n",
    "    \n",
    "    if not has_type_hint and not has_doc:\n",
    "        # Missing both type hint and description\n",
    "        return \"TODO: Add type hint and return description\"\n",
    "    elif not has_type_hint and has_doc:\n",
    "        # Has description but missing type hint\n",
    "        if existing_comment:\n",
    "            # Check if TODO for type hint already exists\n",
    "            if \"TODO: Add type hint\" in existing_comment or \"TODO:Add type hint\" in existing_comment:\n",
    "                return existing_comment  # Don't add duplicate TODO\n",
    "            else:\n",
    "                return f\"{existing_comment} - TODO: Add type hint\"\n",
    "        else:\n",
    "            return \"TODO: Add type hint\"\n",
    "    elif has_type_hint and not has_doc:\n",
    "        # Has type hint but missing description\n",
    "        return \"TODO: Add return description\"\n",
    "    else:\n",
    "        # This shouldn't happen if we're being asked to generate a comment\n",
    "        return existing_comment if existing_comment else \"TODO: Verify description\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def build_fixed_single_line_function(\n",
    "    parsed: dict,  # Parsed signature components\n",
    "    params: List[str],  # Individual parameter strings\n",
    "    result: DocmentsCheckResult  # Check result with missing params info\n",
    ") -> List[str]:  # Lines of fixed function signature\n",
    "    \"Build a fixed single-line function with documentation comments\"\n",
    "    fixed_lines = []\n",
    "    indent = parsed['indent']\n",
    "    \n",
    "    # Start the function definition\n",
    "    fixed_lines.append(f\"{indent}{parsed['def_keyword']} {parsed['func_name']}(\")\n",
    "    \n",
    "    # Add parameters with comments as needed\n",
    "    for i, param in enumerate(params):\n",
    "        # Use patch method to get parameter name\n",
    "        param_name = result.get_param_name(param)\n",
    "        \n",
    "        # Use patch method to check if needs fixing\n",
    "        if result.needs_param_fix(param_name):\n",
    "            todo_comment = generate_param_todo_comment(param_name, result)\n",
    "            if i < len(params) - 1:\n",
    "                fixed_lines.append(f\"{indent}    {param},  # {todo_comment}\")\n",
    "            else:\n",
    "                fixed_lines.append(f\"{indent}    {param}  # {todo_comment}\")\n",
    "        else:\n",
    "            if i < len(params) - 1:\n",
    "                fixed_lines.append(f\"{indent}    {param},\")\n",
    "            else:\n",
    "                fixed_lines.append(f\"{indent}    {param}\")\n",
    "    \n",
    "    # Handle return type and existing comment\n",
    "    return_type = parsed['return_type']\n",
    "    existing_comment = parsed['existing_comment']\n",
    "    \n",
    "    # Check if return type is None (no return value)\n",
    "    is_none_return = return_type and 'None' in return_type.strip()\n",
    "    \n",
    "    # For single-line conversions, check if return needs fixing\n",
    "    if return_type:\n",
    "        # Skip adding TODO comments for functions with return type None\n",
    "        if not is_none_return and ('return' in result.missing_params or 'return' in result.params_missing_type_hints):\n",
    "            if existing_comment:\n",
    "                # Parse existing comment\n",
    "                comment_text = existing_comment[1:].strip() if existing_comment.startswith('#') else existing_comment\n",
    "                todo_comment = generate_return_todo_comment(result, comment_text)\n",
    "                fixed_lines.append(f\"{indent}){return_type}: # {todo_comment}\")\n",
    "            else:\n",
    "                # No existing comment\n",
    "                todo_comment = generate_return_todo_comment(result)\n",
    "                fixed_lines.append(f\"{indent}){return_type}:  # {todo_comment}\")\n",
    "        else:\n",
    "            # Return doesn't need fixing OR is None type\n",
    "            if existing_comment:\n",
    "                if existing_comment.startswith('#'):\n",
    "                    fixed_lines.append(f\"{indent}){return_type}: {existing_comment}\")\n",
    "                else:\n",
    "                    fixed_lines.append(f\"{indent}){return_type}: # {existing_comment}\")\n",
    "            else:\n",
    "                fixed_lines.append(f\"{indent}){return_type}:\")\n",
    "    else:\n",
    "        # No return type but might need one\n",
    "        if 'return' in result.params_missing_type_hints:\n",
    "            if existing_comment:\n",
    "                comment_text = existing_comment[1:].strip() if existing_comment.startswith('#') else existing_comment\n",
    "                todo_comment = generate_return_todo_comment(result, comment_text)\n",
    "                fixed_lines.append(f\"{indent}): # {todo_comment}\")\n",
    "            else:\n",
    "                todo_comment = generate_return_todo_comment(result)\n",
    "                fixed_lines.append(f\"{indent}): # {todo_comment}\")\n",
    "        else:\n",
    "            # No return type needed\n",
    "            if existing_comment:\n",
    "                if existing_comment.startswith('#'):\n",
    "                    fixed_lines.append(f\"{indent}): {existing_comment}\")\n",
    "                else:\n",
    "                    fixed_lines.append(f\"{indent}): # {existing_comment}\")\n",
    "            else:\n",
    "                fixed_lines.append(f\"{indent}):\")\n",
    "    \n",
    "    return fixed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fix_multi_line_signature(\n",
    "    lines: List[str],  # All source lines\n",
    "    def_line_idx: int,  # Start of function definition\n",
    "    sig_end_idx: int,  # End of function signature\n",
    "    result: DocmentsCheckResult  # Check result with missing params info\n",
    ") -> List[str]:  # Fixed lines for the signature portion\n",
    "    \"Fix a multi-line function signature by adding parameter comments\"\n",
    "    fixed_lines = []\n",
    "    \n",
    "    for i in range(def_line_idx, sig_end_idx + 1):\n",
    "        line = lines[i]\n",
    "        line_stripped = line.strip()\n",
    "        \n",
    "        # More flexible parameter matching for multi-line signatures\n",
    "        # Match: whitespace + word + optional type annotation + optional comma/paren + optional whitespace + optional comment\n",
    "        param_match = re.match(r'^(\\s*)(\\w+)(\\s*(?::\\s*[^,\\)#]+)?)\\s*([,\\)]?)(\\s*)(?:#\\s*(.*))?$', line)\n",
    "        if param_match and i > def_line_idx and i < sig_end_idx:\n",
    "            # This is a parameter line (not the def line, not the return line)\n",
    "            indent = param_match.group(1)\n",
    "            param_name = param_match.group(2)\n",
    "            type_annotation = param_match.group(3) or ''\n",
    "            trailing_punct = param_match.group(4) or ''\n",
    "            trailing_space = param_match.group(5) or ''\n",
    "            existing_comment = param_match.group(6) or ''\n",
    "            \n",
    "            # Check if this parameter needs fixing (either missing docs or missing type hints)\n",
    "            needs_doc_fix = param_name in result.missing_params and param_name != 'self'\n",
    "            needs_type_hint_fix = param_name in result.params_missing_type_hints and param_name != 'self'\n",
    "            \n",
    "            if needs_doc_fix or needs_type_hint_fix:\n",
    "                todo_comment = generate_param_todo_comment(param_name, result, existing_comment)\n",
    "                # Only add the fixed line if the comment actually changed\n",
    "                if todo_comment != existing_comment:\n",
    "                    fixed_lines.append(f\"{indent}{param_name}{type_annotation}{trailing_punct}{trailing_space}  # {todo_comment}\")\n",
    "                else:\n",
    "                    # Comment didn't change, keep original line\n",
    "                    fixed_lines.append(line)\n",
    "            else:\n",
    "                fixed_lines.append(line)\n",
    "        else:\n",
    "            # Check for return type line\n",
    "            return_match = re.match(r'^(\\s*\\)\\s*->\\s*[^:#]+)\\s*:\\s*(.*)$', line)\n",
    "            if return_match:\n",
    "                pre_colon = return_match.group(1)\n",
    "                after_colon = return_match.group(2).strip()\n",
    "                \n",
    "                # Check if return type is None (no return value)\n",
    "                is_none_return = 'None' in pre_colon\n",
    "                \n",
    "                # Skip adding TODO comments for functions with return type None\n",
    "                if not is_none_return and ('return' in result.missing_params or 'return' in result.params_missing_type_hints):\n",
    "                    if after_colon:\n",
    "                        # There's already a comment, generate appropriate TODO\n",
    "                        comment_text = after_colon[1:].strip() if after_colon.startswith('#') else after_colon\n",
    "                        todo_comment = generate_return_todo_comment(result, comment_text)\n",
    "                        # Only change if the comment actually changed\n",
    "                        if todo_comment != comment_text:\n",
    "                            fixed_lines.append(f\"{pre_colon}: # {todo_comment}\")\n",
    "                        else:\n",
    "                            fixed_lines.append(line)\n",
    "                    else:\n",
    "                        # No comment, add full TODO\n",
    "                        todo_comment = generate_return_todo_comment(result)\n",
    "                        fixed_lines.append(f\"{pre_colon}:  # {todo_comment}\")\n",
    "                else:\n",
    "                    fixed_lines.append(line)\n",
    "            else:\n",
    "                fixed_lines.append(line)\n",
    "    \n",
    "    return fixed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fix_class_definition(\n",
    "    result: DocmentsCheckResult  # Check result with non-compliant class\n",
    ") -> str:  # Fixed source code with class docstring\n",
    "    \"Fix a class definition by adding a docstring if missing\"\n",
    "    lines = result.source.split('\\n')\n",
    "    fixed_lines = []\n",
    "    \n",
    "    # Find the class definition line\n",
    "    class_line_idx = -1\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith('class '):\n",
    "            class_line_idx = i\n",
    "            break\n",
    "    \n",
    "    if class_line_idx == -1:\n",
    "        return result.source\n",
    "    \n",
    "    # Add lines up to and including the class definition\n",
    "    for i in range(class_line_idx + 1):\n",
    "        fixed_lines.append(lines[i])\n",
    "    \n",
    "    # If missing docstring, add it after the class definition\n",
    "    if not result.has_docstring:\n",
    "        # Find the indentation of the first line after class definition\n",
    "        indent = '    '  # Default\n",
    "        if class_line_idx + 1 < len(lines):\n",
    "            next_line = lines[class_line_idx + 1]\n",
    "            # Match leading whitespace\n",
    "            indent_match = re.match(r'^(\\s*)', next_line)\n",
    "            indent = ifnone(indent_match.group(1) if indent_match else None, '    ')\n",
    "        \n",
    "        fixed_lines.append(f'{indent}\"TODO: Add class description\"')\n",
    "    \n",
    "    # Add the rest of the class body\n",
    "    for i in range(class_line_idx + 1, len(lines)):\n",
    "        fixed_lines.append(lines[i])\n",
    "    \n",
    "    return '\\n'.join(fixed_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def insert_function_docstring(\n",
    "    lines: List[str],  # Fixed function lines\n",
    "    def_line_idx: int,  # Index of function definition line\n",
    "    indent: str  # Base indentation for the function\n",
    ") -> List[str]:  # Lines with docstring inserted\n",
    "    \"Insert a TODO docstring after the function signature\"\n",
    "    # Find the signature end (last line before function body)\n",
    "    sig_end_idx = def_line_idx\n",
    "    for i in range(def_line_idx, len(lines)):\n",
    "        if lines[i].rstrip().endswith(':'):\n",
    "            sig_end_idx = i\n",
    "            break\n",
    "    \n",
    "    # Insert docstring after signature\n",
    "    result_lines = []\n",
    "    for i in range(sig_end_idx + 1):\n",
    "        result_lines.append(lines[i])\n",
    "    \n",
    "    # Add the docstring\n",
    "    docstring_indent = indent + '    '\n",
    "    result_lines.append(f'{docstring_indent}\"TODO: Add function description\"')\n",
    "    \n",
    "    # Add the rest of the function body\n",
    "    for i in range(sig_end_idx + 1, len(lines)):\n",
    "        result_lines.append(lines[i])\n",
    "    \n",
    "    return result_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fix_single_line_function(\n",
    "    lines: List[str],  # All source lines\n",
    "    def_line_idx: int,  # Index of function definition line\n",
    "    result: DocmentsCheckResult  # Check result with missing params info\n",
    ") -> List[str]:  # Fixed lines for the function\n",
    "    \"Fix a single-line function signature by converting to multi-line with parameter comments\"\n",
    "    # Parse the signature\n",
    "    parsed = parse_single_line_signature(lines[def_line_idx])\n",
    "    if not parsed:\n",
    "        return lines\n",
    "    \n",
    "    # Split parameters\n",
    "    params = split_parameters(parsed['params_str'])\n",
    "    \n",
    "    # Build the fixed function signature\n",
    "    fixed_signature_lines = build_fixed_single_line_function(parsed, params, result)\n",
    "    \n",
    "    # Combine with rest of function\n",
    "    fixed_lines = []\n",
    "    # Add lines before the function\n",
    "    for i in range(def_line_idx):\n",
    "        fixed_lines.append(lines[i])\n",
    "    \n",
    "    # Add the fixed signature\n",
    "    fixed_lines.extend(fixed_signature_lines)\n",
    "    \n",
    "    # Add docstring if missing\n",
    "    if not result.has_docstring:\n",
    "        docstring_indent = parsed['indent'] + '    '\n",
    "        fixed_lines.append(f'{docstring_indent}\"TODO: Add function description\"')\n",
    "    \n",
    "    # Add lines after the function definition\n",
    "    for i in range(def_line_idx + 1, len(lines)):\n",
    "        fixed_lines.append(lines[i])\n",
    "    \n",
    "    return fixed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fix_multi_line_function(\n",
    "    lines: List[str],  # All source lines\n",
    "    def_line_idx: int,  # Start of function definition\n",
    "    sig_end_idx: int,  # End of function signature\n",
    "    result: DocmentsCheckResult  # Check result with missing params info\n",
    ") -> List[str]:  # Fixed lines for the function\n",
    "    \"Fix a multi-line function signature by adding parameter comments\"\n",
    "    fixed_lines = []\n",
    "    \n",
    "    # Add lines before the function\n",
    "    for i in range(def_line_idx):\n",
    "        fixed_lines.append(lines[i])\n",
    "    \n",
    "    # Fix the signature\n",
    "    signature_lines = fix_multi_line_signature(lines, def_line_idx, sig_end_idx, result)\n",
    "    fixed_lines.extend(signature_lines)\n",
    "    \n",
    "    # Check if the function already has a docstring by looking at the first non-empty line after signature\n",
    "    has_existing_docstring = False\n",
    "    if sig_end_idx + 1 < len(lines):\n",
    "        for i in range(sig_end_idx + 1, len(lines)):\n",
    "            line_stripped = lines[i].strip()\n",
    "            if line_stripped:  # First non-empty line\n",
    "                # Check if it's a docstring\n",
    "                if line_stripped.startswith(('\"\"\"', \"'''\", '\"', \"'\")):\n",
    "                    has_existing_docstring = True\n",
    "                break\n",
    "    \n",
    "    # Insert docstring if missing AND not already present\n",
    "    if not result.has_docstring and not has_existing_docstring:\n",
    "        # Find the indentation of the function definition\n",
    "        indent_match = re.match(r'^(\\s*)', lines[def_line_idx])\n",
    "        base_indent = indent_match.group(1) if indent_match else ''\n",
    "        docstring_indent = base_indent + '    '\n",
    "        fixed_lines.append(f'{docstring_indent}\"TODO: Add function description\"')\n",
    "    \n",
    "    # Add rest of function body\n",
    "    for i in range(sig_end_idx + 1, len(lines)):\n",
    "        fixed_lines.append(lines[i])\n",
    "    \n",
    "    return fixed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_fixed_source(\n",
    "    result: DocmentsCheckResult  # Check result with non-compliant function\n",
    ") -> str:  # Fixed source code with placeholder documentation\n",
    "    \"Generate fixed source code for a non-compliant function or class\"\n",
    "    # Handle classes (including dataclasses)\n",
    "    if result.type == 'ClassDef':\n",
    "        return fix_class_definition(result)\n",
    "    \n",
    "    # Use the patch method to check if fixing is needed\n",
    "    if not result.needs_fixing():\n",
    "        return result.source\n",
    "    \n",
    "    lines = result.source.split('\\n')\n",
    "    \n",
    "    # Find the function definition line and signature end\n",
    "    def_line_idx, sig_end_idx = find_signature_boundaries(lines)\n",
    "    \n",
    "    if def_line_idx == -1:\n",
    "        return result.source\n",
    "    \n",
    "    # Choose the appropriate fix method based on signature type\n",
    "    if def_line_idx == sig_end_idx and (result.missing_params or result.params_missing_type_hints):\n",
    "        # Single-line signature that needs parameter fixing\n",
    "        fixed_lines = fix_single_line_function(lines, def_line_idx, result)\n",
    "    else:\n",
    "        # Multi-line signature \n",
    "        fixed_lines = fix_multi_line_function(lines, def_line_idx, sig_end_idx, result)\n",
    "    \n",
    "    return '\\n'.join(fixed_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fix_notebook(\n",
    "    nb_path: Path,  # Path to notebook to fix\n",
    "    dry_run: bool = False  # If True, show changes without saving\n",
    ") -> Dict[str, Any]:  # Summary of changes made\n",
    "    \"Fix non-compliant functions in a notebook by adding placeholder documentation\"\n",
    "    nb = read_nb(nb_path)\n",
    "    definitions = scan_notebook(nb_path)\n",
    "    \n",
    "    changes = {\n",
    "        'notebook': nb_path.name,\n",
    "        'definitions_fixed': [],\n",
    "        'cells_modified': []\n",
    "    }\n",
    "    \n",
    "    # Check each definition\n",
    "    for defn in definitions:\n",
    "        result = check_definition(defn)\n",
    "        \n",
    "        # Fix if non-compliant OR has missing type hints\n",
    "        needs_fixing = (not result.is_compliant or \n",
    "                       result.missing_params or \n",
    "                       result.params_missing_type_hints)\n",
    "        \n",
    "        if needs_fixing:\n",
    "            # Generate fixed source\n",
    "            fixed_source = generate_fixed_source(result)\n",
    "            \n",
    "            # Only proceed if the source actually changed\n",
    "            if fixed_source != result.source:\n",
    "                # Find and update the cell\n",
    "                cell_id = defn['cell_id']\n",
    "                for cell in nb.cells:\n",
    "                    if cell.get('id') == cell_id:\n",
    "                        # Replace the definition in the cell source\n",
    "                        old_source = result.source\n",
    "                        cell_source = cell.source\n",
    "                        \n",
    "                        # Find the definition in the cell and replace it\n",
    "                        if old_source in cell_source:\n",
    "                            new_cell_source = cell_source.replace(old_source, fixed_source)\n",
    "                            \n",
    "                            if not dry_run:\n",
    "                                cell.source = new_cell_source\n",
    "                            \n",
    "                            changes['definitions_fixed'].append(result.name)\n",
    "                            if cell_id not in changes['cells_modified']:\n",
    "                                changes['cells_modified'].append(cell_id)\n",
    "                            \n",
    "                            if dry_run:\n",
    "                                print(f\"\\nWould fix {result.name}:\")\n",
    "                                print(\"-\" * 40)\n",
    "                                print(fixed_source)\n",
    "                                print(\"-\" * 40)\n",
    "    \n",
    "    # Save the notebook if not dry run\n",
    "    if not dry_run and changes['definitions_fixed']:\n",
    "        write_nb(nb, nb_path)\n",
    "        # Fix grammar: use singular/plural based on count\n",
    "        count = len(changes['definitions_fixed'])\n",
    "        item_word = \"definition\" if count == 1 else \"definitions\"\n",
    "        print(f\"✅ Fixed {count} {item_word} in {nb_path.name}\")\n",
    "        for defn_name in changes['definitions_fixed']:\n",
    "            print(f\"   - {defn_name}\")\n",
    "    elif dry_run and changes['definitions_fixed']:\n",
    "        count = len(changes['definitions_fixed'])\n",
    "        item_word = \"definition\" if count == 1 else \"definitions\" \n",
    "        print(f\"\\n🔍 Dry run: Would fix {count} {item_word}\")\n",
    "    else:\n",
    "        print(f\"✅ All definitions in {nb_path.name} are already compliant\")\n",
    "    \n",
    "    return changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DocstringInfo(NamedTuple):\n",
    "    \"\"\"Information extracted from a docstring\"\"\"\n",
    "    description: str  # Main function description\n",
    "    params: Dict[str, str]  # Parameter name -> description\n",
    "    returns: Optional[str]  # Return description\n",
    "    docstring_type: str  # Type of docstring (google, numpy, sphinx, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def detect_docstring_style(\n",
    "    docstring: str  # Docstring text to analyze\n",
    ") -> str:  # Detected style: 'google', 'numpy', 'sphinx', 'docments', or 'unknown'\n",
    "    \"Detect the style of a docstring\"\n",
    "    if not docstring:\n",
    "        return 'unknown'\n",
    "    \n",
    "    docstring = docstring.strip()\n",
    "    \n",
    "    # Check for Google style (Args:, Returns:, etc.)\n",
    "    if re.search(r'(Args?|Arguments?|Parameters?|Params?|Returns?|Return|Yields?|Yield|Raises?|Raise|Note|Notes|Example|Examples):\\s*$', docstring, re.MULTILINE):\n",
    "        return 'google'\n",
    "    \n",
    "    # Check for NumPy style (Parameters\\n----------)\n",
    "    if re.search(r'(Parameters?|Returns?|Yields?|Raises?|See Also|Notes?|References?|Examples?)\\s*\\n\\s*-{3,}', docstring, re.MULTILINE):\n",
    "        return 'numpy'\n",
    "    \n",
    "    # Check for Sphinx style (:param, :type, :returns, etc.)\n",
    "    if re.search(r':(param|type|returns?|rtype|raises?|note|example)(\\s+\\w+)?:', docstring, re.MULTILINE):\n",
    "        return 'sphinx'\n",
    "    \n",
    "    # Check if already in docments style (very simple check)\n",
    "    # This would be harder to detect since docments puts docs inline\n",
    "    # For now, assume unknown if none of the above patterns match\n",
    "    return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_google_docstring(\n",
    "    docstring: str  # Google-style docstring text\n",
    ") -> DocstringInfo:  # Parsed docstring information\n",
    "    \"Parse a Google-style docstring\"\n",
    "    params = {}\n",
    "    returns = None\n",
    "    description_lines = []\n",
    "    \n",
    "    # Clean the docstring - remove triple quotes and normalize\n",
    "    cleaned = docstring.strip()\n",
    "    if cleaned.startswith('\"\"\"') or cleaned.startswith(\"'''\"):\n",
    "        cleaned = cleaned[3:]\n",
    "    if cleaned.endswith('\"\"\"') or cleaned.endswith(\"'''\"):\n",
    "        cleaned = cleaned[:-3]\n",
    "    \n",
    "    lines = cleaned.split('\\n')\n",
    "    current_section = None\n",
    "    current_param = None\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Check for section headers\n",
    "        if re.match(r'^(Args?|Arguments?|Parameters?|Params?):\\s*$', line):\n",
    "            current_section = 'params'\n",
    "            continue\n",
    "        elif re.match(r'^(Returns?|Return):\\s*$', line):\n",
    "            current_section = 'returns'\n",
    "            continue\n",
    "        elif re.match(r'^(Yields?|Yield|Raises?|Raise|Note|Notes|Example|Examples):\\s*$', line):\n",
    "            current_section = 'other'\n",
    "            continue\n",
    "        \n",
    "        # Process content based on current section\n",
    "        if current_section == 'params':\n",
    "            # Look for parameter definitions: \"param_name (type): description\"\n",
    "            param_match = re.match(r'^(\\w+)\\s*(?:\\([^)]+\\))?\\s*:\\s*(.+)$', line)\n",
    "            if param_match:\n",
    "                param_name = param_match.group(1)\n",
    "                param_desc = param_match.group(2)\n",
    "                params[param_name] = param_desc\n",
    "                current_param = param_name\n",
    "            elif current_param and line:\n",
    "                # Continuation of previous parameter description\n",
    "                params[current_param] += ' ' + line\n",
    "        elif current_section == 'returns':\n",
    "            if line:\n",
    "                if returns is None:\n",
    "                    returns = line\n",
    "                else:\n",
    "                    returns += ' ' + line\n",
    "        elif current_section is None:\n",
    "            # This is part of the main description\n",
    "            if line:\n",
    "                description_lines.append(line)\n",
    "    \n",
    "    description = ' '.join(description_lines)\n",
    "    return DocstringInfo(description, params, returns, 'google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_numpy_docstring(\n",
    "    docstring: str  # NumPy-style docstring text\n",
    ") -> DocstringInfo:  # Parsed docstring information\n",
    "    \"Parse a NumPy-style docstring\"\n",
    "    params = {}\n",
    "    returns = None\n",
    "    description_lines = []\n",
    "    \n",
    "    # Clean the docstring - remove triple quotes and normalize\n",
    "    cleaned = docstring.strip()\n",
    "    if cleaned.startswith('\"\"\"') or cleaned.startswith(\"'''\"):\n",
    "        cleaned = cleaned[3:]\n",
    "    if cleaned.endswith('\"\"\"') or cleaned.endswith(\"'''\"):\n",
    "        cleaned = cleaned[:-3]\n",
    "    \n",
    "    lines = cleaned.split('\\n')\n",
    "    current_section = None\n",
    "    current_param = None\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        line_stripped = line.strip()\n",
    "        \n",
    "        # Check for section headers (followed by dashes)\n",
    "        if i + 1 < len(lines) and re.match(r'^-{3,}$', lines[i + 1].strip()):\n",
    "            if re.match(r'^(Parameters?|Params?)$', line_stripped):\n",
    "                current_section = 'params'\n",
    "                continue\n",
    "            elif re.match(r'^(Returns?|Return)$', line_stripped):\n",
    "                current_section = 'returns'\n",
    "                continue\n",
    "            elif re.match(r'^(Yields?|Raises?|See Also|Notes?|References?|Examples?)$', line_stripped):\n",
    "                current_section = 'other'\n",
    "                continue\n",
    "        \n",
    "        # Skip the dashes line\n",
    "        if re.match(r'^-{3,}$', line_stripped):\n",
    "            continue\n",
    "        \n",
    "        # Process content based on current section\n",
    "        if current_section == 'params':\n",
    "            # Look for parameter definitions: \"param_name : type\" followed by description\n",
    "            param_match = re.match(r'^(\\w+)\\s*:\\s*(.+)$', line_stripped)\n",
    "            if param_match:\n",
    "                param_name = param_match.group(1)\n",
    "                # The type information is on the same line, description usually follows\n",
    "                current_param = param_name\n",
    "                params[param_name] = ''\n",
    "            elif current_param and line_stripped:\n",
    "                # Description line for the current parameter\n",
    "                if params[current_param]:\n",
    "                    params[current_param] += ' ' + line_stripped\n",
    "                else:\n",
    "                    params[current_param] = line_stripped\n",
    "        elif current_section == 'returns':\n",
    "            if line_stripped:\n",
    "                if returns is None:\n",
    "                    returns = line_stripped\n",
    "                else:\n",
    "                    returns += ' ' + line_stripped\n",
    "        elif current_section is None:\n",
    "            # This is part of the main description\n",
    "            if line_stripped:\n",
    "                description_lines.append(line_stripped)\n",
    "    \n",
    "    description = ' '.join(description_lines)\n",
    "    return DocstringInfo(description, params, returns, 'numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_sphinx_docstring(\n",
    "    docstring: str  # Sphinx-style docstring text\n",
    ") -> DocstringInfo:  # Parsed docstring information\n",
    "    \"Parse a Sphinx-style docstring\"\n",
    "    params = {}\n",
    "    returns = None\n",
    "    description_lines = []\n",
    "    \n",
    "    lines = docstring.split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Check for parameter definitions: \":param param_name: description\"\n",
    "        param_match = re.match(r'^:param\\s+(\\w+)\\s*:\\s*(.+)$', line)\n",
    "        if param_match:\n",
    "            param_name = param_match.group(1)\n",
    "            param_desc = param_match.group(2)\n",
    "            params[param_name] = param_desc\n",
    "            continue\n",
    "        \n",
    "        # Check for return definitions: \":returns: description\" or \":return: description\"\n",
    "        return_match = re.match(r'^:returns?\\s*:\\s*(.+)$', line)\n",
    "        if return_match:\n",
    "            returns = return_match.group(1)\n",
    "            continue\n",
    "        \n",
    "        # Skip other sphinx directives\n",
    "        if re.match(r'^:\\w+(\\s+\\w+)?:', line):\n",
    "            continue\n",
    "        \n",
    "        # This is part of the main description\n",
    "        if line:\n",
    "            description_lines.append(line)\n",
    "    \n",
    "    description = ' '.join(description_lines)\n",
    "    return DocstringInfo(description, params, returns, 'sphinx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extract_docstring_info(\n",
    "    source: str,  # Function source code\n",
    "    name: str  # Function name\n",
    ") -> Optional[DocstringInfo]:  # Extracted docstring information or None\n",
    "    \"Extract docstring information from function source code\"\n",
    "    try:\n",
    "        tree = ast.parse(source)\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "                if node.name == name and node.body:\n",
    "                    # Check if first statement is a docstring\n",
    "                    first_stmt = node.body[0]\n",
    "                    if (isinstance(first_stmt, ast.Expr) and \n",
    "                        isinstance(first_stmt.value, (ast.Str, ast.Constant))):\n",
    "                        \n",
    "                        # Extract docstring text\n",
    "                        if hasattr(first_stmt.value, 's'):\n",
    "                            docstring = first_stmt.value.s\n",
    "                        elif hasattr(first_stmt.value, 'value'):\n",
    "                            docstring = first_stmt.value.value\n",
    "                        else:\n",
    "                            return None\n",
    "                        \n",
    "                        if not isinstance(docstring, str):\n",
    "                            return None\n",
    "                        \n",
    "                        # Detect and parse the docstring style\n",
    "                        style = detect_docstring_style(docstring)\n",
    "                        \n",
    "                        if style == 'google':\n",
    "                            return parse_google_docstring(docstring)\n",
    "                        elif style == 'numpy':\n",
    "                            return parse_numpy_docstring(docstring)\n",
    "                        elif style == 'sphinx':\n",
    "                            return parse_sphinx_docstring(docstring)\n",
    "                        else:\n",
    "                            # Unknown style, return basic info\n",
    "                            return DocstringInfo(docstring.strip(), {}, None, 'unknown')\n",
    "                    break\n",
    "    except Exception:\n",
    "        return None\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_to_docments_format(\n",
    "    source: str,  # Original function source code\n",
    "    docstring_info: DocstringInfo,  # Extracted docstring information\n",
    "    result: DocmentsCheckResult  # Check result with missing params info\n",
    ") -> str:  # Converted source code in docments format\n",
    "    \"Convert function source to docments format using extracted docstring info\"\n",
    "    lines = source.split('\\n')\n",
    "    \n",
    "    # Find the function definition line and signature end\n",
    "    def_line_idx, sig_end_idx = find_signature_boundaries(lines)\n",
    "    \n",
    "    if def_line_idx == -1:\n",
    "        return source\n",
    "    \n",
    "    # Build the new function with docments-style documentation\n",
    "    fixed_lines = []\n",
    "    \n",
    "    # Add lines before the function\n",
    "    for i in range(def_line_idx):\n",
    "        fixed_lines.append(lines[i])\n",
    "    \n",
    "    # Convert single-line to multi-line if needed or fix existing multi-line\n",
    "    if def_line_idx == sig_end_idx:\n",
    "        # Single-line signature - convert to multi-line with docments comments\n",
    "        fixed_lines.extend(convert_single_line_to_docments(lines[def_line_idx], docstring_info, result))\n",
    "    else:\n",
    "        # Multi-line signature - add docments comments to existing structure\n",
    "        fixed_lines.extend(convert_multiline_to_docments(lines[def_line_idx:sig_end_idx+1], docstring_info, result))\n",
    "    \n",
    "    # Replace the original docstring with the description only\n",
    "    body_start_idx = sig_end_idx + 1\n",
    "    if body_start_idx < len(lines):\n",
    "        # Find the docstring in the function body and replace it\n",
    "        body_lines = lines[body_start_idx:]\n",
    "        new_body_lines = replace_docstring_in_body(body_lines, docstring_info.description, lines[def_line_idx])\n",
    "        fixed_lines.extend(new_body_lines)\n",
    "    \n",
    "    return '\\n'.join(fixed_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_single_line_to_docments(\n",
    "    sig_line: str,  # Single-line function signature\n",
    "    docstring_info: DocstringInfo,  # Extracted docstring information\n",
    "    result: DocmentsCheckResult  # Check result with missing params info\n",
    ") -> List[str]:  # Multi-line signature with docments comments\n",
    "    \"Convert single-line function signature to multi-line docments format\"\n",
    "    \n",
    "    # Parse the signature\n",
    "    parsed = parse_single_line_signature(sig_line)\n",
    "    if not parsed:\n",
    "        return [sig_line]\n",
    "    \n",
    "    # Split parameters\n",
    "    params = split_parameters(parsed['params_str'])\n",
    "    \n",
    "    # Build the new signature\n",
    "    fixed_lines = []\n",
    "    indent = parsed['indent']\n",
    "    \n",
    "    # Start the function definition\n",
    "    fixed_lines.append(f\"{indent}{parsed['def_keyword']} {parsed['func_name']}(\")\n",
    "    \n",
    "    # Add parameters with docments comments\n",
    "    for i, param in enumerate(params):\n",
    "        param_name = result.get_param_name(param)\n",
    "        \n",
    "        # Get documentation from the extracted docstring info\n",
    "        param_doc = docstring_info.params.get(param_name, '')\n",
    "        \n",
    "        if param_doc:\n",
    "            # Use the extracted documentation\n",
    "            if i < len(params) - 1:\n",
    "                fixed_lines.append(f\"{indent}    {param},  # {param_doc}\")\n",
    "            else:\n",
    "                fixed_lines.append(f\"{indent}    {param}  # {param_doc}\")\n",
    "        else:\n",
    "            # No documentation found, add TODO\n",
    "            if param_name in result.missing_params:\n",
    "                todo_comment = generate_param_todo_comment(param_name, result)\n",
    "                if i < len(params) - 1:\n",
    "                    fixed_lines.append(f\"{indent}    {param},  # {todo_comment}\")\n",
    "                else:\n",
    "                    fixed_lines.append(f\"{indent}    {param}  # {todo_comment}\")\n",
    "            else:\n",
    "                # Keep as is\n",
    "                if i < len(params) - 1:\n",
    "                    fixed_lines.append(f\"{indent}    {param},\")\n",
    "                else:\n",
    "                    fixed_lines.append(f\"{indent}    {param}\")\n",
    "    \n",
    "    # Handle return type\n",
    "    return_type = parsed['return_type']\n",
    "    \n",
    "    # Check if return type is None (no return value)\n",
    "    is_none_return = return_type and 'None' in return_type.strip()\n",
    "    \n",
    "    if return_type and docstring_info.returns and not is_none_return:\n",
    "        fixed_lines.append(f\"{indent}){return_type}:  # {docstring_info.returns}\")\n",
    "    elif return_type and 'return' in result.missing_params and not is_none_return:\n",
    "        todo_comment = generate_return_todo_comment(result)\n",
    "        fixed_lines.append(f\"{indent}){return_type}:  # {todo_comment}\")\n",
    "    elif return_type:\n",
    "        fixed_lines.append(f\"{indent}){return_type}:\")\n",
    "    else:\n",
    "        fixed_lines.append(f\"{indent}):\")\n",
    "    \n",
    "    return fixed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_multiline_to_docments(\n",
    "    sig_lines: List[str],  # Multi-line function signature\n",
    "    docstring_info: DocstringInfo,  # Extracted docstring information\n",
    "    result: DocmentsCheckResult  # Check result with missing params info\n",
    ") -> List[str]:  # Multi-line signature with docments comments\n",
    "    \"Convert multi-line function signature to docments format\"\n",
    "    \n",
    "    fixed_lines = []\n",
    "    \n",
    "    for i, line in enumerate(sig_lines):\n",
    "        line_stripped = line.strip()\n",
    "        \n",
    "        # Check if this line contains a parameter (including the last one that might end with ))\n",
    "        # Updated regex to handle parameters that end with )) for the last param before return type\n",
    "        param_match = re.match(r'^(\\s*)(\\w+)(\\s*(?::\\s*[^,\\)#]+)?)\\s*([,\\)]?)(\\)?)\\s*(?:->\\s*[^:#]+)?\\s*:?\\s*(?:#\\s*(.*))?$', line)\n",
    "        \n",
    "        # Check if it's a parameter line (not the def line)\n",
    "        if param_match and i > 0 and param_match.group(2) != 'def':\n",
    "            param_name = param_match.group(2)\n",
    "            \n",
    "            # Skip if this is actually the return type line\n",
    "            if '->' in line and ')' in line:\n",
    "                # This is a return type line, handle it separately\n",
    "                return_match = re.match(r'^(\\s*.*\\)\\s*->\\s*[^:#]+)\\s*:\\s*(.*)$', line)\n",
    "                if return_match:\n",
    "                    pre_colon = return_match.group(1)\n",
    "                    existing_comment = return_match.group(2).strip()\n",
    "                    \n",
    "                    # Check if return type is None (no return value)\n",
    "                    is_none_return = 'None' in pre_colon\n",
    "                    \n",
    "                    # Check if the existing comment is a TODO comment\n",
    "                    is_todo_comment = 'TODO' in existing_comment if existing_comment else False\n",
    "                    \n",
    "                    if docstring_info.returns and not is_none_return and (not existing_comment or is_todo_comment):\n",
    "                        # Replace with extracted return documentation if no comment or it's a TODO\n",
    "                        fixed_lines.append(f\"{pre_colon}:  # {docstring_info.returns}\")\n",
    "                    elif 'return' in result.missing_params and not is_none_return:\n",
    "                        comment_text = existing_comment[1:].strip() if existing_comment.startswith('#') else existing_comment\n",
    "                        todo_comment = generate_return_todo_comment(result, comment_text)\n",
    "                        fixed_lines.append(f\"{pre_colon}:  # {todo_comment}\")\n",
    "                    else:\n",
    "                        fixed_lines.append(line)\n",
    "                else:\n",
    "                    fixed_lines.append(line)\n",
    "            else:\n",
    "                # Regular parameter line\n",
    "                indent = param_match.group(1)\n",
    "                type_annotation = param_match.group(3) or ''\n",
    "                trailing_punct = param_match.group(4) or ''\n",
    "                extra_paren = param_match.group(5) or ''\n",
    "                existing_comment = param_match.group(6) or ''\n",
    "                \n",
    "                # Reconstruct the line ending (could be , or ) or ))\n",
    "                line_ending = trailing_punct + extra_paren\n",
    "                \n",
    "                # Get documentation from the extracted docstring info\n",
    "                param_doc = docstring_info.params.get(param_name, '')\n",
    "                \n",
    "                # Check if the existing comment is a TODO comment\n",
    "                is_todo_comment = 'TODO' in existing_comment\n",
    "                \n",
    "                if param_doc and (not existing_comment or is_todo_comment):\n",
    "                    # Replace with the extracted documentation if there's no comment or it's a TODO\n",
    "                    fixed_lines.append(f\"{indent}{param_name}{type_annotation}{line_ending}  # {param_doc}\")\n",
    "                elif param_doc and existing_comment and not is_todo_comment:\n",
    "                    # Keep existing non-TODO comment (it might be manually written documentation)\n",
    "                    fixed_lines.append(line)\n",
    "                elif param_name in result.missing_params:\n",
    "                    # No documentation found in docstring, add TODO\n",
    "                    todo_comment = generate_param_todo_comment(param_name, result, existing_comment)\n",
    "                    fixed_lines.append(f\"{indent}{param_name}{type_annotation}{line_ending}  # {todo_comment}\")\n",
    "                else:\n",
    "                    # Keep original\n",
    "                    fixed_lines.append(line)\n",
    "        else:\n",
    "            # Not a parameter line, could be def line or other\n",
    "            fixed_lines.append(line)\n",
    "    \n",
    "    return fixed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def replace_docstring_in_body(\n",
    "    body_lines: List[str],  # Function body lines\n",
    "    description: str,  # New description to use\n",
    "    def_line: str  # Function definition line for indentation\n",
    ") -> List[str]:  # Modified body lines\n",
    "    \"Replace the docstring in function body with a simple description\"\n",
    "    \n",
    "    # Find the indentation of the function definition\n",
    "    indent_match = re.match(r'^(\\s*)', def_line)\n",
    "    base_indent = indent_match.group(1) if indent_match else ''\n",
    "    docstring_indent = base_indent + '    '\n",
    "    \n",
    "    # Look for the docstring (first string literal after function definition)\n",
    "    docstring_found = False\n",
    "    result_lines = []\n",
    "    in_multiline_docstring = False\n",
    "    \n",
    "    for i, line in enumerate(body_lines):\n",
    "        line_stripped = line.strip()\n",
    "        \n",
    "        # If we haven't found the docstring yet and this line is not empty\n",
    "        if not docstring_found and line_stripped:\n",
    "            # Check if it starts a docstring\n",
    "            if line_stripped.startswith(('\"\"\"', \"'''\", '\"', \"'\")):\n",
    "                docstring_found = True\n",
    "                \n",
    "                # Check if it's a single-line docstring\n",
    "                if ((line_stripped.startswith('\"\"\"') and line_stripped.endswith('\"\"\"') and len(line_stripped) > 6) or\n",
    "                    (line_stripped.startswith(\"'''\") and line_stripped.endswith(\"'''\") and len(line_stripped) > 6) or\n",
    "                    (line_stripped.startswith('\"') and line_stripped.endswith('\"') and len(line_stripped) > 2 and not line_stripped.startswith('\"\"\"')) or\n",
    "                    (line_stripped.startswith(\"'\") and line_stripped.endswith(\"'\") and len(line_stripped) > 2 and not line_stripped.startswith(\"'''\"))):\n",
    "                    # Single-line docstring\n",
    "                    result_lines.append(f'{docstring_indent}\"{description}\"')\n",
    "                else:\n",
    "                    # Start of multi-line docstring\n",
    "                    in_multiline_docstring = True\n",
    "                    result_lines.append(f'{docstring_indent}\"{description}\"')\n",
    "            else:\n",
    "                # Not a docstring, keep the line\n",
    "                result_lines.append(line)\n",
    "        elif in_multiline_docstring:\n",
    "            # We're inside a multi-line docstring, check if this ends it\n",
    "            if line_stripped.endswith(('\"\"\"', \"'''\")):\n",
    "                in_multiline_docstring = False\n",
    "                # Skip this line (end of docstring)\n",
    "            # Skip all lines inside the multi-line docstring\n",
    "        else:\n",
    "            # Either we already processed the docstring or this is a regular line\n",
    "            result_lines.append(line)\n",
    "    \n",
    "    # If no docstring was found, add the description at the beginning\n",
    "    if not docstring_found:\n",
    "        result_lines.insert(0, f'{docstring_indent}\"{description}\"')\n",
    "    \n",
    "    return result_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_fixed_source_with_conversion(\n",
    "    result: DocmentsCheckResult  # Check result with non-compliant function\n",
    ") -> str:  # Fixed source code with converted documentation\n",
    "    \"Generate fixed source code, converting existing docstrings to docments format if possible\"\n",
    "    \n",
    "    # First, try to extract docstring information for conversion\n",
    "    docstring_info = extract_docstring_info(result.source, result.name)\n",
    "    \n",
    "    # If we found structured docstring info (not unknown), convert it\n",
    "    if (docstring_info and \n",
    "        docstring_info.docstring_type in ['google', 'numpy', 'sphinx'] and\n",
    "        (docstring_info.params or docstring_info.returns)):\n",
    "        try:\n",
    "            converted_source = convert_to_docments_format(result.source, docstring_info, result)\n",
    "            return converted_source\n",
    "        except Exception:\n",
    "            # Fallback to original fix if conversion fails\n",
    "            pass\n",
    "    \n",
    "    # Fallback to the original generate_fixed_source function\n",
    "    return generate_fixed_source(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fix_notebook_with_conversion(\n",
    "    nb_path: Path,  # Path to notebook to fix\n",
    "    dry_run: bool = False,  # If True, show changes without saving\n",
    "    convert_docstrings: bool = True  # If True, convert existing docstrings to docments format\n",
    ") -> Dict[str, Any]:  # Summary of changes made\n",
    "    \"Fix non-compliant functions in a notebook, optionally converting docstrings to docments format\"\n",
    "    nb = read_nb(nb_path)\n",
    "    definitions = scan_notebook(nb_path)\n",
    "    \n",
    "    changes = {\n",
    "        'notebook': nb_path.name,\n",
    "        'definitions_fixed': [],\n",
    "        'definitions_converted': [],\n",
    "        'cells_modified': []\n",
    "    }\n",
    "    \n",
    "    # Check each definition\n",
    "    for defn in definitions:\n",
    "        result = check_definition(defn)\n",
    "        \n",
    "        # Fix if non-compliant OR has missing type hints\n",
    "        needs_fixing = (not result.is_compliant or \n",
    "                       result.missing_params or \n",
    "                       result.params_missing_type_hints)\n",
    "        \n",
    "        if needs_fixing:\n",
    "            # Choose the appropriate fix method\n",
    "            if convert_docstrings:\n",
    "                fixed_source = generate_fixed_source_with_conversion(result)\n",
    "                \n",
    "                # Check if this was a conversion (has structured docstring info)\n",
    "                docstring_info = extract_docstring_info(result.source, result.name)\n",
    "                is_conversion = (docstring_info and \n",
    "                               docstring_info.docstring_type in ['google', 'numpy', 'sphinx'])\n",
    "            else:\n",
    "                fixed_source = generate_fixed_source(result)\n",
    "                is_conversion = False\n",
    "            \n",
    "            # Only proceed if the source actually changed\n",
    "            if fixed_source != result.source:\n",
    "                # Find and update the cell\n",
    "                cell_id = defn['cell_id']\n",
    "                for cell in nb.cells:\n",
    "                    if cell.get('id') == cell_id:\n",
    "                        # Replace the definition in the cell source\n",
    "                        old_source = result.source\n",
    "                        cell_source = cell.source\n",
    "                        \n",
    "                        # Find the definition in the cell and replace it\n",
    "                        if old_source in cell_source:\n",
    "                            new_cell_source = cell_source.replace(old_source, fixed_source)\n",
    "                            \n",
    "                            if not dry_run:\n",
    "                                cell.source = new_cell_source\n",
    "                            \n",
    "                            changes['definitions_fixed'].append(result.name)\n",
    "                            if is_conversion:\n",
    "                                changes['definitions_converted'].append(result.name)\n",
    "                            \n",
    "                            if cell_id not in changes['cells_modified']:\n",
    "                                changes['cells_modified'].append(cell_id)\n",
    "                            \n",
    "                            if dry_run:\n",
    "                                action = \"convert and fix\" if is_conversion else \"fix\"\n",
    "                                print(f\"\\nWould {action} {result.name}:\")\n",
    "                                print(\"-\" * 40)\n",
    "                                print(fixed_source)\n",
    "                                print(\"-\" * 40)\n",
    "    \n",
    "    # Save the notebook if not dry run\n",
    "    if not dry_run and changes['definitions_fixed']:\n",
    "        write_nb(nb, nb_path)\n",
    "        \n",
    "        # Report results\n",
    "        fixed_count = len(changes['definitions_fixed'])\n",
    "        converted_count = len(changes['definitions_converted'])\n",
    "        \n",
    "        if converted_count > 0:\n",
    "            print(f\"✅ Fixed {fixed_count} definitions in {nb_path.name} ({converted_count} converted from other docstring styles)\")\n",
    "        else:\n",
    "            print(f\"✅ Fixed {fixed_count} definitions in {nb_path.name}\")\n",
    "        \n",
    "        for defn_name in changes['definitions_fixed']:\n",
    "            action = \"converted & fixed\" if defn_name in changes['definitions_converted'] else \"fixed\"\n",
    "            print(f\"   - {defn_name} ({action})\")\n",
    "    elif dry_run and changes['definitions_fixed']:\n",
    "        fixed_count = len(changes['definitions_fixed'])\n",
    "        converted_count = len(changes['definitions_converted'])\n",
    "        \n",
    "        if converted_count > 0:\n",
    "            print(f\"\\n🔍 Dry run: Would fix {fixed_count} definitions ({converted_count} converted from other docstring styles)\")\n",
    "        else:\n",
    "            print(f\"\\n🔍 Dry run: Would fix {fixed_count} definitions\")\n",
    "    else:\n",
    "        print(f\"✅ All definitions in {nb_path.name} are already compliant\")\n",
    "    \n",
    "    return changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing Docstring Detection and Parsing\n",
      "==================================================\n",
      "📋 Style Detection Results:\n",
      "✅ Google: google\n",
      "✅ Numpy: numpy\n",
      "✅ Sphinx: sphinx\n",
      "✅ Unknown: unknown\n",
      "\n",
      "📖 Parsing Results:\n",
      "\n",
      "Google parsing:\n",
      "  Description: Calculate the sum of two numbers.\n",
      "  Parameters: ['x', 'y']\n",
      "  Returns: Yes\n",
      "\n",
      "Numpy parsing:\n",
      "  Description: Calculate the sum of two numbers.\n",
      "  Parameters: ['x', 'y']\n",
      "  Returns: Yes\n",
      "\n",
      "Sphinx parsing:\n",
      "  Description: \"\"\"Calculate the sum of two numbers. \"\"\"\n",
      "  Parameters: ['x', 'y']\n",
      "  Returns: Yes\n",
      "\n",
      "✅ Docstring detection and parsing tests completed\n"
     ]
    }
   ],
   "source": [
    "def test_docstring_detection_and_parsing():\n",
    "    \"\"\"Test docstring style detection and parsing for all supported formats\"\"\"\n",
    "    print(\"🧪 Testing Docstring Detection and Parsing\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Test docstrings for different styles\n",
    "    test_docstrings = [\n",
    "        # Google style\n",
    "        ('google', '''\"\"\"Calculate the sum of two numbers.\n",
    "        \n",
    "        Args:\n",
    "            x (int): The first number to add\n",
    "            y (int): The second number to add\n",
    "            \n",
    "        Returns:\n",
    "            int: The sum of x and y\n",
    "        \"\"\"'''),\n",
    "        \n",
    "        # NumPy style  \n",
    "        ('numpy', '''\"\"\"Calculate the sum of two numbers.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : int\n",
    "            The first number to add\n",
    "        y : int  \n",
    "            The second number to add\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The sum of x and y\n",
    "        \"\"\"'''),\n",
    "        \n",
    "        # Sphinx style\n",
    "        ('sphinx', '''\"\"\"Calculate the sum of two numbers.\n",
    "        \n",
    "        :param x: The first number to add\n",
    "        :param y: The second number to add\n",
    "        :returns: The sum of x and y\n",
    "        \"\"\"'''),\n",
    "        \n",
    "        # Unknown style\n",
    "        ('unknown', '''\"\"\"Just a simple description without structured parameters.\"\"\"''')\n",
    "    ]\n",
    "    \n",
    "    # Test detection\n",
    "    print(\"📋 Style Detection Results:\")\n",
    "    for expected_style, docstring in test_docstrings:\n",
    "        detected_style = detect_docstring_style(docstring)\n",
    "        status = \"✅\" if detected_style == expected_style else \"❌\"\n",
    "        print(f\"{status} {expected_style.title()}: {detected_style}\")\n",
    "    \n",
    "    # Test parsing for structured formats\n",
    "    print(\"\\n📖 Parsing Results:\")\n",
    "    for style_name, docstring in test_docstrings[:3]:  # Skip unknown style\n",
    "        if style_name == 'google':\n",
    "            parsed = parse_google_docstring(docstring)\n",
    "        elif style_name == 'numpy':\n",
    "            parsed = parse_numpy_docstring(docstring)\n",
    "        elif style_name == 'sphinx':\n",
    "            parsed = parse_sphinx_docstring(docstring)\n",
    "        \n",
    "        print(f\"\\n{style_name.title()} parsing:\")\n",
    "        print(f\"  Description: {parsed.description}\")\n",
    "        print(f\"  Parameters: {list(parsed.params.keys())}\")\n",
    "        print(f\"  Returns: {'Yes' if parsed.returns else 'No'}\")\n",
    "    \n",
    "    print(\"\\n✅ Docstring detection and parsing tests completed\")\n",
    "\n",
    "# Run test\n",
    "test_docstring_detection_and_parsing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 Testing Function Fixing\n",
      "==================================================\n",
      "\n",
      "📝 Testing: Missing all documentation and type hints\n",
      "Function: missing_all_docs\n",
      "\n",
      "Source:\n",
      "def bad_function(x, y, z=10):\n",
      "    result = x + y + z\n",
      "    return result\n",
      "\n",
      "Has docstring: False\n",
      "Is compliant: False\n",
      "Missing: ['x', 'y', 'z']\n",
      "\n",
      "Fixed Source:\n",
      "def bad_function(\n",
      "    x,  # TODO: Add type hint and description\n",
      "    y,  # TODO: Add type hint and description\n",
      "    z=10  # TODO: Add type hint and description\n",
      "):\n",
      "    \"TODO: Add function description\"\n",
      "    result = x + y + z\n",
      "    return result\n",
      "\n",
      "\n",
      "📝 Testing: Has type hints but missing parameter documentation\n",
      "Function: typed_function\n",
      "\n",
      "Source:\n",
      "def typed_function(name: str, age: int) -> str:\n",
      "    return f\"{name} is {age} years old\"\n",
      "\n",
      "Has docstring: False\n",
      "Is compliant: False\n",
      "Missing: ['name', 'age', 'return']\n",
      "\n",
      "Fixed Source:\n",
      "def typed_function(\n",
      "    name: str,  # TODO: Add description\n",
      "    age: int  # TODO: Add description\n",
      ") -> str:  # TODO: Add return description\n",
      "    \"TODO: Add function description\"\n",
      "    return f\"{name} is {age} years old\"\n",
      "\n",
      "\n",
      "📝 Testing: Partially documented - missing one parameter doc\n",
      "Function: partially_documented\n",
      "\n",
      "Source:\n",
      "def get_export_cells(\n",
      "    nb_path: Path,  # Path to the notebook file\n",
      "    fake_test_path: Path \n",
      ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
      "    \"Extract all code cells from a notebook that have export directives\"\n",
      "    nb = read_nb(nb_path)\n",
      "    return []\n",
      "\n",
      "Has docstring: False\n",
      "Is compliant: False\n",
      "Missing: ['fake_test_path']\n",
      "\n",
      "Fixed Source:\n",
      "def get_export_cells(\n",
      "    nb_path: Path,  # Path to the notebook file\n",
      "    fake_test_path: Path   # TODO: Add description\n",
      ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
      "    \"Extract all code cells from a notebook that have export directives\"\n",
      "    nb = read_nb(nb_path)\n",
      "    return []\n",
      "\n",
      "\n",
      "✅ Function fixing tests completed\n"
     ]
    }
   ],
   "source": [
    "def test_function_fixing():\n",
    "    \"\"\"Test basic function fixing for various scenarios\"\"\"\n",
    "    print(\"\\n🔧 Testing Function Fixing\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Test cases with different compliance issues\n",
    "    test_cases = [\n",
    "        {\n",
    "            'name': 'missing_all_docs',\n",
    "            'source': '''def bad_function(x, y, z=10):\n",
    "    result = x + y + z\n",
    "    return result''',\n",
    "            'args': [\n",
    "                {'name': 'x', 'annotation': None},\n",
    "                {'name': 'y', 'annotation': None},\n",
    "                {'name': 'z', 'annotation': None}\n",
    "            ],\n",
    "            'returns': None,\n",
    "            'description': 'Missing all documentation and type hints'\n",
    "        },\n",
    "        {\n",
    "            'name': 'typed_function',\n",
    "            'source': '''def typed_function(name: str, age: int) -> str:\n",
    "    return f\"{name} is {age} years old\"''',\n",
    "            'args': [\n",
    "                {'name': 'name', 'annotation': 'str'},\n",
    "                {'name': 'age', 'annotation': 'int'}\n",
    "            ],\n",
    "            'returns': 'str',\n",
    "            'description': 'Has type hints but missing parameter documentation'\n",
    "        },\n",
    "        {\n",
    "            'name': 'partially_documented',\n",
    "            'source': '''def get_export_cells(\n",
    "    nb_path: Path,  # Path to the notebook file\n",
    "    fake_test_path: Path \n",
    ") -> List[Dict[str, Any]]:  # List of cells with export directives\n",
    "    \"Extract all code cells from a notebook that have export directives\"\n",
    "    nb = read_nb(nb_path)\n",
    "    return []''',\n",
    "            'args': [\n",
    "                {'name': 'nb_path', 'annotation': 'Path'},\n",
    "                {'name': 'fake_test_path', 'annotation': 'Path'}\n",
    "            ],\n",
    "            'returns': 'List[Dict[str, Any]]',\n",
    "            'description': 'Partially documented - missing one parameter doc'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for test_case in test_cases:\n",
    "        print(f\"\\n📝 Testing: {test_case['description']}\")\n",
    "        print(f\"Function: {test_case['name']}\")\n",
    "\n",
    "        print(f\"\\nSource:\\n{test_case['source']}\\n\")\n",
    "        \n",
    "        # Create test definition\n",
    "        test_def = {\n",
    "            'name': test_case['name'],\n",
    "            'type': 'FunctionDef',\n",
    "            'source': test_case['source'],\n",
    "            'notebook': 'test.ipynb',\n",
    "            'args': test_case['args'],\n",
    "            'returns': test_case['returns']\n",
    "        }\n",
    "        \n",
    "        # Check compliance\n",
    "        result = check_definition(test_def)\n",
    "        print(f\"Has docstring: {result.has_docstring}\")\n",
    "        print(f\"Is compliant: {result.is_compliant}\")\n",
    "        if not result.is_compliant:\n",
    "            print(f\"Missing: {result.missing_params}\")\n",
    "            \n",
    "            # Apply fix\n",
    "            fixed_source = generate_fixed_source(result)\n",
    "            print(f\"\\nFixed Source:\\n{fixed_source}\\n\")\n",
    "    \n",
    "    print(\"\\n✅ Function fixing tests completed\")\n",
    "\n",
    "# Run test\n",
    "test_function_fixing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Testing Docstring Conversion\n",
      "==================================================\n",
      "\n",
      "📝 Testing Google Style Conversion\n",
      "Function: google_example\n",
      "\n",
      "Source:\n",
      "def google_example(name: str, age: int, active: bool = True) -> str:\n",
      "    \"\"\"Generate a user profile string.\n",
      "\n",
      "    Args:\n",
      "        name (str): The user's full name\n",
      "        age (int): The user's age in years\n",
      "        active (bool): Whether the user is currently active\n",
      "\n",
      "    Returns:\n",
      "        str: A formatted profile string\n",
      "    \"\"\"\n",
      "    return f\"{name} ({age}) - {'Active' if active else 'Inactive'}\"\n",
      "\n",
      "Docstring type: google\n",
      "Parameters found: ['name', 'age', 'active']\n",
      "Return info: Yes\n",
      "\n",
      "Converted Source:\n",
      "def google_example(\n",
      "    name: str,  # The user's full name\n",
      "    age: int,  # The user's age in years\n",
      "    active: bool = True  # Whether the user is currently active\n",
      ") -> str:  # str: A formatted profile string\n",
      "    \"Generate a user profile string.\"\n",
      "    return f\"{name} ({age}) - {'Active' if active else 'Inactive'}\"\n",
      "\n",
      "\n",
      "📝 Testing NumPy Style Conversion\n",
      "Function: numpy_example\n",
      "\n",
      "Source:\n",
      "def numpy_example(data: list, threshold: float = 0.5) -> dict:\n",
      "    \"\"\"Process data based on threshold.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    data : list\n",
      "        Input data to process\n",
      "    threshold : float\n",
      "        Minimum threshold value\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    dict\n",
      "        Processing results with statistics\n",
      "    \"\"\"\n",
      "    return {'processed': len(data), 'threshold': threshold}\n",
      "\n",
      "Docstring type: numpy\n",
      "Parameters found: ['data', 'threshold']\n",
      "Return info: Yes\n",
      "\n",
      "Converted Source:\n",
      "def numpy_example(\n",
      "    data: list,  # Input data to process\n",
      "    threshold: float = 0.5  # Minimum threshold value\n",
      ") -> dict:  # dict Processing results with statistics\n",
      "    \"Process data based on threshold.\"\n",
      "    return {'processed': len(data), 'threshold': threshold}\n",
      "\n",
      "\n",
      "✅ Docstring conversion tests completed\n"
     ]
    }
   ],
   "source": [
    "def test_docstring_conversion():\n",
    "    \"\"\"Test conversion from various docstring formats to docments style\"\"\"\n",
    "    print(\"\\n🔄 Testing Docstring Conversion\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Test functions with different docstring formats\n",
    "    test_functions = [\n",
    "        {\n",
    "            'name': 'google_example',\n",
    "            'source': '''def google_example(name: str, age: int, active: bool = True) -> str:\n",
    "    \"\"\"Generate a user profile string.\n",
    "    \n",
    "    Args:\n",
    "        name (str): The user's full name\n",
    "        age (int): The user's age in years\n",
    "        active (bool): Whether the user is currently active\n",
    "        \n",
    "    Returns:\n",
    "        str: A formatted profile string\n",
    "    \"\"\"\n",
    "    return f\"{name} ({age}) - {'Active' if active else 'Inactive'}\"''',\n",
    "            'args': [\n",
    "                {'name': 'name', 'annotation': 'str'},\n",
    "                {'name': 'age', 'annotation': 'int'},\n",
    "                {'name': 'active', 'annotation': 'bool'}\n",
    "            ],\n",
    "            'returns': 'str',\n",
    "            'style': 'Google'\n",
    "        },\n",
    "        {\n",
    "            'name': 'numpy_example',\n",
    "            'source': '''def numpy_example(data: list, threshold: float = 0.5) -> dict:\n",
    "    \"\"\"Process data based on threshold.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : list\n",
    "        Input data to process\n",
    "    threshold : float\n",
    "        Minimum threshold value\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Processing results with statistics\n",
    "    \"\"\"\n",
    "    return {'processed': len(data), 'threshold': threshold}''',\n",
    "            'args': [\n",
    "                {'name': 'data', 'annotation': 'list'},\n",
    "                {'name': 'threshold', 'annotation': 'float'}\n",
    "            ],\n",
    "            'returns': 'dict',\n",
    "            'style': 'NumPy'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for func_info in test_functions:\n",
    "        print(f\"\\n📝 Testing {func_info['style']} Style Conversion\")\n",
    "        print(f\"Function: {func_info['name']}\")\n",
    "\n",
    "        print(f\"\\nSource:\\n{func_info['source']}\\n\")\n",
    "        \n",
    "        # Create test definition\n",
    "        test_def = {\n",
    "            'name': func_info['name'],\n",
    "            'type': 'FunctionDef',\n",
    "            'source': func_info['source'],\n",
    "            'notebook': 'test.ipynb',\n",
    "            'args': func_info['args'],\n",
    "            'returns': func_info['returns']\n",
    "        }\n",
    "        \n",
    "        # Check original compliance\n",
    "        result = check_definition(test_def)\n",
    "        \n",
    "        \n",
    "        # Extract and verify docstring info\n",
    "        docstring_info = extract_docstring_info(result.source, result.name)\n",
    "        if docstring_info:\n",
    "            print(f\"Docstring type: {docstring_info.docstring_type}\")\n",
    "            print(f\"Parameters found: {list(docstring_info.params.keys())}\")\n",
    "            print(f\"Return info: {'Yes' if docstring_info.returns else 'No'}\")\n",
    "        \n",
    "        # Convert to docments format\n",
    "        converted = generate_fixed_source_with_conversion(result)\n",
    "        print(f\"\\nConverted Source:\\n{converted}\\n\")\n",
    "        \n",
    "        # Verify converted version is compliant\n",
    "        test_def_converted = test_def.copy()\n",
    "        test_def_converted['source'] = converted\n",
    "        result_converted = check_definition(test_def_converted)\n",
    "    \n",
    "    print(\"\\n✅ Docstring conversion tests completed\")\n",
    "\n",
    "# Run test\n",
    "test_docstring_conversion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Testing Edge Cases\n",
      "==================================================\n",
      "\n",
      "DataClass Source:@dataclass\n",
      "class DocmentsCheckResult:\n",
      "    name: str  # Name of the function/class\n",
      "    type: str  # Type (FunctionDef, ClassDef, etc.)\n",
      "    notebook: str  # Source notebook\n",
      "    has_docstring: bool  # Whether it has a docstring\n",
      "    params_documented: Dict[str, bool]  # Which params have documentation\n",
      "    return_documented: bool  # Whether return is documented\n",
      "    missing_params: List[str]  # Parameters missing documentation\n",
      "    is_compliant: bool  # Overall compliance status\n",
      "\n",
      "📝 Testing dataclass without docstring\n",
      "\n",
      "Fixed DataClass Source:\n",
      "@dataclass\n",
      "class DocmentsCheckResult:\n",
      "    \"TODO: Add class description\"\n",
      "    name: str  # Name of the function/class\n",
      "    type: str  # Type (FunctionDef, ClassDef, etc.)\n",
      "    notebook: str  # Source notebook\n",
      "    has_docstring: bool  # Whether it has a docstring\n",
      "    params_documented: Dict[str, bool]  # Which params have documentation\n",
      "    return_documented: bool  # Whether return is documented\n",
      "    missing_params: List[str]  # Parameters missing documentation\n",
      "    is_compliant: bool  # Overall compliance status\n",
      "\n",
      "\n",
      "Edge Case Source:\n",
      "def get_export_cells(nb_path: Path) -> List[Dict[str, Any]]:  # List of cells with export directives\n",
      "    \"Extract all code cells from a notebook that have export directives\"\n",
      "    nb = read_nb(nb_path)\n",
      "    return []\n",
      "\n",
      "\n",
      "📝 Testing single-line function with existing return comment\n",
      "\n",
      "Fixed Edge Case Source:\n",
      "\n",
      "def get_export_cells(\n",
      "    nb_path: Path  # TODO: Add description\n",
      ") -> List[Dict[str, Any]]: # List of cells with export directives\n",
      "    \"Extract all code cells from a notebook that have export directives\"\n",
      "    nb = read_nb(nb_path)\n",
      "    return []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_edge_cases():\n",
    "    \"\"\"Test edge cases and special scenarios\"\"\"\n",
    "    print(\"\\n🎯 Testing Edge Cases\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Test dataclass without docstring\n",
    "    dataclass_source = '''@dataclass\n",
    "class DocmentsCheckResult:\n",
    "    name: str  # Name of the function/class\n",
    "    type: str  # Type (FunctionDef, ClassDef, etc.)\n",
    "    notebook: str  # Source notebook\n",
    "    has_docstring: bool  # Whether it has a docstring\n",
    "    params_documented: Dict[str, bool]  # Which params have documentation\n",
    "    return_documented: bool  # Whether return is documented\n",
    "    missing_params: List[str]  # Parameters missing documentation\n",
    "    is_compliant: bool  # Overall compliance status'''\n",
    "\n",
    "    print(f\"\\nDataClass Source:{dataclass_source}\\n\")    \n",
    "    \n",
    "    test_dataclass = {\n",
    "        'name': 'DocmentsCheckResult',\n",
    "        'type': 'ClassDef',\n",
    "        'source': dataclass_source,\n",
    "        'notebook': 'test.ipynb',\n",
    "        'args': [],\n",
    "        'returns': None\n",
    "    }\n",
    "    \n",
    "    print(\"📝 Testing dataclass without docstring\")\n",
    "    result = check_definition(test_dataclass)\n",
    "    \n",
    "    if not result.is_compliant:\n",
    "        fixed = generate_fixed_source(result)\n",
    "        print(f\"\\nFixed DataClass Source:\\n{fixed}\\n\")\n",
    "    \n",
    "    # Test single-line function with existing return comment\n",
    "    edge_case_source = '''\n",
    "def get_export_cells(nb_path: Path) -> List[Dict[str, Any]]:  # List of cells with export directives\n",
    "    \"Extract all code cells from a notebook that have export directives\"\n",
    "    nb = read_nb(nb_path)\n",
    "    return []'''\n",
    "\n",
    "    print(f\"\\nEdge Case Source:{edge_case_source}\\n\")\n",
    "    \n",
    "    test_edge_case = {\n",
    "        'name': 'get_export_cells',\n",
    "        'type': 'FunctionDef',\n",
    "        'source': edge_case_source,\n",
    "        'notebook': 'test.ipynb',\n",
    "        'args': [{'name': 'nb_path', 'annotation': 'Path'}],\n",
    "        'returns': 'List[Dict[str, Any]]'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n📝 Testing single-line function with existing return comment\")\n",
    "    result_edge = check_definition(test_edge_case)\n",
    "    \n",
    "    if not result_edge.is_compliant:\n",
    "        fixed_edge = generate_fixed_source(result_edge)\n",
    "        print(f\"\\nFixed Edge Case Source:\\n{fixed_edge}\\n\")\n",
    "        test_edge_fixed = test_edge_case.copy()\n",
    "        test_edge_fixed['source'] = fixed_edge\n",
    "        result_edge_after = check_definition(test_edge_fixed)\n",
    "\n",
    "# Run test\n",
    "test_edge_cases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Testing Functions Without Return Values\n",
      "==================================================\n",
      "\n",
      "📝 Testing: Function with no return value\n",
      "Function: output_report\n",
      "Has return value: False\n",
      "Missing type hints: []\n",
      "'return' in missing type hints: False\n",
      "\n",
      "📝 Testing: Simple function with no return\n",
      "Function: print_only\n",
      "Has return value: False\n",
      "Missing type hints: ['x', 'y']\n",
      "'return' in missing type hints: False\n",
      "\n",
      "Fixed Source:\n",
      "def print_only(\n",
      "    x,  # TODO: Add type hint and description\n",
      "    y  # TODO: Add type hint and description\n",
      "):\n",
      "    \"Just print values\"\n",
      "    print(f\"{x} and {y}\")\n",
      "\n",
      "\n",
      "📝 Testing: Function that returns a value\n",
      "Function: with_return\n",
      "Has return value: True\n",
      "Missing type hints: ['x', 'y', 'return']\n",
      "'return' in missing type hints: True\n",
      "\n",
      "Fixed Source:\n",
      "def with_return(\n",
      "    x,  # TODO: Add type hint and description\n",
      "    y  # TODO: Add type hint and description\n",
      "): # TODO: Add type hint\n",
      "    \"Add and return\"\n",
      "    return x + y\n",
      "\n",
      "\n",
      "✅ No-return-value function tests completed\n"
     ]
    }
   ],
   "source": [
    "# Test fixing functions without return values\n",
    "def test_no_return_value_functions():\n",
    "    \"\"\"Test that functions without return values don't get TODO: Add type hint comments\"\"\"\n",
    "    print(\"\\n🔍 Testing Functions Without Return Values\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    from cjm_nbdev_docments.core import function_has_return_value\n",
    "    \n",
    "    test_cases = [\n",
    "        {\n",
    "            'name': 'output_report',\n",
    "            'source': '''def output_report(\n",
    "    report: str,  # Report content to output\n",
    "    output_path: Optional[Path] = None,  # File path to save report to\n",
    "    quiet: bool = False  # Whether to suppress output\n",
    "):  # TODO: Add return description\n",
    "    \"Output the report to console or file\"\n",
    "    if output_path:\n",
    "        output_path.write_text(report)\n",
    "        if not quiet:\n",
    "            print(f\"Report saved to {output_path}\")\n",
    "    elif not quiet:\n",
    "        print(report)''',\n",
    "            'args': [\n",
    "                {'name': 'report', 'annotation': 'str'},\n",
    "                {'name': 'output_path', 'annotation': 'Optional[Path]'},\n",
    "                {'name': 'quiet', 'annotation': 'bool'}\n",
    "            ],\n",
    "            'returns': None,\n",
    "            'description': 'Function with no return value'\n",
    "        },\n",
    "        {\n",
    "            'name': 'print_only',\n",
    "            'source': '''def print_only(x, y):\n",
    "    \"Just print values\"\n",
    "    print(f\"{x} and {y}\")''',\n",
    "            'args': [\n",
    "                {'name': 'x', 'annotation': None},\n",
    "                {'name': 'y', 'annotation': None}\n",
    "            ],\n",
    "            'returns': None,\n",
    "            'description': 'Simple function with no return'\n",
    "        },\n",
    "        {\n",
    "            'name': 'with_return',\n",
    "            'source': '''def with_return(x, y):\n",
    "    \"Add and return\"\n",
    "    return x + y''',\n",
    "            'args': [\n",
    "                {'name': 'x', 'annotation': None},\n",
    "                {'name': 'y', 'annotation': None}\n",
    "            ],\n",
    "            'returns': None,\n",
    "            'description': 'Function that returns a value'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for test_case in test_cases:\n",
    "        print(f\"\\n📝 Testing: {test_case['description']}\")\n",
    "        print(f\"Function: {test_case['name']}\")\n",
    "        \n",
    "        # Check if function has return value\n",
    "        has_return = function_has_return_value(test_case['source'], test_case['name'])\n",
    "        print(f\"Has return value: {has_return}\")\n",
    "        \n",
    "        # Create test definition\n",
    "        test_def = {\n",
    "            'name': test_case['name'],\n",
    "            'type': 'FunctionDef',\n",
    "            'source': test_case['source'],\n",
    "            'notebook': 'test.ipynb',\n",
    "            'args': test_case['args'],\n",
    "            'returns': test_case['returns']\n",
    "        }\n",
    "        \n",
    "        # Check compliance\n",
    "        result = check_definition(test_def)\n",
    "        print(f\"Missing type hints: {result.params_missing_type_hints}\")\n",
    "        print(f\"'return' in missing type hints: {'return' in result.params_missing_type_hints}\")\n",
    "        \n",
    "        # Apply fix if needed\n",
    "        if not result.is_compliant or result.params_missing_type_hints:\n",
    "            fixed_source = generate_fixed_source(result)\n",
    "            print(f\"\\nFixed Source:\\n{fixed_source}\\n\")\n",
    "            \n",
    "            # Verify no TODO for return type hint was added if no return value\n",
    "            if not has_return and \"TODO: Add type hint\" in fixed_source and \"):\" in fixed_source:\n",
    "                # Check if TODO is on the return line\n",
    "                for line in fixed_source.split('\\n'):\n",
    "                    if ')' in line and ':' in line and 'TODO: Add type hint' in line and 'def' not in line:\n",
    "                        print(\"❌ ERROR: Added TODO for return type hint when function has no return value!\")\n",
    "                        break\n",
    "    \n",
    "    print(\"\\n✅ No-return-value function tests completed\")\n",
    "\n",
    "# Run test\n",
    "test_no_return_value_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🆕 Testing Simplified Docstring Format\n",
      "==================================================\n",
      "Testing docstring:\n",
      "\"\"\"Add an element with OOB swap configuration.\n",
      "\n",
      "Args:\n",
      "    element: The element to add\n",
      "    target_id: Target element ID for OOB swap\n",
      "    swap_mode: Swap mode (innerHTML, outerHTML, beforeend, afterbegin, etc.)\n",
      "    wrap: If True and target_id is provided, wrap content in a Div with OOB attributes.\n",
      "          If False, add OOB attributes directly to the element.\n",
      "\n",
      "Returns:\n",
      "    Self for chaining\n",
      "\"\"\"\n",
      "\n",
      "Detected style: google\n",
      "✅ Successfully detected as Google style\n",
      "Description: Add an element with OOB swap configuration.\n",
      "Parameters parsed: ['element', 'target_id', 'swap_mode', 'wrap']\n",
      "Parameter details:\n",
      "  - element: The element to add\n",
      "  - target_id: Target element ID for OOB swap\n",
      "  - swap_mode: Swap mode (innerHTML, outerHTML, beforeend, afterbegin, etc.)\n",
      "  - wrap: If True and target_id is provided, wrap content in a Div with OOB attributes. If False, add OOB attributes directly to the element.\n",
      "Returns: Self for chaining\n",
      "\n",
      "📝 Testing conversion of simplified format:\n",
      "Is compliant before conversion: False\n",
      "Missing params: ['element', 'target_id', 'swap_mode', 'wrap']\n",
      "\n",
      "Extracted docstring info:\n",
      "  Style: google\n",
      "  Params: ['element', 'target_id', 'swap_mode', 'wrap']\n",
      "\n",
      "Converted to docments format:\n",
      "def add_oob_element(\n",
      "    element,  # The element to add\n",
      "    target_id,  # Target element ID for OOB swap\n",
      "    swap_mode,  # Swap mode (innerHTML, outerHTML, beforeend, afterbegin, etc.)\n",
      "    wrap=True  # If True and target_id is provided, wrap content in a Div with OOB attributes. If False, add OOB attributes directly to the element.\n",
      "):\n",
      "    \"Add an element with OOB swap configuration.\"\n",
      "    # Implementation here\n",
      "    return self\n",
      "\n",
      "✅ Simplified docstring format test completed\n"
     ]
    }
   ],
   "source": [
    "def test_simplified_docstring_format():\n",
    "    \"\"\"Test the simplified docstring format (Args without type info in parentheses)\"\"\"\n",
    "    print(\"\\n🆕 Testing Simplified Docstring Format\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # The exact docstring format the user wants to support\n",
    "    test_docstring = '''\"\"\"Add an element with OOB swap configuration.\n",
    "\n",
    "Args:\n",
    "    element: The element to add\n",
    "    target_id: Target element ID for OOB swap\n",
    "    swap_mode: Swap mode (innerHTML, outerHTML, beforeend, afterbegin, etc.)\n",
    "    wrap: If True and target_id is provided, wrap content in a Div with OOB attributes.\n",
    "          If False, add OOB attributes directly to the element.\n",
    "\n",
    "Returns:\n",
    "    Self for chaining\n",
    "\"\"\"'''\n",
    "    \n",
    "    print(\"Testing docstring:\")\n",
    "    print(test_docstring)\n",
    "    print()\n",
    "    \n",
    "    # Test detection\n",
    "    detected_style = detect_docstring_style(test_docstring)\n",
    "    print(f\"Detected style: {detected_style}\")\n",
    "    \n",
    "    # Test parsing - should be detected as Google style\n",
    "    if detected_style == 'google':\n",
    "        parsed = parse_google_docstring(test_docstring)\n",
    "        print(f\"✅ Successfully detected as Google style\")\n",
    "        print(f\"Description: {parsed.description}\")\n",
    "        print(f\"Parameters parsed: {list(parsed.params.keys())}\")\n",
    "        print(f\"Parameter details:\")\n",
    "        for param, desc in parsed.params.items():\n",
    "            print(f\"  - {param}: {desc}\")\n",
    "        print(f\"Returns: {parsed.returns}\")\n",
    "    else:\n",
    "        print(f\"❌ Not detected as Google style (detected as {detected_style})\")\n",
    "    \n",
    "    # Test conversion with a complete function\n",
    "    test_function_source = '''def add_oob_element(element, target_id, swap_mode, wrap=True):\n",
    "    \"\"\"Add an element with OOB swap configuration.\n",
    "\n",
    "    Args:\n",
    "        element: The element to add\n",
    "        target_id: Target element ID for OOB swap\n",
    "        swap_mode: Swap mode (innerHTML, outerHTML, beforeend, afterbegin, etc.)\n",
    "        wrap: If True and target_id is provided, wrap content in a Div with OOB attributes.\n",
    "              If False, add OOB attributes directly to the element.\n",
    "\n",
    "    Returns:\n",
    "        Self for chaining\n",
    "    \"\"\"\n",
    "    # Implementation here\n",
    "    return self'''\n",
    "    \n",
    "    print(\"\\n📝 Testing conversion of simplified format:\")\n",
    "    \n",
    "    # Create test definition\n",
    "    test_def = {\n",
    "        'name': 'add_oob_element',\n",
    "        'type': 'FunctionDef',\n",
    "        'source': test_function_source,\n",
    "        'notebook': 'test.ipynb',\n",
    "        'args': [\n",
    "            {'name': 'element', 'annotation': None},\n",
    "            {'name': 'target_id', 'annotation': None},\n",
    "            {'name': 'swap_mode', 'annotation': None},\n",
    "            {'name': 'wrap', 'annotation': None}\n",
    "        ],\n",
    "        'returns': None\n",
    "    }\n",
    "    \n",
    "    # Check compliance\n",
    "    result = check_definition(test_def)\n",
    "    print(f\"Is compliant before conversion: {result.is_compliant}\")\n",
    "    print(f\"Missing params: {result.missing_params}\")\n",
    "    \n",
    "    # Extract docstring info\n",
    "    docstring_info = extract_docstring_info(test_function_source, 'add_oob_element')\n",
    "    if docstring_info:\n",
    "        print(f\"\\nExtracted docstring info:\")\n",
    "        print(f\"  Style: {docstring_info.docstring_type}\")\n",
    "        print(f\"  Params: {list(docstring_info.params.keys())}\")\n",
    "        \n",
    "        # Convert to docments format\n",
    "        converted = generate_fixed_source_with_conversion(result)\n",
    "        print(f\"\\nConverted to docments format:\")\n",
    "        print(converted)\n",
    "    \n",
    "    print(\"\\n✅ Simplified docstring format test completed\")\n",
    "\n",
    "# Run test\n",
    "test_simplified_docstring_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Testing Mixed Documentation Scenario\n",
      "==================================================\n",
      "Original source with TODOs and docstring:\n",
      "def add_element(self,\n",
      "                   element: Any,  # TODO: Add description\n",
      "                   target_id: Optional[str] = None,  # TODO: Add description\n",
      "                   swap_mode: str = \"innerHTML\",  # TODO: Add description\n",
      "                   wrap: bool = True) -> 'OOBStreamBuilder':\n",
      "        \"\"\"Add an element with OOB swap configuration.\n",
      "\n",
      "        Args:\n",
      "            element: The element to add\n",
      "            target_id: Target element ID for OOB swap\n",
      "            swap_mode: Swap mode (innerHTML, outerHTML, beforeend, afterbegin, etc.)\n",
      "            wrap: If True and target_id is provided, wrap content in a Div with OOB attributes.\n",
      "                  If False, add OOB attributes directly to the element.\n",
      "\n",
      "        Returns:\n",
      "            Self for chaining\n",
      "        \"\"\"\n",
      "        return self\n",
      "\n",
      "Is compliant: False\n",
      "Missing params: ['wrap', 'return']\n",
      "Has TODOs: True\n",
      "\n",
      "Extracted docstring info:\n",
      "  Style: google\n",
      "  Params: ['element', 'target_id', 'swap_mode', 'wrap']\n",
      "\n",
      "After conversion attempt:\n",
      "def add_element(self,\n",
      "                   element: Any,  # The element to add\n",
      "                   target_id: Optional[str] = None,  # Target element ID for OOB swap\n",
      "                   swap_mode: str = \"innerHTML\",  # Swap mode (innerHTML, outerHTML, beforeend, afterbegin, etc.)\n",
      "                   wrap: bool = True) -> 'OOBStreamBuilder':  # Self for chaining\n",
      "    \"Add an element with OOB swap configuration.\"\n",
      "        return self\n",
      "\n",
      "✅ Mixed documentation scenario test completed\n"
     ]
    }
   ],
   "source": [
    "def test_mixed_documentation_scenario():\n",
    "    \"\"\"Test converting docstring when parameters already have TODO comments\"\"\"\n",
    "    print(\"\\n🔄 Testing Mixed Documentation Scenario\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # This is the exact scenario from the user's code\n",
    "    test_source = '''def add_element(self,\n",
    "                   element: Any,  # TODO: Add description\n",
    "                   target_id: Optional[str] = None,  # TODO: Add description\n",
    "                   swap_mode: str = \"innerHTML\",  # TODO: Add description\n",
    "                   wrap: bool = True) -> 'OOBStreamBuilder':\n",
    "        \"\"\"Add an element with OOB swap configuration.\n",
    "        \n",
    "        Args:\n",
    "            element: The element to add\n",
    "            target_id: Target element ID for OOB swap\n",
    "            swap_mode: Swap mode (innerHTML, outerHTML, beforeend, afterbegin, etc.)\n",
    "            wrap: If True and target_id is provided, wrap content in a Div with OOB attributes.\n",
    "                  If False, add OOB attributes directly to the element.\n",
    "            \n",
    "        Returns:\n",
    "            Self for chaining\n",
    "        \"\"\"\n",
    "        return self'''\n",
    "    \n",
    "    print(\"Original source with TODOs and docstring:\")\n",
    "    print(test_source)\n",
    "    print()\n",
    "    \n",
    "    # Create test definition\n",
    "    test_def = {\n",
    "        'name': 'add_element',\n",
    "        'type': 'FunctionDef',\n",
    "        'source': test_source,\n",
    "        'notebook': 'test.ipynb',\n",
    "        'args': [\n",
    "            {'name': 'self', 'annotation': None},\n",
    "            {'name': 'element', 'annotation': 'Any'},\n",
    "            {'name': 'target_id', 'annotation': 'Optional[str]'},\n",
    "            {'name': 'swap_mode', 'annotation': 'str'},\n",
    "            {'name': 'wrap', 'annotation': 'bool'}\n",
    "        ],\n",
    "        'returns': \"'OOBStreamBuilder'\"\n",
    "    }\n",
    "    \n",
    "    # Check compliance\n",
    "    result = check_definition(test_def)\n",
    "    print(f\"Is compliant: {result.is_compliant}\")\n",
    "    print(f\"Missing params: {result.missing_params}\")\n",
    "    print(f\"Has TODOs: {result.has_todos}\")\n",
    "    print()\n",
    "    \n",
    "    # Extract docstring info\n",
    "    docstring_info = extract_docstring_info(test_source, 'add_element')\n",
    "    if docstring_info:\n",
    "        print(f\"Extracted docstring info:\")\n",
    "        print(f\"  Style: {docstring_info.docstring_type}\")\n",
    "        print(f\"  Params: {list(docstring_info.params.keys())}\")\n",
    "        print()\n",
    "    \n",
    "    # Try to convert\n",
    "    converted = generate_fixed_source_with_conversion(result)\n",
    "    print(\"After conversion attempt:\")\n",
    "    print(converted)\n",
    "    \n",
    "    print(\"\\n✅ Mixed documentation scenario test completed\")\n",
    "\n",
    "# Run test\n",
    "test_mixed_documentation_scenario()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
